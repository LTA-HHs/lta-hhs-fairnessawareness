[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "No Fairness without Awareness",
    "section": "",
    "text": "Inleiding\nIn deze analyse onderzoeken we Retentie na 1 jaar voor de opleiding B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars, van de faculteit IT & Design (ITD).",
    "crumbs": [
      "Inleiding"
    ]
  },
  {
    "objectID": "index.html#onderzoek-naar-kansengelijkheid",
    "href": "index.html#onderzoek-naar-kansengelijkheid",
    "title": "No Fairness without Awareness",
    "section": "Onderzoek naar kansengelijkheid",
    "text": "Onderzoek naar kansengelijkheid\nHet lectoraat Learning Technology & Analytics (LTA) van De Haagse Hogeschool heeft tot doel kansengelijkheid voor studenten te verhogen met behulp van learning analytics en inzet van learning technology.\nHet lectoraat heeft een onderzoeksmethode ontwikkeld om te kunnen analyseren of er sprake is van bias in studiedata in relatie tot het succes van studenten, wat een indicatie kan zijn van een gebrek aan kansengelijkheid. Deze methode gebruikt prognosemodellen op basis van machine learning. Een prognosemodel is dus niet een doel op zich, maar het instrument voor een analyse van kansengelijkheid, ook wel een fairness analyse genoemd.\nOver deze methode heeft de lector, Dr. Theo Bakker, zijn intreerede uitgesproken op 21 november 2024, getiteld: ‘No Fairness without Awareness. Toegepast onderzoek naar kansengelijkheid in het hoger onderwijs. Intreerede lectoraat Learning Technology & Analytics.’ (Bakker, 2024). Zie voor een verdere toelichting op het gehele onderzoeksprogramma: ‘No Fairness without Awareness’.",
    "crumbs": [
      "Inleiding"
    ]
  },
  {
    "objectID": "index.html#het-nut-van-prognosemodellen",
    "href": "index.html#het-nut-van-prognosemodellen",
    "title": "No Fairness without Awareness",
    "section": "Het nut van prognosemodellen",
    "text": "Het nut van prognosemodellen\nPrognosemodellen kunnen inzicht bieden in de factoren die gecorreleerd zijn aan de uitval of - als tegenhanger - de retentie van studenten. Met deze inzichten kan een opleiding interventies ontwikkelen om uitval te verminderen of te voorkomen en retentie te bevorderen. Denk aan een betere voorlichting, onboarding, begeleiding of ontwikkeling van het onderwijs. Voor de uitleg van de toepassing van deze methode om kansengelijkheid op te sporen is retentie beter te volgen dan uitval. Vandaar dat we in deze analyse retentie na 1 jaar als uitkomstvariabele nemen.\n\n\n\n\n\n\nDisclaimer\n\n\n\nDe prognosemodellen die we in deze analyses ontwikkelen zijn bedoeld om de dynamiek in het studiesucces van studenten een opleiding beter te begrijpen om kansengelijkheid te bevorderen.\nDeze modellen mogen op geen enkele wijze gebruikt worden om individuele studenten te beoordelen of hun succes te voorspellen.",
    "crumbs": [
      "Inleiding"
    ]
  },
  {
    "objectID": "index.html#opbouw-analyse-en-aanpak",
    "href": "index.html#opbouw-analyse-en-aanpak",
    "title": "No Fairness without Awareness",
    "section": "Opbouw analyse en aanpak",
    "text": "Opbouw analyse en aanpak\nDeze analyse kent drie hoofdstukken met de drie stappen van de aanpak:\n\nHoofdstuk 1: Prognosemodel retentie na 1 jaar - De ontwikkeling van een aantal prognosemodellen om retentie na 1 jaar te voorspellen, waaruit het best presterende model wordt gekozen.\nHoofdstuk 2: Factoranalyse - Een verdiepende analyse op de factoren van het best presterende model.\nHoofdstuk 3: Kansengelijkheid - De analyse van de modellen op bias en kansengelijkheid.",
    "crumbs": [
      "Inleiding"
    ]
  },
  {
    "objectID": "index.html#vragen-of-suggesties",
    "href": "index.html#vragen-of-suggesties",
    "title": "No Fairness without Awareness",
    "section": "Vragen of suggesties",
    "text": "Vragen of suggesties\nHeb je vragen of suggesties over deze analyse? Neem dan contact op met Theo Bakker via 06-25637172 of per mail via t.c.bakker@hhs.nl.\n\n \nCopyright\nDr. Theo Bakker, Lectoraat Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.\n\n\n\n\n\nBakker, T. (2024). No Fairness without Awareness. Toegepast onderzoek naar kansengelijkheid in het hoger onderwijs. Intreerede lectoraat Learning Technology & Analytics. The Hague University of Applied Sciences. https://doi.org/10.5281/zenodo.14204674",
    "crumbs": [
      "Inleiding"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html",
    "href": "lta-hhs-tidymodels-h1-basis.html",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "",
    "text": "1.1 Methode, data en analyse",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html#methode-data-en-analyse",
    "href": "lta-hhs-tidymodels-h1-basis.html#methode-data-en-analyse",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "",
    "text": "1.1.1 Toelichting op de methode\nVoor de ontwikkeling van prognosemodellen gebruiken we de aanpak van Tidymodels. Tidymodels is een framework voor het bouwen van een prognosemodel. Hiermee verzekeren we ons van een systematische, herhaalbare en schaalbare aanpak.\n\n\n1.1.2 Toelichting op de data\nDe basis voor deze analyse is studiedata van De Haagse Hogeschool (De HHs), verrijkt door het lectoraat LTA. De data bevat informatie over de inschrijvingen van studenten in het eerste jaar van de opleiding:\n\nDemografische kenmerken: geslacht, leeftijd, reistijd en SES totaalscore.\nVooropleidingskenmerken: toelaatgevende vooropleiding, studiekeuzeprofiel en gemiddeld eindcijfer in de vooropleiding.\nAanmeldingskenmerken: aansluiting (direct na diploma, tussenjaar, switch), dag van aanmelding, aantal parallelle studies aan De HHs en collegejaar.\n\nDeze variabelen zijn gekozen omdat we uit eerder onderzoek weten dat ze voorspellende waarde kunnen hebben voor studiesucces (Bakker, 2022) of omdat ze behoren tot sensitieve kenmerken die in fairness analyse gebruikt worden.\n\n\nToon code\n# Lees de data dictionary in\ndfData_dictionary &lt;- Get_Data_Dictionary()\n\n# Toon de data dictionary\nGet_tblData_Dictionary(dfData_dictionary)\n\n\n\n\nTabel 1.1: Variabelen en mogelijke waarden\n\n\n\nVariabeleToelichtingMogelijke waardenAanmeldingDe dag van de aanmelding voor de studie gerekend vanaf 1 september-366 - 366AansluitingDe manier waarop een student instroomt in de opleiding2e studie, Direct, Na CD, Onbekend, Overig, Switch Extern, Switch Intern, TussenjaarAPCGOf de student ten tijde van het behalen van de toelaatgevende vooropleiding in een armoedeprobleemcumulatiegebied woondeJa, Nee, OnbekendCijfer_CE_EngelsHet gemiddelde cijfer Engels van het centaal examen van de middelbare school0-10Cijfer_CE_NatuurkundeHet gemiddelde cijfer voor Natuurkunde van het centaal examen van de middelbare school0-10Cijfer_CE_NederlandsHet gemiddelde cijfer Nederlands van het centaal examen van de middelbare school0-10Cijfer_CE_VOHet gemiddelde cijfer voor het centaal examen van de middelbare school0-10Cijfer_CE_WiskundeHet gemiddelde cijfer voor Wiskunde van het centaal examen van de middelbare school0-10Cijfer_SE_VOHet gemiddelde cijfer voor het schoolexamen van de middelbare school0-10CollegejaarHet collegejaar van de inschrijving2012-2022Dubbele_studieGegeven of de student meer dan 1 studie volgtJa, NeeGeslachtHet geslacht van de studentM, VIDUniek nummer per studentLeeftijdDe leeftijd van de student op 1 oktober16-100RankingDe positie die de student heeft in de selectie voor de opleiding (alleen bij de B Huidtherapie)0-350ReistijdDe reistijd van de student naar de vestiging van de opleiding op een maandag om 9 uur met het openbaar vervoer vanaf de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding in minuten0-120RetentieOf de student doorstudeert na het eerste studiejaarJa, NeeSES_ArbeidDe sociaaleconomische status score op arbeid van het CBS op basis van de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding-1 - 1SES_TotaalDe sociaaleconomische status score totaal van het CBS op basis van de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding-1 - 1SES_WelvaartDe sociaaleconomische status score op welvaart van het CBS op basis van de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding-1 - 1StudiekeuzeprofielHet studiekeuzeprofiel in het voortgezet onderwijs (havo of vwo) of profiel in het mboAHO, ALG, CERT, CM, EA, EM, EM&CM, HB, HO, ICT, MedV, NG, NT, NT&NG, Onbekend, TP, TR, TSL, VNL, VS, ZWVooropleidingDe toelaatgevende vooropleidingBD, CD, HAVO, HO, MBO, Overig, VWO\n\n\n\n\n\n\n\n1.1.3 Toelichting op de analyse\nWe toetsen in deze analyse Retentie na 1 jaar, voortaan Retentie genoemd.\nRetentie is gedefinieerd als ingeschreven staan in dezelfde opleiding in een aansluitend collegejaar. Een wisseling van opleidingsvorm binnen de opleiding, bijvoorbeeld van voltijd in jaar 1 naar duaal in jaar 2, geldt ook als retentie. Uitval is het tegenovergestelde van retentie: niet ingeschreven staan in dezelfde opleiding in een aansluitend collegejaar. Een wisseling van opleidingsvorm binnen de opleiding, bijvoorbeeld van voltijd in jaar 1 naar duaal in jaar 2, geldt niet als uitval.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html#voorbereidingen",
    "href": "lta-hhs-tidymodels-h1-basis.html#voorbereidingen",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "1.2 Voorbereidingen",
    "text": "1.2 Voorbereidingen\n\n1.2.1 Laad de data\nWe laden een subset in van historische data specifiek voor:\nOpleiding: ITD | B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars - Retentie na 1 jaar\n\n\nToon code\n## Laad de data voor de opleiding\nif(params$use_synthetic_data) {\n  dfOpleiding_inschrijvingen_base &lt;- Get_Studyprogram_Enrollments_Synthetic(\n    studytrack = params$opleiding,\n    studyform = toupper(params$opleidingsvorm_afkorting)\n  ) |&gt; \n    mutate(\n      INS_Student_UUID_opleiding_vorm = paste(ID, INS_Opleiding, INS_Opleidingsvorm, sep = \"_\"),\n      INS_Opleidingsnaam_huidig = paste(INS_Opleidingsnaam_huidig, \"(Synth.)\", sep = \" \")\n    )\n} else {\n  dfOpleiding_inschrijvingen_base &lt;- get_lta_studyprogram_enrollments_pin(\n    board = \"HHs/Inschrijvingen\",\n    faculty = params$faculteit,\n    studyprogram = params$opleidingsnaam,\n    studytrack = params$opleiding,\n    studyform = toupper(params$opleidingsvorm),\n    range = \"eerstejaars\")\n}\n\n## Herschik de levels\nSet_Levels(dfOpleiding_inschrijvingen_base)\n\ndfOpleiding_inschrijvingen_base &lt;- dfOpleiding_inschrijvingen_base |&gt;  \n  \n  ## Maak een eenvoudige succes variabele aan\n  Mutate_Retentie(sSucces_model) |&gt;\n  \n  ## Maak van de succes variabele een factor\n  mutate(SUC_Retentie = as.factor(SUC_Retentie)) |&gt; \n\n  ## Verbijzonder eventueel op basis van het propedeusediploma\n  # Filter_Propedeusediploma(sPropedeusediploma) |&gt;\n\n  ## Maak van de Dubbele studie variabele een Ja/Nee variabele\n  mutate(INS_Dubbele_studie = ifelse(INS_Aantal_inschrijvingen &gt; 1, \"Ja\", \"Nee\")) |&gt;  \n\n  ## Verwijder INS_Aantal_inschrijvingen\n  select(-INS_Aantal_inschrijvingen) |&gt; \n\n  ## Pas voor een aantal variabelen de levels aan\n  Mutate_Levels(\n  c(\n    \"VOP_Studiekeuzeprofiel_LTA_afkorting\",\n    \"INS_Aansluiting_LTA\",\n    \"VOP_Toelaatgevende_vooropleiding_soort\"\n  ),\n    list(lLevels_skp, lLevels_vop, lLevels_vop)\n  )\n  \n## B Huidtherapie: Filter op uitsluitend studenten met een rangnummer (selectie)\nif(opleiding == \"HDT\") {\n  dfOpleiding_inschrijvingen_base &lt;- dfOpleiding_inschrijvingen_base |&gt; \n    filter(!is.na(RNK_Rangnummer)) \n} \n\n\n\n\n1.2.2 Selecteer en inspecteer de data\nWe selecteren eerst de relevante variabelen. We verwijderen daarbij variabelen die maar 1 waarde hebben. We inspecteren de variabelen in een samenvatting in relatie tot retentie en corrigeren daarbij voor multiple testing; de gecorrigeerde significantie-waarden staan vermeld als q-value. Daarnaast inspecteren we de kwaliteit van de data op missende waarden.\n\n\nToon code\nlSelect &lt;- c(\n    \"INS_Student_UUID_opleiding_vorm\",\n    \"CBS_APCG_tf\",\n    \"DEM_Geslacht\",\n    \"DEM_Leeftijd_1_oktober\",\n    \"GIS_Tijd_fiets_OV\",\n    \"INS_Collegejaar\",\n    \"INS_Dagen_tussen_aanmelding_en_1_september\",\n    \"INS_Dubbele_studie\",\n    \"INS_Aansluiting_LTA\",\n    \"SES_Deelscore_arbeid\",\n    \"SES_Deelscore_welvaart\",\n    \"SES_Totaalscore\",\n    \"SUC_Retentie\",\n    \"VOP_Gemiddeld_cijfer_cijferlijst\",\n    \"VOP_Gemiddeld_eindcijfer_VO_van_de_hoogste_vooropleiding_voor_het_HO\",\n    \"VOP_Cijfer_CE1_nederlands\",\n    \"VOP_Cijfer_CE1_engels\",\n    \"VOP_Cijfer_CE_proxy_wiskunde\",\n    \"VOP_Cijfer_CE1_natuurkunde\",\n    \"VOP_Studiekeuzeprofiel_LTA_afkorting\",\n    \"VOP_Toelaatgevende_vooropleiding_soort\"\n  )\n\n## B Huidtherapie: voeg de variabele RNK_Rangnummer toe\nif(opleiding == \"HDT\") {\n  lSelect &lt;- c(lSelect, \"RNK_Rangnummer\")\n}\n\n## Maak een subset\ndfOpleiding_inschrijvingen &lt;- dfOpleiding_inschrijvingen_base |&gt;\n  \n  ## Selecteer de relevante variabelen\n  select_at(lSelect) |&gt;\n  \n  ## Hernoem variabelen voor beter leesbare namen\n  rename(\n    ID                    = INS_Student_UUID_opleiding_vorm,\n    Geslacht              = DEM_Geslacht,\n    Leeftijd              = DEM_Leeftijd_1_oktober,\n    Reistijd              = GIS_Tijd_fiets_OV,\n    Dubbele_studie        = INS_Dubbele_studie,\n    Collegejaar           = INS_Collegejaar,\n    Aanmelding            = INS_Dagen_tussen_aanmelding_en_1_september,\n    Aansluiting           = INS_Aansluiting_LTA,\n    APCG                  = CBS_APCG_tf,\n    SES_Arbeid            = SES_Deelscore_arbeid,\n    SES_Welvaart          = SES_Deelscore_welvaart,\n    SES_Totaal            = SES_Totaalscore,          \n    Retentie              = SUC_Retentie,\n    Cijfer_SE_VO          = VOP_Gemiddeld_cijfer_cijferlijst,\n    Cijfer_CE_VO          = VOP_Gemiddeld_eindcijfer_VO_van_de_hoogste_vooropleiding_voor_het_HO,\n    Cijfer_CE_Nederlands  = VOP_Cijfer_CE1_nederlands,\n    Cijfer_CE_Engels      = VOP_Cijfer_CE1_engels,\n    Cijfer_CE_Wiskunde    = VOP_Cijfer_CE_proxy_wiskunde,\n    Cijfer_CE_Natuurkunde = VOP_Cijfer_CE1_natuurkunde,\n    Studiekeuzeprofiel    = VOP_Studiekeuzeprofiel_LTA_afkorting,\n    Vooropleiding         = VOP_Toelaatgevende_vooropleiding_soort\n  ) |&gt; \n  \n  ## Pas CBS_APCG_tf aan naar factor\n  mutate(APCG = case_when(APCG == TRUE ~ \"Ja\",\n                          APCG == FALSE ~ \"Nee\",\n                          .default = \"Onbekend\")) |&gt;\n\n  ## Geef aan waar missende cijfers in het VO zijn\n  Mutate_Cijfers_VO() |&gt;\n  \n  ## Verwijder variabelen, waarbij er maar 1 waarde is\n  select(where(~ n_distinct(.) &gt; 1)) |&gt;\n  \n  arrange(Collegejaar, ID)\n\n## B Huidtherapie: hernoem de variabele RNK_Rangnummer\nif(opleiding == \"HDT\") {\n  dfOpleiding_inschrijvingen &lt;- dfOpleiding_inschrijvingen |&gt; \n    rename(Rangnummer = RNK_Rangnummer)\n} \n\ndfOpleiding_inschrijvingen &lt;- dfOpleiding_inschrijvingen |&gt; \n ltabase::sort_distinct()\n\n## Verwijder de basis dataset\n## rm(dfOpleiding_inschrijvingen_base)\n\n\n\n\n\nTabel 1.2: Variabelen in relatie tot de uitkomstmaat: params$succes\n\n\n Retentie VariabeleJa, N=1002 (62%)1Nee, N=611 (38%)1p-value2q-value3Totaal, N = 16131Aanmelding135,80 (62,44)112,36 (68,57)&lt;0,001&lt;0,001***126,92 (65,80)Aansluiting&lt;0,0010,012***2e Studie6 (40%)9 (60%)15 (100%)Direct455 (60%)301 (40%)756 (100%)Na CD14 (74%)5 (26%)19 (100%)Onbekend0 (NA%)0 (NA%)0 (NA%)Overig0 (NA%)0 (NA%)0 (NA%)Switch extern254 (57%)191 (43%)445 (100%)Switch intern148 (73%)54 (27%)202 (100%)Tussenjaar125 (71%)51 (29%)176 (100%)APCG&lt;0,0010,013***Ja224 (63%)133 (37%)357 (100%)Nee721 (64%)411 (36%)1.132 (100%)Onbekend57 (46%)67 (54%)124 (100%)Cijfer_CE_Engels6,93 (1,18)7,07 (1,10)0,16&gt;0,996,98 (1,15)Cijfer_CE_Engels_missing0,70&gt;0,99Ja533 (62%)331 (38%)864 (100%)Nee469 (63%)280 (37%)749 (100%)Cijfer_CE_Natuurkunde6,18 (0,96)6,31 (0,95)0,21&gt;0,996,23 (0,95)Cijfer_CE_Natuurkunde_missing0,68&gt;0,99Ja867 (62%)533 (38%)1.400 (100%)Nee135 (63%)78 (37%)213 (100%)Cijfer_CE_Nederlands5,94 (0,85)5,96 (0,91)0,86&gt;0,995,95 (0,87)Cijfer_CE_Nederlands_missing0,61&gt;0,99Ja533 (62%)333 (38%)866 (100%)Nee469 (63%)278 (37%)747 (100%)Cijfer_CE_VO6,46 (0,37)6,35 (0,34)&lt;0,001&lt;0,001***6,42 (0,36)Cijfer_CE_VO_missing0,59&gt;0,99Ja488 (61%)306 (39%)794 (100%)Nee514 (63%)305 (37%)819 (100%)Cijfer_CE_Wiskunde6,35 (1,12)6,28 (1,07)0,65&gt;0,996,33 (1,10)Cijfer_CE_Wiskunde_missing0,64&gt;0,99Ja544 (62%)339 (38%)883 (100%)Nee458 (63%)272 (37%)730 (100%)Cijfer_SE_VO6,46 (0,38)6,35 (0,36)&lt;0,001&lt;0,001***6,42 (0,38)Cijfer_SE_VO_missing0,59&gt;0,99Ja501 (61%)314 (39%)815 (100%)Nee501 (63%)297 (37%)798 (100%)Dubbele_studie&lt;0,001&lt;0,001***Ja12 (26%)34 (74%)46 (100%)Nee990 (63%)577 (37%)1.567 (100%)Geslacht&lt;0,001&lt;0,001***M521 (57%)394 (43%)915 (100%)V481 (69%)217 (31%)698 (100%)Leeftijd20,01 (2,26)20,19 (2,61)0,48&gt;0,9920,08 (2,40)Reistijd37,01 (18,38)38,84 (22,79)0,79&gt;0,9937,70 (20,17)SES_Arbeid0,01 (0,08)0,01 (0,08)0,57&gt;0,990,01 (0,08)SES_Totaal0,02 (0,28)0,01 (0,27)0,45&gt;0,990,02 (0,28)SES_Welvaart0,01 (0,13)0,01 (0,13)0,36&gt;0,990,01 (0,13)Studiekeuzeprofiel0,057&gt;0,99AHO2 (67%)1 (33%)3 (100%)ALG0 (0%)1 (100%)1 (100%)CERT1 (100%)0 (0%)1 (100%)CM78 (72%)30 (28%)108 (100%)EA36 (67%)18 (33%)54 (100%)EM118 (56%)93 (44%)211 (100%)EM&CM152 (70%)66 (30%)218 (100%)HB8 (62%)5 (38%)13 (100%)HO27 (57%)20 (43%)47 (100%)ICT82 (64%)47 (36%)129 (100%)MedV132 (65%)72 (35%)204 (100%)NG115 (63%)68 (37%)183 (100%)NT56 (60%)38 (40%)94 (100%)NT&NG62 (60%)41 (40%)103 (100%)Onbekend90 (52%)83 (48%)173 (100%)TP2 (40%)3 (60%)5 (100%)TR5 (56%)4 (44%)9 (100%)TSL4 (80%)1 (20%)5 (100%)VNL8 (80%)2 (20%)10 (100%)VS1 (33%)2 (67%)3 (100%)ZW23 (59%)16 (41%)39 (100%)Vooropleiding0,0110,26*BD42 (46%)50 (54%)92 (100%)CD21 (70%)9 (30%)30 (100%)HAVO548 (64%)312 (36%)860 (100%)HO27 (53%)24 (47%)51 (100%)MBO330 (63%)192 (37%)522 (100%)Overig0 (NA%)0 (NA%)0 (NA%)VWO34 (59%)24 (41%)58 (100%)1Mean (SD); n (%)2Wilcoxon rank sum test; Fisher's Exact Test for Count Data with simulated p-value  (based on 2000 replicates); Pearson's Chi-squared test3*p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n\n\n\nToon code\n## Laad dlookr\nsuppressMessages(library(dlookr))\n\n## Toon een samenvatting van de data, gesorteerd op missende waarden\ndiagnose(dfOpleiding_inschrijvingen) |&gt; \n  mutate(missing_percent = round(missing_percent, 2),\n         unique_rate = round(missing_percent, 2)) |&gt;\n  arrange(desc(missing_percent)) |&gt;\n  knitr::kable(col.names = c(\"Variabelen\",\n                           \"Type\",\n                           \"# Missende waarden\",\n                           \"% Missende waarden\",\n                           \"# Unieke waarden\",\n                           \"Ratio unieke waarden\"))\n## Verwijder dlookr\ndetach(\"package:dlookr\", unload = TRUE)\n\n\n\n\nTabel 1.3: Kwaliteit van de data voor bewerkingen (gesorteerd op missende waarden)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabelen\nType\n# Missende waarden\n% Missende waarden\n# Unieke waarden\nRatio unieke waarden\n\n\n\n\nCijfer_CE_Natuurkunde\nnumeric\n1400\n86.79\n42\n86.79\n\n\nCijfer_CE_Wiskunde\nnumeric\n883\n54.74\n56\n54.74\n\n\nCijfer_CE_Nederlands\nnumeric\n866\n53.69\n45\n53.69\n\n\nCijfer_CE_Engels\nnumeric\n864\n53.56\n57\n53.56\n\n\nCijfer_SE_VO\nnumeric\n815\n50.53\n23\n50.53\n\n\nCijfer_CE_VO\nnumeric\n794\n49.23\n23\n49.23\n\n\nStudiekeuzeprofiel\nfactor\n173\n10.73\n21\n10.73\n\n\nSES_Welvaart\nnumeric\n126\n7.81\n355\n7.81\n\n\nSES_Arbeid\nnumeric\n125\n7.75\n261\n7.75\n\n\nSES_Totaal\nnumeric\n125\n7.75\n459\n7.75\n\n\nReistijd\nnumeric\n20\n1.24\n362\n1.24\n\n\nAanmelding\nnumeric\n0\n0.00\n266\n0.00\n\n\nAansluiting\nfactor\n0\n0.00\n6\n0.00\n\n\nAPCG\ncharacter\n0\n0.00\n3\n0.00\n\n\nCijfer_CE_Engels_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_Natuurkunde_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_Nederlands_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_VO_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_Wiskunde_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_SE_VO_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCollegejaar\nnumeric\n0\n0.00\n11\n0.00\n\n\nDubbele_studie\ncharacter\n0\n0.00\n2\n0.00\n\n\nGeslacht\nfactor\n0\n0.00\n2\n0.00\n\n\nID\ncharacter\n0\n0.00\n1613\n0.00\n\n\nLeeftijd\nnumeric\n0\n0.00\n17\n0.00\n\n\nRetentie\nfactor\n0\n0.00\n2\n0.00\n\n\nVooropleiding\nfactor\n0\n0.00\n6\n0.00\n\n\n\n\n\n\n\n\n\n\n1.2.3 Bewerk de data\n\nUit de eerste diagnose blijkt dat niet alle variabelen goed genoeg zijn voor het bouwen van een prognosemodel: er zijn missende waarden en niet alle veldtypes zijn geschikt.\nOm bias te voorkomen verwijderen we geen rijen met missende waarden, maar vullen die op (imputatie). We bewerken de data zo dat alle missende waarden worden opgevuld: bij numerieke waarden met het gemiddelde en bij categorische variabelen met ‘Onbekend’.\nWe passen het type van sommige variabelen aan, zodat ze in het model gebruikt kunnen worden: tekstvelden zetten we om naar factor (een categorische variabele); logische variabelen (Ja/Nee) zetten we om naar een numerieke variabele (1/0).\nDe uitkomstvariabele, Retentie, leiden we af van de variabele SUC_Uitval_aantal_jaar_LTA. Als de waarde daar 1 is, is de student na 1 jaar uitgevallen, 2 na 2 jaar, etc. Zolang de waarde daar 0 is, is de student niet uitgevallen.\nEen fictief studentnummer (INS_Student_UUID_opleiding_vorm) gebruiken we, zodat we - als er afwijkende resultaten zijn - de dataset gericht kunnen onderzoeken als dat nodig is.\n\n\n\nToon code\n## Bewerk de data\ndfOpleiding_inschrijvingen &lt;- dfOpleiding_inschrijvingen |&gt; \n  \n  ## Imputeer alle numerieke variabelen met de mean\n  mutate(across(where(is.numeric), ~ ifelse(\n    is.na(.x),\n    mean(.x, na.rm = T),\n    .x\n  )) ) |&gt;\n  \n  ## Zet character variabelen om naar factor\n  mutate(across(where(is.character), as.factor)) |&gt; \n  \n  ## Zet logische variabelen om naar 0 of 1\n  mutate(across(where(is.logical), as.integer)) |&gt;\n  \n  ## Vul in factoren missende waarden op met \"Onbekend\"\n  mutate(across(where(is.factor), ~ suppressWarnings(\n    fct_explicit_na(.x, na_level = \"Onbekend\")\n  ))) |&gt; \n  \n  ## Herschik de kolommen, zodat Retentie vooraan staat\n  select(Retentie, everything()) \n\n## Bekijk de data\n## glimpse(dfOpleiding_inschrijvingen) \n\n## Laad dlookr\nsuppressMessages(library(dlookr))\n\n## Maak een diagnose van de data\ndiagnose(dfOpleiding_inschrijvingen) |&gt; \n  mutate(missing_percent = round(missing_percent, 2),\n         unique_rate = round(unique_rate, 2)) |&gt;\n  knitr::kable(col.names = c(\"Variabelen\",\n                           \"Type\",\n                           \"# Missende waarden\",\n                           \"% Missende waarden\",\n                           \"# Unieke waarden\",\n                           \"Ratio unieke waarden\"))\ndetach(\"package:dlookr\", unload = TRUE)\n\n\n\n\nTabel 1.4: Kwaliteit van de data na bewerkingen (gesorteerd op missende waarden)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabelen\nType\n# Missende waarden\n% Missende waarden\n# Unieke waarden\nRatio unieke waarden\n\n\n\n\nRetentie\nfactor\n0\n0\n2\n0.00\n\n\nAanmelding\nnumeric\n0\n0\n266\n0.16\n\n\nAansluiting\nfactor\n0\n0\n6\n0.00\n\n\nAPCG\nfactor\n0\n0\n3\n0.00\n\n\nCijfer_CE_Engels\nnumeric\n0\n0\n57\n0.04\n\n\nCijfer_CE_Engels_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_Natuurkunde\nnumeric\n0\n0\n42\n0.03\n\n\nCijfer_CE_Natuurkunde_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_Nederlands\nnumeric\n0\n0\n45\n0.03\n\n\nCijfer_CE_Nederlands_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_VO\nnumeric\n0\n0\n23\n0.01\n\n\nCijfer_CE_VO_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_Wiskunde\nnumeric\n0\n0\n56\n0.03\n\n\nCijfer_CE_Wiskunde_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_SE_VO\nnumeric\n0\n0\n23\n0.01\n\n\nCijfer_SE_VO_missing\nfactor\n0\n0\n2\n0.00\n\n\nCollegejaar\nnumeric\n0\n0\n11\n0.01\n\n\nDubbele_studie\nfactor\n0\n0\n2\n0.00\n\n\nGeslacht\nfactor\n0\n0\n2\n0.00\n\n\nID\nfactor\n0\n0\n1613\n1.00\n\n\nLeeftijd\nnumeric\n0\n0\n17\n0.01\n\n\nReistijd\nnumeric\n0\n0\n362\n0.22\n\n\nSES_Arbeid\nnumeric\n0\n0\n261\n0.16\n\n\nSES_Totaal\nnumeric\n0\n0\n459\n0.28\n\n\nSES_Welvaart\nnumeric\n0\n0\n355\n0.22\n\n\nStudiekeuzeprofiel\nfactor\n0\n0\n21\n0.01\n\n\nVooropleiding\nfactor\n0\n0\n6\n0.00\n\n\n\n\n\n\n\n\n\n\n1.2.4 Bekijk de onderlinge correlaties\nHet is verstandig om voorafgaand aan het bouwen van een model te kijken naar de onderlinge correlaties tussen numerieke variabelen. Dit geeft inzicht in de data en kan helpen bij het maken van keuzes voor het model of de duiding van de uitkomsten.\n\n\nToon code\n## Maak een plot van de onderlinge correlaties in numerieke variabelen\n## Verwijder de kolommen met een standaarddeviatie van 0\ndfOpleiding_inschrijvingen |&gt; \n  select(-Collegejaar) |&gt;\n  select(where(is.numeric)) |&gt; \n  select_if(~ sd(.) != 0) |&gt;\n  cor() |&gt; \n  corrplot::corrplot(\n    order = 'hclust', \n    addrect = 4,\n    method = \"number\",  \n    tl.cex = 0.8,       \n    tl.col = \"black\",\n    diag = FALSE)\n\n\n\n\n\n\n\n\nFiguur 1.1: Correlatiematrix\n\n\n\n\n\n\n\n1.2.5 Bouw de trainingset, validatieset en testset\n\nDe data is nu geschikt om een prognosemodel mee te bouwen.\nOm het model te bouwen, testen en valideren, splitsen we de data in drie delen van 60%, 20% en 20%. We doen dit op zo’n manier, dat elk deel ongeveer een gelijk aantal studenten bevat dat doorstudeert (dus niet uitvalt).\nWe trainen het model op basis van 60% en valideren de modellen tijdens het trainen op de overige 20% (de validatieset).\nDe verdeling van de training- en validatieset muteren we 10x (10 folds) om te voorkomen dat het model te veel leert van de trainingset en daardoor slecht presteert op de validatieset.\nAls het model klaar is, testen we het op de 20% studenten uit de testset. De testset blijft dus de gehele tijd ongemoeid, zodat we overfitting - een te goed model op bekende data, maar slechte presetaties (performance) op onbekende data - voorkomen.\nEen willekeurig, maar vaststaand seed-getal voorkomt dat we bij elke run van het model c.q. deze code een net iets andere uitkomst krijgen.\n\n\n\nToon code\nknitr::include_graphics(here::here(\"01_Includes/img\", \"voorspelmodel-dataset-lta-hhs.png\"))\n\n\n\n\n\n\n\n\nFiguur 1.2: Splitsing van de dataset in trainingset, validatieset en testset\n\n\n\n\n\n\n\nToon code\nset.seed(0821)\n\n## Splits de data in 3 delen: 60%, 20% en 20%\nsplits      &lt;- initial_validation_split(dfOpleiding_inschrijvingen,\n                                        strata = Retentie,\n                                        prop = c(0.6, 0.2))\n\n## Maak drie sets: een trainingset, een testset en een validatieset\ndfRetentie_train      &lt;- training(splits)\ndfRetentie_test       &lt;- testing(splits)\ndfRetentie_validation &lt;- validation_set(splits)\n\n## Maak een resample set op basis van 10 folds (default)\ndfRetentie_resamples  &lt;- vfold_cv(dfRetentie_train, strata = Retentie)\n\n\n\n\n\n\nTabel 1.5: Verhouding van de uitkomstvariabele in de training- en testset\n\n\n\n\n\n\nNaam\nRetentie\nAantal\nProportie\n\n\n\n\nTrainingset\nFALSE\n366\n37.8%\n\n\nTrainingset\nTRUE\n601\n62.2%\n\n\nTestset\nFALSE\n123\n38.0%\n\n\nTestset\nTRUE\n201\n62.0%",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html#model-i-logistische-regressie",
    "href": "lta-hhs-tidymodels-h1-basis.html#model-i-logistische-regressie",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "1.3 Model I: Logistische Regressie",
    "text": "1.3 Model I: Logistische Regressie\n\nHet eerste model is een logistische regressie met penalized likelihood; we gebruiken de glmnet engine voor het bouwen van het model. Penalized likelihood is een techniek die helpt bij het voorkomen van overfitting: het voegt voor elke extra variabele een strafterm toe om eenvoudige modellen te belonen. Glmnet is een veelgebruikt package voor het bouwen van logistische regressiemodellen.\nWe gebruiken de Area under the ROC Curve (AUC/ROC) als performance metric. De ROC-curve (Receiver Operating Characteristic) is een grafiek die de prestaties van een classificatiemodel afbeeldt door de verhouding tussen de true positives (sensitiviteit) en de false positives (aspecficiteit = 1-specificiteit) te plotten bij verschillende drempelwaarden. De oppervlakte onder deze curve, bekend als de AUC (Area Under the Curve), kwantificeert het onderscheidingsvermogen van het model; een AUC van 1 duidt op een perfect onderscheidend vermogen, terwijl een AUC van 0,5 wijst op een model zonder onderscheidend vermogen.\n\n\n1.3.1 Maak het model\nEerst bouwen we het model.\n\n## Bouw het model: logistische regressie\nlr_mod &lt;- \n  logistic_reg(penalty = tune(), mixture = 1) |&gt; \n  set_engine(\"glmnet\")\n\n\n\n1.3.2 Maak de recipe\nVervolgens zetten we meerdere stappen in een ‘recipe’:\n\nWe definiëren de student-ID als ID variabele. Daarmee krijgt deze variabele de rol van uniek rij-kenmerk.\nWe verwijderen vervolgens de oorspronkelijke student-ID en het collegejaar uit de data, omdat deze verder niet gebruikt moeten worden in het model.\nWe converteren factoren naar dummy variabelen: voor elke categorie wordt er een nieuwe logische variabele (Ja/Nee) aangemaakt.\nWe verwijderen variabelen die geen waarde toevoegen: variabelen met uitsluitend nullen.\nWe normaliseren numerieke variabelen om ze met elkaar te kunnen vergelijken door ze te centreren en schalen.\nSterk gecorreleerde waarden verwijderen we nu niet, omdat we later in de analyse de eventuele samenhang met andere variabelen in een prognosemodel nog willen kunnen visualiseren.\n\n\n## Bouw de recipe: logistische regressie\nlr_recipe &lt;- \n  recipe(Retentie ~ ., data = dfRetentie_train) |&gt;  \n  update_role(ID, new_role = \"ID\") |&gt;           ## Zet de student ID als ID variabele\n  step_rm(ID, Collegejaar) |&gt;                   ## Verwijder ID en collegejaar uit het model\n  step_dummy(all_nominal_predictors()) |&gt;       ## Maak dummy variabelen van categorische variabelen\n  step_zv(all_predictors()) |&gt;                  ## Verwijder zero values\n  step_normalize(all_numeric_predictors())      ## Centreer en schaal numerieke variabelen\n\n\n\nToon code\n## Toon de recipe\ntidy(lr_recipe) |&gt; \n  knitr::kable(col.names = c(\"Nummer\", \n                             \"Operatie\", \n                             \"Type\",\n                             \"Getraind\",\n                             \"Sla over\",\n                             \"ID\"))\n\n\n\n\nTabel 1.6: Recipesteps voor logistische regressie\n\n\n\n\n\n\nNummer\nOperatie\nType\nGetraind\nSla over\nID\n\n\n\n\n1\nstep\nrm\nFALSE\nFALSE\nrm_KV8Lp\n\n\n2\nstep\ndummy\nFALSE\nFALSE\ndummy_bUMsj\n\n\n3\nstep\nzv\nFALSE\nFALSE\nzv_beaLb\n\n\n4\nstep\nnormalize\nFALSE\nFALSE\nnormalize_3WTmw\n\n\n\n\n\n\n\n\nDe variabelen die nu nog overblijven zijn:\n\n\n\n\nTabel 1.7: Resterende variabelen voor logistische regressie na bewerkingen\n\n\n\n\n\n\n\n\n\n\n\nAanmelding\nAPCG_Nee\nStudiekeuzeprofiel_MedV\n\n\nCijfer_CE_Engels\nAPCG_Onbekend\nStudiekeuzeprofiel_NG\n\n\nCijfer_CE_Natuurkunde\nCijfer_CE_Engels_missing_Nee\nStudiekeuzeprofiel_NT\n\n\nCijfer_CE_Nederlands\nCijfer_CE_Natuurkunde_missing_Nee\nStudiekeuzeprofiel_NT.NG\n\n\nCijfer_CE_VO\nCijfer_CE_Nederlands_missing_Nee\nStudiekeuzeprofiel_Onbekend\n\n\nCijfer_CE_Wiskunde\nCijfer_CE_VO_missing_Nee\nStudiekeuzeprofiel_TP\n\n\nCijfer_SE_VO\nCijfer_CE_Wiskunde_missing_Nee\nStudiekeuzeprofiel_TR\n\n\nLeeftijd\nCijfer_SE_VO_missing_Nee\nStudiekeuzeprofiel_TSL\n\n\nReistijd\nDubbele_studie_Nee\nStudiekeuzeprofiel_VNL\n\n\nSES_Arbeid\nGeslacht_V\nStudiekeuzeprofiel_VS\n\n\nSES_Totaal\nStudiekeuzeprofiel_ALG\nStudiekeuzeprofiel_ZW\n\n\nSES_Welvaart\nStudiekeuzeprofiel_CM\nVooropleiding_CD\n\n\nRetentie\nStudiekeuzeprofiel_EA\nVooropleiding_HAVO\n\n\nAansluiting_Direct\nStudiekeuzeprofiel_EM\nVooropleiding_HO\n\n\nAansluiting_Na.CD\nStudiekeuzeprofiel_EM.CM\nVooropleiding_MBO\n\n\nAansluiting_Switch.extern\nStudiekeuzeprofiel_HB\nVooropleiding_VWO\n\n\nAansluiting_Switch.intern\nStudiekeuzeprofiel_HO\n\n\n\nAansluiting_Tussenjaar\nStudiekeuzeprofiel_ICT\n\n\n\n\n\n\n\n\n\n\n\n1.3.3 Maak de workflow\nVoor de uitvoering bouwen we een workflow. Daaraan voegen we het model en de bewerkingen in de recipe toe.\n\n## Maak de workflow: logistische regressie\nlr_workflow &lt;- \n  workflow() |&gt;         ## Maak een workflow\n  add_model(lr_mod) |&gt;  ## Voeg het model toe\n  add_recipe(lr_recipe) ## Voeg de recipe toe\n\n## Toon de workflow\nlr_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\n1.3.4 Tune en train het model\nHet model moet getuned worden. Dit houdt in dat we de beste parameters voor het model moeten vinden. We maken een grid met verschillende penalty waarden. Daarmee kunnen we vervolgens het beste model selecteren met de hoogste ROC/AUC. We plotten de resultaten van de tuning, zodat we hieruit het beste model kunnen kiezen.\n\n## Maak een grid: logistische regressie\nlr_reg_grid &lt;- tibble(penalty = 10 ^ seq(-4, -1, length.out = 30))\n\n## Train en tune het model: logistische regressie\nlr_res &lt;- \n  lr_workflow |&gt; \n  tune_grid(dfRetentie_validation,\n            grid = lr_reg_grid,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n\n\n\nToon code\n## Plot de resultaten + een rode verticale lijn voor de max AUC\nlr_plot &lt;- \n  lr_res |&gt; \n  collect_metrics() |&gt; \n  ggplot(aes(x = penalty, y = mean)) + \n  geom_point() + \n  geom_line() + \n  \n  ## Maak de schaal van de x-as logaritmisch\n  scale_x_log10(labels = scales::label_number()) +\n    theme(\n      axis.title.x = element_text(margin = margin(t = 20))\n    ) +\n  \n  # Bepaal de titel, ondertitel en caption\n  labs(\n    caption = sCaption,\n    x = \"Area under the ROC Curve\",\n    y = \"Penalty\"\n  )\n  \n  ## Voeg LTA elementen toe\n  lr_plot &lt;- Add_LTA_Theme_Elements(lr_plot, title_subtitle = FALSE)\n  \n# Zoek de penalty waarde met de max AUC\nmax_auc_penalty &lt;- lr_res |&gt; \n  collect_metrics() |&gt; \n  filter(mean == max(mean)) |&gt; \n  pull(penalty)\n\n# Voeg de rode verticale lijn toe aan lr_plot\nlr_plot_plus &lt;- lr_plot + \n  geom_vline(xintercept = max_auc_penalty, color = \"red\")\n\n# Vind een mean voor de max AUC die hoger is\nmax_auc_mean &lt;- lr_res |&gt; \n  collect_metrics() |&gt; \n  filter(mean == max(mean)) |&gt; \n  pull(penalty)\n\n## Print de definitieve plot\nlr_plot_plus\n\n\n\n\n\n\n\n\nFiguur 1.3: Tuning resultaten logistische regressie\n\n\n\n\n\n\n\n1.3.5 Kies het beste model\nDe prestaties van een model gevisualiseerd met behulp van een ROC curve. De sensitiviteit (True Positive Rate) en specificiteit (True Negative Rate) worden hierin tegenover elkaar uitgezet. De Area under the ROC Curve (AUC/ROC) geeft de prestaties van het model weer. Het model scoort beter naarmate de AUC/ROC dichter bij de 1 ligt, de linker bovenhoek. De linker bovenhoek houdt in dat alle prognoses exact overeenstemmen met de werkelijkheid. Een AUC/ROC van 0,5 betekent dat het model niet beter presteert dan een willekeurige voorspelling.\nWe gebruiken modellen met een zo hoog mogelijke Area under the ROC Curve (AUC/ROC) en een zo laag mogelijke penalty. Zo kunnen we uit de resultaten het beste model kiezen en visualiseren.\n\n## Toon het beste model\ntop_models &lt;-\n  lr_res |&gt; \n  show_best(metric = \"roc_auc\", n = 10) |&gt; \n  mutate(mean = round(mean, 6)) |&gt;\n  arrange(penalty) \n\n\n\nToon code\ntop_models|&gt; \n  knitr::kable(col.names = c(\"Penalty\", \n                             \"Metriek\", \n                             \"Estimator\",\n                             \"Gemiddelde\",\n                             \"Aantal\",\n                             \"SE\",\n                             \"Configuratie\"))\n\n\n\n\nTabel 1.8: Model performance voor logistische regressie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPenalty\nMetriek\nEstimator\nGemiddelde\nAantal\nSE\nConfiguratie\n\n\n\n\n0.0017433\nroc_auc\nbinary\n0.668279\n1\nNA\nPreprocessor1_Model13\n\n\n0.0022122\nroc_auc\nbinary\n0.670205\n1\nNA\nPreprocessor1_Model14\n\n\n0.0028072\nroc_auc\nbinary\n0.670820\n1\nNA\nPreprocessor1_Model15\n\n\n0.0035622\nroc_auc\nbinary\n0.672172\n1\nNA\nPreprocessor1_Model16\n\n\n0.0045204\nroc_auc\nbinary\n0.673934\n1\nNA\nPreprocessor1_Model17\n\n\n0.0057362\nroc_auc\nbinary\n0.675369\n1\nNA\nPreprocessor1_Model18\n\n\n0.0072790\nroc_auc\nbinary\n0.676967\n1\nNA\nPreprocessor1_Model19\n\n\n0.0092367\nroc_auc\nbinary\n0.678934\n1\nNA\nPreprocessor1_Model20\n\n\n0.0117210\nroc_auc\nbinary\n0.677336\n1\nNA\nPreprocessor1_Model21\n\n\n0.0148735\nroc_auc\nbinary\n0.669262\n1\nNA\nPreprocessor1_Model22\n\n\n\n\n\n\n\n\n\n## Selecteer het beste model: logistische regressie\nlr_best &lt;- \n  lr_res |&gt; \n  collect_metrics() |&gt; \n  filter(mean == max(mean)) |&gt;\n  slice(1) \n\n\n\nToon code\nlr_best|&gt; \n  mutate(mean = round(mean, 6)) |&gt;\n  knitr::kable(col.names = c(\"Penalty\", \n                             \"Metriek\", \n                             \"Estimator\",\n                             \"Gemiddelde\",\n                             \"Aantal\",\n                             \"SE\",\n                             \"Configuratie\"))\n\n\n\n\nTabel 1.9: Hoogste model performance voor logistische regressie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPenalty\nMetriek\nEstimator\nGemiddelde\nAantal\nSE\nConfiguratie\n\n\n\n\n0.0092367\nroc_auc\nbinary\n0.678934\n1\nNA\nPreprocessor1_Model20\n\n\n\n\n\n\n\n\n\n## Verzamel de predicties en evalueer het model (AUC/ROC): logistische regressie\nlr_auc &lt;- \n  lr_res |&gt; \n  collect_predictions(parameters = lr_best) |&gt; \n  roc_curve(Retentie, .pred_FALSE) |&gt; \n  mutate(model = \"Logistisch Regressie\")\n\n\n\nToon code\n## Plot de ROC curve\nGet_ROC_Plot(lr_auc, position = 1)\n\n\n\n\n\n\n\n\nFiguur 1.4: ROC curve voor logistische regressie\n\n\n\n\n\n\n\nToon code\n## Bepaal de AUC van het beste model\nlr_auc_highest   &lt;-\n  lr_res |&gt;\n  collect_predictions(parameters = lr_best) |&gt; \n  roc_auc(Retentie, .pred_FALSE)\n\n## Voeg de naam van het model en de AUC toe dfModel_results\ndfModel_results &lt;- \n  dfModel_results |&gt;\n  add_row(model = \"Logistic Regression\", auc = lr_auc_highest$.estimate)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html#model-ii-tree-based-ensemble",
    "href": "lta-hhs-tidymodels-h1-basis.html#model-ii-tree-based-ensemble",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "1.4 Model II: Tree-based ensemble",
    "text": "1.4 Model II: Tree-based ensemble\n\nHet tweede model is een random forest: een ensemble van beslisbomen (decision trees). Het is een krachtig model dat goed om kan gaan met complexe data en veel variabelen.\nWe gebruiken de ranger engine voor het bouwen van het model.\n\n\n1.4.1 Bepaal het aantal PC-cores\nOmdat een random forest model veel berekeningen vereist, willen we daarvoor alle computerkracht gebruiken die beschikbaar is. Het aantal CPU’s (cores), wat verschilt per computer, bepaalt hoe snel het model getraind kan worden. We bepalen het aantal cores en gebruiken dat bij het bouwen van het model.\n\n\nToon code\n## Bepaal het aantal cores\ncores &lt;- parallel::detectCores()\n\n\n\n\n1.4.2 Maak het model\nWe bouwen eerst het model. We gebruiken de rand_forest functie om het model te bouwen. We tunen de mtry en min_n parameters. De mtry parameter bepaalt het aantal variabelen dat per boom wordt gebruikt. De min_n parameter bepaalt het minimum aantal observaties dat in een blad van de boom moet zitten. De functie tune() is hier nog een placeholder om de beste waarden voor deze parameters - die we later bepalen - in te kunnen stellen. We gebruiken 1.000 bomen c.q. versies van het model.\n\n## Bouw het model: random forest\n\nrf_mod &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) |&gt; \n  set_engine(\"ranger\", num.threads = cores) |&gt; \n  set_mode(\"classification\")\n\n\n\n1.4.3 Maak de recipe\nWe maken een recipe voor het random forest model. We verwijderen de student ID en het collegejaar uit de data, omdat deze niet moet worden gebruikt in het model. Overige stappen zijn bij een random forest minder relevant in tegenstelling tot een regressiemodel.\n\n## Maak de recipe: random forest\nrf_recipe &lt;- \n  recipe(Retentie ~ ., data = dfRetentie_train) |&gt; \n  step_rm(ID, Collegejaar)                      ## Verwijder ID en Collegejaar uit het model\n\n\n\nToon code\n## Toon de recipe\ntidy(rf_recipe) |&gt; \n  knitr::kable(col.names = c(\"Nummer\", \n                             \"Operatie\", \n                             \"Type\",\n                             \"Getraind\",\n                             \"Sla over\",\n                             \"ID\"))\n\n\n\n\nTabel 1.10: Recipesteps voor random forest\n\n\n\n\n\n\nNummer\nOperatie\nType\nGetraind\nSla over\nID\n\n\n\n\n1\nstep\nrm\nFALSE\nFALSE\nrm_HCcZp\n\n\n\n\n\n\n\n\n\n\n1.4.4 Maak de workflow\nWe voegen het model en de recipe toe aan de workflow voor dit model.\n\n## Maak de workflow: random forest\nrf_workflow &lt;- \n  workflow() |&gt; \n  add_model(rf_mod) |&gt; \n  add_recipe(rf_recipe)\n\n## Toon de workflow\nrf_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_rm()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: ranger \n\n\n\n\n1.4.5 Tune en train het model\nWe trainen en tunen het model in de workflow. We maken een grid met verschillende waarden voor de parameters mtry en min_n. We gebruiken de Area under the ROC Curve (AUC/ROC) als performance metric. Met de resultaten van de tuning kiezen we het beste model.\n\n## Toon de parameters die getuned kunnen worden\nrf_mod\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: ranger \n\n## Extraheer de parameters die getuned worden\nextract_parameter_set_dials(rf_mod)\n\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n\n## Bepaal de seed\nset.seed(2904)\n\n## Bouw het grid: random forest\nrf_res &lt;- \n  rf_workflow |&gt; \n  tune_grid(dfRetentie_validation,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n\n\n1.4.6 Kies het beste model\nWe evalueren de beste modellen en maken een ROC curve om de performance van het model te visualiseren. Vervolgens vergelijken we de prestaties van de modellen en kiezen daaruit het beste model.\n\n## Toon de beste modellen\nrf_res |&gt; \n  show_best(metric = \"roc_auc\", n = 15) |&gt; \n  mutate(mean = round(mean, 6)) |&gt;\n  knitr::kable(col.names = c(\"Mtry\", \n                             \"Min. aantal\", \n                             \"Metriek\",\n                             \"Estimator\",\n                             \"Gemiddelde\",\n                             \"Aantal\",\n                             \"SE\",\n                             \"Configuratie\"))\n\n\n\nTabel 1.11: Model performance voor random forest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMtry\nMin. aantal\nMetriek\nEstimator\nGemiddelde\nAantal\nSE\nConfiguratie\n\n\n\n\n2\n6\nroc_auc\nbinary\n0.700041\n1\nNA\nPreprocessor1_Model22\n\n\n11\n29\nroc_auc\nbinary\n0.699836\n1\nNA\nPreprocessor1_Model02\n\n\n4\n26\nroc_auc\nbinary\n0.699385\n1\nNA\nPreprocessor1_Model23\n\n\n5\n36\nroc_auc\nbinary\n0.699344\n1\nNA\nPreprocessor1_Model09\n\n\n7\n35\nroc_auc\nbinary\n0.698074\n1\nNA\nPreprocessor1_Model14\n\n\n8\n31\nroc_auc\nbinary\n0.698033\n1\nNA\nPreprocessor1_Model24\n\n\n11\n21\nroc_auc\nbinary\n0.697951\n1\nNA\nPreprocessor1_Model15\n\n\n2\n32\nroc_auc\nbinary\n0.696434\n1\nNA\nPreprocessor1_Model03\n\n\n3\n8\nroc_auc\nbinary\n0.695492\n1\nNA\nPreprocessor1_Model08\n\n\n6\n23\nroc_auc\nbinary\n0.695246\n1\nNA\nPreprocessor1_Model17\n\n\n13\n25\nroc_auc\nbinary\n0.694262\n1\nNA\nPreprocessor1_Model25\n\n\n22\n38\nroc_auc\nbinary\n0.692295\n1\nNA\nPreprocessor1_Model01\n\n\n16\n34\nroc_auc\nbinary\n0.691926\n1\nNA\nPreprocessor1_Model07\n\n\n18\n40\nroc_auc\nbinary\n0.690369\n1\nNA\nPreprocessor1_Model16\n\n\n15\n20\nroc_auc\nbinary\n0.690287\n1\nNA\nPreprocessor1_Model20\n\n\n\n\n\n\n\n\n\n\nToon code\n## Plot de resultaten\nautoplot &lt;- autoplot(rf_res) +\n  theme_minimal() +\n  labs(\n    y = \"roc/auc\",\n    caption = sCaption\n  )\n  \n  ## Voeg LTA elementen toe\n  autoplot &lt;- Add_LTA_Theme_Elements(autoplot, title_subtitle = FALSE)\n  \n  print(autoplot)\n\n\n\n\n\n\n\n\nFiguur 1.5: Model performance random forest\n\n\n\n\n\n\n## Selecteer het beste model\nrf_best &lt;- \n  rf_res |&gt; \n  select_best(metric = \"roc_auc\")\n\n\n\nToon code\nrf_best|&gt; \n  knitr::kable(col.names = c(\"Mtry\", \n                             \"Min. aantal\", \n                             \"Configuratie\"))\n\n\n\n\nTabel 1.12: Hoogste model performance voor random forest\n\n\n\n\n\n\nMtry\nMin. aantal\nConfiguratie\n\n\n\n\n2\n6\nPreprocessor1_Model22\n\n\n\n\n\n\n\n\n\n\nToon code\n## Verzamel de predicties\nrf_res |&gt; \n  collect_predictions() |&gt; \n  head(10) |&gt;\n  mutate(.pred_FALSE = scales::percent(.pred_FALSE, accuracy = 0.1),\n         .pred_TRUE = scales::percent(.pred_TRUE, accuracy = 0.1)) |&gt;\n  knitr::kable(col.names = c(\"% Voorsp. FALSE\", \n                             \"% Voorsp. TRUE\", \n                             \"ID\",\n                             \"Rij\",\n                             \"Mtry\", \n                             \"Min. aantal\", \n                             \"Retentie\",\n                             \"Configuratie\"))\n\n\n\n\nTabel 1.13: Predicties voor random forest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n% Voorsp. FALSE\n% Voorsp. TRUE\nID\nRij\nMtry\nMin. aantal\nRetentie\nConfiguratie\n\n\n\n\n53.7%\n46.3%\nvalidation\n968\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n45.4%\n54.6%\nvalidation\n969\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n41.4%\n58.6%\nvalidation\n970\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n41.6%\n58.4%\nvalidation\n971\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n33.4%\n66.6%\nvalidation\n972\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n51.1%\n48.9%\nvalidation\n973\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n21.6%\n78.4%\nvalidation\n974\n22\n38\nFALSE\nPreprocessor1_Model01\n\n\n50.0%\n50.0%\nvalidation\n975\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n48.1%\n51.9%\nvalidation\n976\n22\n38\nFALSE\nPreprocessor1_Model01\n\n\n22.4%\n77.6%\nvalidation\n977\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n\n\n\n\n\n\n\n\nToon code\n## Bepaal de AUC/ROC curve\nrf_auc &lt;- \n  rf_res |&gt; \n  collect_predictions(parameters = rf_best) |&gt; \n  roc_curve(Retentie, .pred_FALSE) |&gt; \n  mutate(model = \"Random Forest\")\n\n## Plot de ROC curve\nGet_ROC_Plot(rf_auc, position = 2)\n\n## Bepaal de AUC van het beste model\nrf_auc_highest   &lt;-\n  rf_res |&gt;\n  collect_predictions(parameters = rf_best) |&gt; \n  roc_auc(Retentie, .pred_FALSE)\n\n## Voeg de naam van het model en de AUC toe dfModel_results\ndfModel_results &lt;- \n  dfModel_results |&gt;\n  add_row(model = \"Random Forest\", auc = rf_auc_highest$.estimate)\n\n\n\n\n\n\n\n\nFiguur 1.6: ROC curve voor random forest",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html#de-uiteindelijke-fit",
    "href": "lta-hhs-tidymodels-h1-basis.html#de-uiteindelijke-fit",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "1.5 De uiteindelijke fit",
    "text": "1.5 De uiteindelijke fit\n\nIn de laatste stap van deze analyse maken we het model definitief.\nWe testen het model op de testset en evalueren het model met metrieken en de Variable Importance (VI). De VI kwantificeert de bijdrage van elke variabele aan de voorspellende kracht van een model. Het identificeert welke variabelen significant zijn voor de modelprestaties, wat essentieel is voor het interpreteren en optimaliseren van een model (Van der Laan, 2006). Methoden zoals de Shapley-waarde en permutation importance worden vaak toegepast om dit belang te meten. Op deze methoden komen we terug in het volgende hoofdstuk.\n\n\n1.5.1 Combineer de AUC/ROC curves en kies het beste model\nEerst combineren we de AUC/ROC curves van de modellen om ze te vergelijken. We kiezen het beste model op basis van de hoogste AUC/ROC.\n\n\nToon code\n## Combineer de AUC/ROC curves om de modellen te vergelijken\nGet_ROC_Plot(list(lr_auc, rf_auc))\n\n\n\n\n\n\n\n\nFiguur 1.7: Gecombineerde ROC curves\n\n\n\n\n\n\n\nToon code\n## Bepaal welke van de modellen het beste is op basis van de hoogste AUC/ROC\ndfModel_results &lt;- dfModel_results |&gt;\n  mutate(number = row_number()) |&gt; \n  mutate(best = ifelse(auc == max(auc), TRUE, FALSE)) |&gt; \n  arrange(number)\n\n## Bepaal het beste model\nsBest_model     &lt;- dfModel_results$model[dfModel_results$best == TRUE]\nsBest_model_auc &lt;- round(dfModel_results$auc[dfModel_results$best == TRUE], 4)\n\n\nHet beste model is het Random Forest model met een AUC/ROC van 0.7. We ronden de analyse verder af met het Random Forest model.\n\n\n1.5.2 Maak het finale model\nWe maken het finale model op basis van de beste parameters die we hebben gevonden. Door in de engine bij importance de impurity op te geven, wordt het beste random forest model gekozen om de data definitief mee te classificeren.\n\n## Test het ontwikkelde model op de testset\n## Bepaal de optimale parameters\n\n## Bouw de laatste modellen\nlast_lr_mod &lt;-\n    logistic_reg(penalty = lr_best$penalty,\n                 mixture = 1) |&gt;\n    set_engine(\"glmnet\") |&gt;\n    set_mode(\"classification\")\n\nlast_rf_mod &lt;-\n    rand_forest(mtry = rf_best$mtry,\n                min_n = rf_best$min_n,\n                trees = 1000) |&gt;\n    set_engine(\"ranger\", num.threads = cores, importance = \"impurity\") |&gt;\n    set_mode(\"classification\")\n\n\n\n1.5.3 Maak de workflow\nWe voegen het model toe aan de workflow en updaten de workflow met het finale model.\n\n## Update de workflows\n last_lr_workflow &lt;- \n    lr_workflow |&gt; \n    update_model(last_lr_mod)\n\n last_rf_workflow &lt;- \n    rf_workflow |&gt; \n    update_model(last_rf_mod)\n\n\n\n1.5.4 Fit het finale model\nWe voeren de finale fit uit. De functie last_fit past het model toe op de validatieset.\n\n## Voer de laatste fit uit\nset.seed(2904)\n\n## Maak voor beide modellen een laatste fit, zodat we deze kunnen opslaan voor later gebruik\nlast_fit_lr &lt;- \n    last_lr_workflow |&gt; \n    last_fit(splits)\n\nlast_fit_rf &lt;- \n    last_rf_workflow |&gt; \n    last_fit(splits)\n\nlLast_fits &lt;- list(last_fit_lr, last_fit_rf) |&gt; \n  set_names(c(\"Logistic Regression\", \"Random Forest\"))\n\n## Bepaal welk model het beste is\nif(sBest_model == \"Logistic Regression\") {\n  last_fit &lt;- last_fit_lr\n} else if(sBest_model == \"Random Forest\") {\n  last_fit &lt;- last_fit_rf\n}\n\n## Bewaar de resultaten, de modelresultaten en de bijbehorende data\nsFittedmodels_outputpath &lt;- Get_Model_Outputpath(mode = \"last-fits\")\nsaveRDS(lLast_fits, file = sFittedmodels_outputpath)\n\nsModelresults_outputpath &lt;- Get_Model_Outputpath(mode = \"modelresults\")\nsaveRDS(dfModel_results, file = sModelresults_outputpath)\n\nsData_outputpath &lt;- Get_Model_Outputpath(mode = \"data\")\nsaveRDS(dfOpleiding_inschrijvingen, file = sData_outputpath)\n\n\n\n1.5.5 Evalueer het finale model: metrieken en variable importance\nWe evalueren het finale model op basis van 4 metrieken: 1) accuraatheid, 2) ROC/AUC en 3) de Brier score (de Mean Squared Error) en 4) de Variable Importance (VI). Uit de VI is op te maken welke variabelen het meest bijdragen aan de voorspelling van de uitkomstvariabele.\n\n## Verzamel de metrieken\nlast_fit |&gt; \n  collect_metrics() |&gt; \n  mutate(.estimate = round(.estimate, 4)) |&gt;\n  knitr::kable(col.names = c(\"Metriek\", \n                             \"Estimator\",\n                             \"Estimate\",\n                             \"Configuratie\"))\n\n\n\n\nMetriek\nEstimator\nEstimate\nConfiguratie\n\n\n\n\naccuracy\nbinary\n0.6420\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.6491\nPreprocessor1_Model1\n\n\nbrier_class\nbinary\n0.2219\nPreprocessor1_Model1\n\n\n\n\n\n\n\nToon code\n# Extraheer de feature importance\ndfVi &lt;- last_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  vip::vi() |&gt; \n  arrange(desc(Importance)) |&gt;\n  head(20)\n  \n# Maak de plot met fill op de variabele 'Importance'\nimportance_plot &lt;- dfVi |&gt; \n  ggplot(aes(x = reorder(Variable, Importance), \n             y = Importance, \n             fill = Importance)) +\n  geom_col(show.legend = FALSE) +\n  \n  ## Maak de titel en caption\n  labs(x = NULL,\n       y = \"VI-score\",\n       caption = sCaption) +\n  \n  theme_minimal() +\n  Set_LTA_Theme() +\n  \n  theme(\n    axis.title.x = element_text(margin = margin(t = 20))\n  ) +\n  \n  coord_flip()\n  \n  ## Voeg LTA elementen toe\n  importance_plot &lt;- Add_LTA_Theme_Elements(importance_plot, title_subtitle = TRUE)\n\n# Toon de plot\nprint(importance_plot)\n\n\n\n\n\n\n\n\nFiguur 1.8: Meest voorspellende factoren op basis van de Variable Importance (VI)\n\n\n\n\n\n\n\n1.5.6 Plot de ROC curve\nTot slot visualiseren we de prestaties weer met een ROC curve van het beste model.\n\n## Toon de roc curve\nauc_lf &lt;- last_fit |&gt; \n  collect_predictions() |&gt; \n  roc_curve(Retentie, .pred_FALSE) |&gt; \n  mutate(model = \"Last fit\")\n\nGet_ROC_Plot(auc_lf, position = 3)\n\n\n\n\n\n\n\nFiguur 1.9: ROC curve finale model",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html#conclusies",
    "href": "lta-hhs-tidymodels-h1-basis.html#conclusies",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "1.6 Conclusies",
    "text": "1.6 Conclusies\n\n1.6.1 Het beste prognosemodel voor deze opleiding\nHet beste prognosemodel blijkt het Random Forest model te zijn.\n\nVan de prognosemodellen die we hebben ontwikkeld om retentie na 1 jaar te voorspellen, had het Random Forest model de hoogste AUC/ROC waarde (0.7).\n\n\n\n1.6.2 Mate van accuraatheid en lift\nEen prognosemodel moet minimaal beter presteren dan een base-model om waarde op basis van accuraatheid toe te voegen. Het base-model neemt als basis de grootste klasse van de gemiddelde retentie na 1 jaar van de afgelopen jaren. Stel we zouden tegen alle studenten zeggen dat ze hun studie gaan halen, dan is de mate van accuratesse gelijk aan dit base-model. Dit base-model is dus altijd hoger dan de 50% lijn van de AUC/ROC curve, tenzij het base-model toevallig precies 50% is.\n\n\nToon code\nknitr::include_graphics(here::here(\"01_Includes/img\", \"basemodel-lift.png\"))\n\n\n\n\n\n\n\n\nFiguur 1.10: Lift afhankelijk van base-model en accuraatheid\n\n\n\n\n\nDe mate van accuraatheid van het prognosemodel is vrij laag (64.2%).\n\nBase-model: 62.12% – Voor deze opleiding berekenen we het base-model als volgt. Van alle studenten studeerde 62.12% door; 100% - 62.12% = 37.88% studeerde niet door. De grootste klasse van deze twee, 62.12%, is daarmee de accuratesse van het base-model.\nAccuratesse prognose: 64.2% – Het model voorspelt Retentie na 1 jaar met een accuratesse van 64.2%.\nLift: 2.08% – Het model scoort in de huidige opbouw met een verschil van 2.08% (de lift) iets beter dan de accuraatheid van het base-model.\n\n\n\n1.6.3 Confusion Matrix\n\n\nToon code\n## Bepaal de confusion matrix\nconfusion_matrix &lt;- last_fit |&gt;\n  collect_predictions() |&gt;\n  conf_mat(truth = Retentie, estimate = .pred_class) \n\ndfConf_matrix &lt;- as_tibble(confusion_matrix$table) |&gt;\n  rename(Werkelijkheid = Truth) |&gt;\n  mutate(Werkelijkheid = ifelse(Werkelijkheid == \"TRUE\", \"Retentie\", \"Geen retentie\"),\n         Prediction    = ifelse(Prediction == \"TRUE\", \"Retentie\", \"Geen retentie\"))\n\npTP  &lt;- Change_Number_Marks((dfConf_matrix$n[4]/sum(dfConf_matrix$n)*100),1)\npFP  &lt;- Change_Number_Marks((dfConf_matrix$n[2]/sum(dfConf_matrix$n)*100),1)\npTN  &lt;- Change_Number_Marks((dfConf_matrix$n[1]/sum(dfConf_matrix$n)*100),1)\npFN  &lt;- Change_Number_Marks((dfConf_matrix$n[3]/sum(dfConf_matrix$n)*100),1)\npACC &lt;- Change_Number_Marks(Last_fit_Accuracy,1)\n\n\nDe prestaties van het model kunnen we verder uitdrukken in een confusion matrix. Hierin zien we de voorspellingen van het model en de werkelijke uitkomsten. De matrix geeft inzicht in de mate van correcte en incorrecte voorspellingen. Ter illustratie werken we de matrix uit voor een voorspelling waarop een bindend studieadvies (BSA) gebaseerd zou kunnen zijn.\n\n\nToon code\nknitr::include_graphics(here::here(\"01_Includes/img\", \"confusion-matrix-retention-lta-hhs.png\"))\n\n\n\n\n\n\n\n\nFiguur 1.11: Confusion matrix in relatie tot BSA\n\n\n\n\n\nWe passen de confusion matrix nu toe op het model dat als beste naar voren kwam. De accuraatheid van dit model is 64,2%. De accuraatheid van het model berekenen we door de som van de diagonaal te berekenen: het aandeel goed voorspelde uitkomsten, Retentie = Retentie (True Positive) en Geen retentie = Geen retentie (True Negative), af te zetten tegen het totaal aantal voorspellingen: 57,4% + 6,8% = 64,2%. (NB. De weergave in deze confusion matrix is diagonaal gespiegeld vergeleken met het voorbeeld.)\n\n\nToon code\nconfusion_plot &lt;- plot_confusion_matrix(\n    dfConf_matrix,\n    target_col = \"Werkelijkheid\",\n    prediction_col = \"Prediction\",\n    counts_col = \"n\",\n    palette = \"Blues\",\n    add_sums = TRUE,\n    theme_fn = ggplot2::theme_light,\n    sums_settings = sum_tile_settings(\n      palette = \"Greens\",\n      label = \"Totaal\",\n      tc_tile_border_color = \"black\"\n    )) +\n    \n    ## Pas de labels aan\n    labs(\n      x = \"Werkelijke uitkost\",\n      y = \"Voorspelde uitkomst\",\n      caption = sCaption\n    ) +\n    \n    Set_LTA_Theme()\n  \n  ## Voeg LTA elementen toe\n  confusion_plot &lt;- Add_LTA_Theme_Elements(confusion_plot, \n                                           title_subtitle = TRUE)\n  \n  print(confusion_plot)\n\n\n\n\n\n\n\n\nFiguur 1.12: Confusion matrix ten opzichte van Retentie na 1 jaar\n\n\n\n\n\n\n\n1.6.4 Uitleggen of verklaren?\nNaast de accuraatheid van het model is het ook belangrijk om te weten welke factoren het meest bijdragen aan de voorspelling van retentie na 1 jaar. Daarin gaat de vergelijking met de prestaties van het basemodel mank. Dat model geeft op geen enkele manier aan waarom een student een kans op succes heeft, anders dan - ‘dit is gebruikelijk in deze opleiding’.\nOngeacht de mate van accuraatheid, is het voor onderzoek naar kansengelijkheid essentieel om te weten welke factoren het meest bijdragen aan de voorspelling van retentie na 1 jaar. Het gaat erom dat we het belang van de factoren in de voorspellingen kunnen begrijpen en duiden. Machine Learning is hiervoor uitstekend geschikt, omdat het de mogelijkheid biedt om de belangrijkste factoren en hun invloed te leren kennen (Shmueli, 2010; Shmueli & Koppius, 2011).",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h1-basis.html#vervolgstappen-factoranalyse",
    "href": "lta-hhs-tidymodels-h1-basis.html#vervolgstappen-factoranalyse",
    "title": "1  Prognosemodel Retentie na 1 jaar",
    "section": "1.7 Vervolgstappen: Factoranalyse",
    "text": "1.7 Vervolgstappen: Factoranalyse\nDe volgende stap (stap 2) is een verdiepende analyse van de mate waarin de factoren die we gevonden hebben van invloed zijn op Retentie na 1 jaar. We kijken naar de rangorde, of ze retentie na 1 jaar verhogen of juist verlagen en hoe stabiel de factoren zijn als we in andere volgordes aan het model toevoegen. Om het concreet te maken zullen we het model toepassen op een aantal fictieve studenten, die we opbouwen uit de meeste voorkomende waarden in deze opleiding. Dit is het onderwerp van analyse 2: de Factoranalyse.\n\n \nVerantwoording\nDeze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: No Fairness without Awareness | Het rapport is door het lectoraat ontwikkeld in Quarto 1.6.39. | Template versie: 0.9.1.9000\n\n \nCopyright\nDr. Theo Bakker, Lectoraat Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.\n\n\n\n\n\nBakker, T. (2022). Study Progression and Success of Autistic Students in Higher Education. A Longitudinal, Propensity Score-Weighted Population Study. https://doi.org/10.5463/thesis.1\n\n\nShmueli, G. (2010). To Explain or to Predict? Statistical Science, 25(3), 289–310. https://doi.org/10.1214/10-sts330\n\n\nShmueli, G., & Koppius, O. (2011). Predictive Analytics in Information Systems Research. MIS Quarterly, 35(3), 553. https://doi.org/10.2307/23042796\n\n\nVan der Laan, M. J. (2006). Statistical inference for variable importance. The International Journal of Biostatistics, 2(1).",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h2-verdieping-factoren.html",
    "href": "lta-hhs-tidymodels-h2-verdieping-factoren.html",
    "title": "2  Analyse van factoren",
    "section": "",
    "text": "2.1 Inleiding\nNa de basis-analyse van de data en het bouwen van de prognosemodellen, gaan we in deze verdiepende analyse dieper in op de factoren van de modellen. Het doel is beter te begrijpen hoe de factoren precies de retentie verklaren. Deze verdiepende factoranalyse heeft 6 stappen:",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h2-verdieping-factoren.html#inleiding",
    "href": "lta-hhs-tidymodels-h2-verdieping-factoren.html#inleiding",
    "title": "2  Analyse van factoren",
    "section": "",
    "text": "We lezen de bewerkte dataset in en de modellen die we in de basis-analyse hebben gemaakt.\nWe maken een explainer om de modellen beter te begrijpen en te kunnen uitleggen. Dit lichten we later in deze pagina toe.\nWe gebruiken het beste model om de prognose te verklaren en te begrijpen. We kijken naar de bijdrage van de variabelen aan de voorspelling en passen het model toe op de meest voorkomende studenten.\nVervolgens onderzoeken we de stabiliteit van de invloed van de verklarende variabelen met behulp van Shapley waarden.\nDaarna onderzoeken we hoe de retentie er anders uit zou kunnen zien als de studenten andere kenmerken zouden hebben met een Ceteris Paribus analyse.\nTot slot onderzoeken we per variabele de variantie van de voorspellingen met een Partial Dependence analyse.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h2-verdieping-factoren.html#voorbereidingen",
    "href": "lta-hhs-tidymodels-h2-verdieping-factoren.html#voorbereidingen",
    "title": "2  Analyse van factoren",
    "section": "2.2 Voorbereidingen",
    "text": "2.2 Voorbereidingen\n\n2.2.1 Laad de data\nWe laden de bewerkte data en prognosemodellen in voor:\nOpleiding: ITD | B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars - Retentie na 1 jaar\n\n\nToon code\n## Bepaal de paden\nsData_outputpath           &lt;- Get_Model_Outputpath(mode = \"data\")\nsFittedmodels_outputpath   &lt;- Get_Model_Outputpath(mode = \"last-fits\")\nsModelresults_outputpath   &lt;- Get_Model_Outputpath(mode = \"modelresults\")\n\n## Laad de data voor de opleiding: data, last fits en model results\ndfOpleiding_inschrijvingen &lt;- rio::import(sData_outputpath, trust = TRUE)\nlLast_fits                 &lt;- rio::import(sFittedmodels_outputpath, trust = TRUE)\ndfModel_results            &lt;- rio::import(sModelresults_outputpath, trust = TRUE)\n\n# Pas de Retentie variabele aan naar numeric (0/1), \n# zodat er een explainer van gemaakt kan worden\ndfOpleiding_inschrijvingen$Retentie &lt;- as.numeric(dfOpleiding_inschrijvingen$Retentie) - 1\n\n## Maak een lijst van dfPersonas\nlDfPersona &lt;- list()\n\n## Loop over de variabelen\nlDfPersona &lt;- map(c(\"Geslacht\", \"Vooropleiding\", \"Aansluiting\"),\n                  ~ Get_dfPersona(.x)) |&gt;\n  set_names(c(\"Geslacht\", \"Vooropleiding\", \"Aansluiting\"))\n\ndfPersona_per_group &lt;- bind_rows(lDfPersona) \n\n## Bewaar dit bestand als excel\nsOutputPath &lt;- file.path(\"92_Tmp\", \"dfPersona_per_group.xlsx\")\nwritexl::write_xlsx(dfPersona_per_group, sOutputPath)\n\n## Laad de persona's\ndfPersona_all &lt;- Get_dfPersona()",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h2-verdieping-factoren.html#verdiepende-analyse-van-het-model",
    "href": "lta-hhs-tidymodels-h2-verdieping-factoren.html#verdiepende-analyse-van-het-model",
    "title": "2  Analyse van factoren",
    "section": "2.3 Verdiepende analyse van het model",
    "text": "2.3 Verdiepende analyse van het model\nWe weten vanuit de basis-analyse welke variabelen van invloed zijn, maar niet hoe en in welke richting ze retentie verklaren: dragen ze sterk bij of juist niet, verhogen of verlagen ze retentie? Om het model beter te begrijpen en te kunnen uitleggen, maken met behulp van het DALEX package een explainer.\nDALEX is onder andere ontwikkeld om uit te kunnen leggen welke verklarende variabelen van belang zijn en wat deze voor een effect hebben in een model. Een explainer is een model-onafhankelijke wrapper, die inzicht geeft in de voorspellingen van het model en de bijdrage van de variabelen aan de prognose. Een explainer maakt het verder mogelijk om modellen onderling te vergelijken en benchmarken.\n\n2.3.1 Maak een explainer\nWe gaan nu een stap verder met behulp van het DALEX package. Op basis van het tidymodels model extraheren we de informatie voor de explainer van Dalex.\n\n\nToon code\n## Extraheer het fitted model en de workflow\nfitted_model &lt;- last_fit |&gt;\n  extract_fit_parsnip()\n\nworkflow &lt;- last_fit |&gt;\n  extract_workflow()\n\n# Maak een explainer\nexplain_lf &lt;- DALEX::explain(\n  model = workflow,\n  data = dfOpleiding_inschrijvingen,\n  y = dfOpleiding_inschrijvingen$Retentie,\n  label = \"Linear Regression\")\n\n\nPreparation of a new explainer is initiated\n  -&gt; model label       :  Linear Regression \n  -&gt; data              :  1613  rows  27  cols \n  -&gt; target variable   :  1613  values \n  -&gt; predict function  :  yhat.workflow  will be used (  default  )\n  -&gt; predicted values  :  No value for predict function target column. (  default  )\n  -&gt; model_info        :  package tidymodels , ver. 1.2.0 , task classification (  default  ) \n  -&gt; predicted values  :  numerical, min =  0.1653039 , mean =  0.6217209 , max =  0.9175099  \n  -&gt; residual function :  difference between y and yhat (  default  )\n  -&gt; residuals         :  numerical, min =  -0.8923788 , mean =  -0.0005181616 , max =  0.795335  \n  A new explainer has been created!  \n\n\n\n\n2.3.2 Toets de Root Mean Square Error na permutaties\nDe eerste analyse is de Root Mean Square Error (RMSE) na permutaties.\n\nDe RMSE is een maatstaf voor de gemiddelde afwijking van de voorspellingen van een model ten opzichte van de werkelijke waarden. Het wordt berekend als de wortel van de gemiddelde kwadratische fout.\nRMSE na permutaties wil zeggen dat de RMSE is berekend na het herhaaldelijk willekeurig herschikken (permuteren) van de waarden van een variabele in de dataset en daarmee de voorspellingen. Deze techniek passen we toe om de robuustheid en betrouwbaarheid van het model te evalueren.\n\nWaarom is RMSE na permutaties nodig?\n\nModelvalidatie: Door de variabelen te permuteren en de RMSE te berekenen, kunnen we de prestatie van het model vergelijken met een willekeurige schatting. Variabelen die significant beter presteren dan de gemiddelde RMSE na permutaties hebben meer voorspellende kracht.\nOverfit detectie: Als de RMSE van het originele model niet veel beter is dan het RMSE na permutaties, kan dit een indicatie zijn dat het model overfit op de trainingsdata en niet goed generaliseert naar nieuwe data.\n\nDe meeste voorspellende factoren en hun RMSE zijn:\n\n\nToon code\nsPlotPath &lt;- file.path(Get_Plot_Outputpath(plotname = \"lf_model_parts_rmse\"))\n\n## Als de plot niet bestaat of als recreateplots - T, maak dan een nieuwe plot\nif(!file.exists(sPlotPath) | params$recreateplots == TRUE) {\n\n  ## Bereken de model parts op basis van de RMSE\n  mp_rmse &lt;- model_parts(explain_lf, loss_function = loss_root_mean_square)\n  \n  ## Maak een plot van de RMSE\n  mp_rmse_plot &lt;- Get_RMSE_Plot(mp_rmse)\n  \n  ## Bewaar de plot\n  suppressWarnings(\n    Finalize_Plot(\n      plot_name = mp_rmse_plot,\n      save_filepath = sPlotPath,\n      height_pixels = 50 + (15 * length(unique(mp_rmse$variable)))\n    ))\n\n  # ## Toon de bestaande plot\n  knitr::include_graphics(sPlotPath)\n      \n} else {\n  \n  ## Toon de bestaande plot\n  knitr::include_graphics(sPlotPath)\n  \n}\n\n\n\n\n\n\n\n\nFiguur 2.1: Meest voorspellende factoren - RMSE\n\n\n\n\n\nHet valt op dat de meest voorspellende variabelen ook een hoge RMSE hebben. Dit betekent dat deze variabelen een grote invloed hebben op de voorspelling van het model, maar per toepassing op een individuele student uit het verleden ook sterk kunnen variëren.\n\n\n2.3.3 Inspecteer variabelen met de meeste invloed\nEen volgende analyse is een toepassing van het model op de meest voorkomende student. We kijken eerst naar de meest voorkomende student in het algemeen. Vervolgens analyseren we de meest voorkomende student in meerdere groepen: naar vooropleiding, geslacht, leeftijd en aansluiting, etc. Om de meest voorkomende student te bepalen, gebruiken we de meeste frequente waarden van de verklarende variabelen in de dataset per groep.\nNB. Het kan goed zijn dat we combinaties krijgen van waarden van variabelen die niet kunnen voorkomen, bijv. een student van het mbo met een E&M profiel. Dit is wel correct: het is een fictieve student die de meest voorkomende kenmerken van de totale populatie van studenten van deze opleiding vertegenwoordigt.\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we een onderscheid maken tussen mbo en havo studenten, dan bepalen we de mediaan van numerieke variabelen en de meest frequente waarde van categorische variabelen. Van de leeftijd kan misschien 20 het vaakst voorkomen, etc.\n\n\nWe kijken hiermee naar de voorspelling van het model per groep en de bijdrage van de verklarende variabelen aan die specifieke voorspelling. Dit geeft een verder inzicht in de werking van het model. Een categorie met 20 studenten of minder laten we buiten beschouwing.\n\n2.3.3.1 Toelichting op de opbouw van de kans op retentie\nDe opbouw van het model bestaat uit een intercept, gevolgd door verklarende variabelen die een verschil maken ten opzichte van die intercept. De intercept is de basiskans op retentie voor alle studenten. Deze kans is voor de B Communication and Multimedia Design (CMD) voltijd 62,2%. De cumulatieve bijdrage van de variabelen aan de voorspelling kan positief of negatief zijn. Een positieve bijdrage betekent dat de variabele de kans op retentie verhoogt, een negatieve bijdrage betekent dat het de kans op retentie verlaagt.\nHet kan zijn dat nieuwe variabelen geen invloed meer hebben op de kans. Dit betekent niet per se dat ze niet belangrijk zijn. Het kan zijn dat de invloed die ze hebben op de kans al is ‘afgevangen’ door variabelen die eerder in het model zijn opgenomen.\n\n\n\n\n\n\nTer illustratie\n\n\n\nDe variabele Cijfer_CE_VO_missing = Ja betekent dat een student geen VO cijfers heeft voor het centraal schriftelijk examen. Dit geldt voor vrijwel alle MBO studenten. Doordat de variabele Cijfer_CE_VO_missing de kans op retentie net wat sterker beïnvloedt, komt Vooropleiding = MBO niet meer voor als invloedrijke variabele, maar is dit wel de achterliggende reden dat het cijfer ontbreekt.\n\n\nUiteindelijk tellen alle verklarende variabelen op tot een definitieve voorspelling die per persoon verschilt, afhankelijk van hun persoonlijke verschillen per variabele.\n\n\n2.3.3.2 De meest voorkomende student (totaal)\nWe kijken eerst naar de meest voorkomende student in de opleiding. We analyseren de kans op retentie voor deze fictieve student en de bijdrage van de variabelen aan die kans. Daarbij tonen we de verdeling van de voorspellingen voor deze student voor alle variabelen en per variabele. Dit laat zien welke variabelen belangrijk zijn, naar welke kant de verdeling neigt en welke spreiding de kansverdeling heeft.\nToelichting\n\nAll data - De eerste variabele all data is eigenlijk geen variabele, maar geeft aan wat alle data samen aan kans op retentie voorspellen. Variabelen die daarna bovenaan staan, wegen het zwaarst in de voorspelling van de kans.\nRichting - Als de verdeling van de kansen naar de linkerkant van de x-as gaat, draagt deze variabele meer bij aan een toename op de kans op retentie; als deze naar de rechterkant beweegt, draagt deze variabele juist bij aan een afname op de kans op retentie\nSpreiding - Als de spreiding breed is, geeft dit aan dat er binnen deze variabele veel variatie is in de kans op retentie en er voorzichtig mee omgegaan moet worden. Als de spreiding heel smal is, betekent dit dat de variabele weinig of geen invloed heeft op de kans op retentie Deze variabelen bevinden zich op de intercept.\nVorm - De vorm achter de variabele (een viool) geeft de verdeling van de kans op retentie weer. Hoe breder de viool-vorm, hoe meer studenten op die locatie een kans op retentie hebben.\n\n\n\n\n\n\n\nFiguur 2.2: Opbouw van de kans op retentie\n\n\n\n\n\n2.3.3.3 De meest voorkomende student (per groep)\nNu de algemene opbouw van de kans op retentie bekend is voor de meest voorkomende student, gaan we verder met een analyse van de meest voorkomende studenten per groep.\nDe volgorde van de variabelen is zo gesorteerd dat per groep de meest voorspellende variabelen bovenaan staat. De volgorde verschilt per groep en geeft inzicht in wat er per groep speelt. De variabelen zijn vaak proxies voor onderliggende verschillen.\n\n2.3.3.3.1 Naar geslacht\n\nMV\n\n\n\n\n\n\n\n\nFiguur 2.3: Breakdown naar geslacht: M\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.4: Breakdown naar geslacht: V\n\n\n\n\n\n\n\n\n2.3.3.3.2 Naar vooropleiding\n\nMBOHAVOVWOBDHOCD\n\n\n\n\n\n\n\n\nFiguur 2.5: Breakdown naar vooropleiding: MBO\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.6: Breakdown naar vooropleiding: HAVO\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.7: Breakdown naar vooropleiding: VWO\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.8: Breakdown naar vooropleiding: BD\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.9: Breakdown naar vooropleiding: HO\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.10: Breakdown naar vooropleiding: CD\n\n\n\n\n\n\n\n\n2.3.3.3.3 Naar aansluiting\nDe subtotalen voor de categorieën 2e Studie en Na CD zijn te laag voor een betrouwbare analyse.\n\nDirectTussenjaarSwitch internSwitch extern\n\n\n\n\n\n\n\n\nFiguur 2.11: Breakdown naar aansluiting: Direct\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.12: Breakdown naar aansluiting: Tussenjaar\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.13: Breakdown naar aansluiting: Switch intern\n\n\n\n\n\n\n\n\n\n\n\nFiguur 2.14: Breakdown naar aansluiting: Switch extern\n\n\n\n\n\n\n\n\n\n\n2.3.4 Shapley\nNa deze factorentanalyse kijken we naar de stabiliteit van de invloed van de verklarende variabelen. We gebruiken hiervoor Shapley waarden. Anders dan bij de vorige modellen, houdt Shapley rekening met een andere volgorde van de variabelen.\nDe volgorde van de variabelen is cumulatief (additief) en maakt dus uit voor de bijdrage aan het model: als er een andere variabele al in het model is toegevoegd, heeft dat invloed op de daaropvolgende variabele. Een Shapley analyse permuteert de volgorde van de variabelen om daarmee de verschillen te berekenen in de bijdrage aan de voorspelling. Zo krijgen we nog beter zicht op het belang en de invloed van de individuele variabelen in het voorspelmodel. Variabelen zonder bijdrage hebben we verwijderd.\n\n\nToon code\n## Bewaar de plot\nsPlotPath &lt;- file.path(Get_Plot_Outputpath(plotname = \"lf_shapley\"))\n\n## Als de plot niet bestaat of als recreateplots - T, maak dan een nieuwe plot\nif(!file.exists(sPlotPath) | params$recreateplots == TRUE) {\n\n  ## Bepaal de Shapley waarden\n  lf_shapley &lt;- \n    predict_parts(\n      explainer = explain_lf,\n      new_observation = dfPersona_all[1, ],\n      type = \"shap\",\n      B = 20\n    )\n\n  ## Zet deze om naar een dataframe\n  dfShapley &lt;- Get_dfShapley(lf_shapley)\n\n  ## Bouw de plot\n  shapley_plot &lt;- Get_Shapley_Plot(dfShapley)\n  \n  ## Bewaar de plot\n  suppressWarnings(\n    Finalize_Plot(\n      plot_name = shapley_plot,\n      save_filepath = sPlotPath,\n      height_pixels = 50 + (20 * length(unique(dfShapley$variable_name)))\n    ))\n  \n  ## Print de bestaande plot\n  knitr::include_graphics(sPlotPath)\n\n} else {\n\n  ## Print de bestaande plot\n  knitr::include_graphics(sPlotPath)\n\n}\n\n\n\n\n\n\n\n\nFiguur 2.15: Shapley values\n\n\n\n\n\nToelichting:\n\nDe variabelen met blauwe balken verhogen de kans op retentie, de variabelen met rode balken verlagen de kans op retentie\nDe boxplot in iedere balk geeft de spreiding van de bijdrage van de variabelen aan de voorspelling weer. Hoe breder de boxplot, des te meer variatie in de bijdrage van de variabele aan de voorspelling.\nDe positie van de variabele geeft het belang van de variabele aan in de voorspelling. Hoe hoger de variabele, des te belangrijker de variabele is in de voorspelling.\n\n\n\n\n2.3.5 What-if: een Ceteris Paribus analyse\nVervolgens analyseren we een aantal scenario’s (wat als…). We nemen opnieuw de meest voorkomende studenten, maar beelden nu af hoe de kans op retentie eruit zou zien als telkens een van de variabelen net wat anders was geweest.\n\n\n\n\n\n\nLet op!\n\n\n\nDit is de invloed van de variabelen bij de unieke combinatie van deze meest voorkomende student per categorie. Zie voor de invloed van een variabelen ongeacht deze unieke combinatie de analyse van Partial Dependence Profielen in de volgende paragraaf.\n\n\nHiervoor houden we steeds alle variabelen gelijk, op één na (ceteris paribus is Latijn voor ‘al het overige gelijk’). Van die ene variabelen passen we de waarden aan en zien dan het effect op de voorspelde kans op retentie. Dit geeft beter inzicht in het effect van de individuele variabelen in het model. We voeren deze analyse uit voor numerieke variabelen.\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat de student in dit model net een wat hoger eindexamencijfer zou hebben gehad op de middelbare school, wat zou dan de kans op retentie zijn geweest? Het is waarschijnlijk dat de kans op retentie dan hoger zou zijn geweest. Bij hbo-opleidingen die goed aansluiten hebben met een opleiding aan een universiteit, zou de kans op retentie juist lager zijn geweest omdat studenten dan na een hbo-diploma vaak doorstromen naar een universiteit.\n\n\nOpnieuw kijken we naar geslacht, vooropleiding en aansluiting. N.B. Het kan zijn dat een van de categorieën niet zichtbaar is, dit komt doordat deze dan over elkaar heen vallen.\n\n\n\n\n\n\nFiguur 2.16: Ceteris-paribus profiel naar geslacht\n\n\n\n\n\n\n\n\n\nFiguur 2.17: Ceteris-paribus profiel naar vooropleiding\n\n\n\n\n\n\n\n\n\nFiguur 2.18: Ceteris-paribus profiel naar aansluiting\n\n\n\n\n\n\n2.3.6 Partial Dependence analyse\nTot slot analyseren we Partial Dependence. Hierbij onderzoeken we de invloed van individuele variabelen op de kans op retentie, ongeacht de combinatie van de meest voorkomende studenten. Per (numerieke) variabele analyseren we de variantie binnen de kansen op retentie. We gebruiken hiervoor het gemiddelde van alle Ceteris Paribus profielen. Vandaar dat we ook wel spreken over Partial Dependence profielen (PDP’s). We gebruiken voor deze analyse weer het DALEX package.\nWe analyseren eerst de variabelen voor alle studenten. We tonen niet alleen de gemiddelde lijn, maar ook de lijnen van de individuele CP-profielen. Vervolgens analyseren op dezelfde manier de variabelen per groep: geslacht, vooropleiding en aansluiting.\nToelichting\n\nDe gemiddelde lijn geeft de gemiddelde kans op retentie weer voor alle studenten in de dataset voor alle waarden per variabele.\nDe individuele lijnen geven de kans op retentie weer voor de individuele studenten in de dataset voor alle waarden per variabele. De bandbreedte van de individuele lijnen geeft de spreiding van de kans op retentie weer binnen de variabele. Het toont dat de kans op retentie per student kan verschillen, zelfs als de variabele gelijk is; de richting van het verband is wel gelijk.\nStandaard worden 100 willekeurige profielen gekozen om deze afbeeldingen op te bouwen; door deze selectie kan het zijn dat sommige categorieën met weinig observaties in de populatie niet afgebeeld worden.\nDoordat lijnen kunnen overlappen kan het zijn dat sommige lijnen niet zichtbaar zijn. De legenda geeft aan welke mogelijke categorieën voorkomen in de analyse.\n\n\n2.3.6.1 Alle studenten\n\n\n\n\n\n\nFiguur 2.19: Partial Dependence profiel naar alle studenten\n\n\n\n\n\n2.3.6.2 Geslacht\n\n\n\n\n\n\nFiguur 2.20: Partial Dependence profiel naar geslacht\n\n\n\n\n\n2.3.6.3 Vooropleiding\n\n\n\n\n\n\nFiguur 2.21: Partial Dependence profiel naar vooropleiding\n\n\n\n\n\n2.3.6.4 Aansluiting\n\n\n\n\n\n\nFiguur 2.22: Partial Dependence profiel naar aansluiting",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h2-verdieping-factoren.html#vervolgstappen-kansengelijkheid",
    "href": "lta-hhs-tidymodels-h2-verdieping-factoren.html#vervolgstappen-kansengelijkheid",
    "title": "2  Analyse van factoren",
    "section": "2.4 Vervolgstappen: kansengelijkheid",
    "text": "2.4 Vervolgstappen: kansengelijkheid\nDe volgende stap (stap 3) is te onderzoeken of er binnen deze opleiding binnen deze modellen kansengelijkheid bestaat.\nDit doen we door voor verschillende groepen studenten de metrieken van de modellen te evalueren, zoals accuraatheid. Als de metrieken van de voorspellingen van het model voor verschillende groepen studenten sterk uiteenlopen kan er sprake zijn van een bias, wat kan duiden op kansenongelijkheid. Dit is het onderwerp van de volgende en laatste analyse.\n\n \nVerantwoording\nDeze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: No Fairness without Awareness | Het rapport is door het lectoraat ontwikkeld in Quarto 1.6.39. | Template versie: 0.9.1.9000\n\n \nCopyright\nDr. Theo Bakker, Lectoraat Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html",
    "href": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html",
    "title": "3  Analyse van kansengelijkheid",
    "section": "",
    "text": "3.1 Inleiding\nNa de factoranalyse van de data gaan we nu in op de onderwerpen bias, fairness en kansengelijkheid. Het doel is beter te begrijpen of er studenten zijn met minder kans op succes en of dit disproportioneel is. Dit kan duiden op kansenongelijkheid.\nDe analyse van kansengelijkheid heeft de volgende stappen:",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#inleiding",
    "href": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#inleiding",
    "title": "3  Analyse van kansengelijkheid",
    "section": "",
    "text": "We lezen de bewerkte dataset weer in en de modellen die we in de basis-analyse hebben gemaakt.\nWe maken weer een explainer om de modellen beter te begrijpen en te kunnen uitleggen.\nVervolgens berekenen we of er bias bestaat voor verschillende groepen studenten naar geslacht, vooropleiding en vorm van aansluiting. We analyseren daarvoor de verdeling van kansen en mate van fairness in het voorspelmodel dat we hebben ontwikkeld.\nTot slot trekken we er conclusies uit over de mate van bias binnen de opleiding voor retentie na 1 jaar.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#voorbereidingen",
    "href": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#voorbereidingen",
    "title": "3  Analyse van kansengelijkheid",
    "section": "3.2 Voorbereidingen",
    "text": "3.2 Voorbereidingen\n\n3.2.1 Laad de data\nWe laden de bewerkte data en het beste prognosemodel in voor:\nOpleiding: ITD | B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars - Retentie na 1 jaar\n\n\nToon code\n## Bepaal de paden\nsData_outputpath         &lt;- Get_Model_Outputpath(mode = \"data\")\nsFittedmodels_outputpath &lt;- Get_Model_Outputpath(mode = \"last-fits\")\nsModelresults_outputpath &lt;- Get_Model_Outputpath(mode = \"modelresults\")\n\n## Laad de data voor de opleiding: data, last fits en model results\ndfOpleiding_inschrijvingen &lt;- rio::import(sData_outputpath, trust = TRUE) |&gt; \n  mutate(Geslacht      = factor(Geslacht,      levels = lLevels_geslacht),\n         Vooropleiding = factor(Vooropleiding, levels = lLevels_vop),\n         Aansluiting   = factor(Aansluiting,   levels = lLevels_aansluiting))\nlLast_fits                 &lt;- rio::import(sFittedmodels_outputpath, trust = TRUE)\ndfModel_results            &lt;- rio::import(sModelresults_outputpath, trust = TRUE)\n\n# Pas de Retentie variabele aan naar numeric (0/1), \n# zodat er een explainer van gemaakt kan worden\ndfOpleiding_inschrijvingen$Retentie &lt;- as.numeric(dfOpleiding_inschrijvingen$Retentie) - 1\n\n## Maak een lijst van dfPersonas\nlDfPersona &lt;- list()\n\n## Loop over de variabelen\nlDfPersona &lt;- map(c(\"Geslacht\", \"Vooropleiding\", \"Aansluiting\"),\n                  ~ Get_dfPersona(.x)) |&gt;\n  set_names(c(\"Geslacht\", \"Vooropleiding\", \"Aansluiting\"))\n\n## Laad de persona's\ndfPersona_all &lt;- Get_dfPersona()\n\n\n\n\n3.2.2 Maak een explainer\nWe maken weer gebruik van de explainer van DALEX.\n\n\nToon code\n## Extraheer het fitted model en de workflow\nfitted_model &lt;- last_fit |&gt;\n  extract_fit_parsnip()\n\nworkflow &lt;- last_fit |&gt;\n  extract_workflow()\n\n# Maak een explainer\nexplain_lf &lt;- DALEXtra::explain_tidymodels(\n  model = workflow,\n  data = dfOpleiding_inschrijvingen |&gt; select(-Retentie),\n  y = dfOpleiding_inschrijvingen |&gt; pull(Retentie),\n  colorize = TRUE,\n  verbose = FALSE,\n  label = \"Linear Regression\"\n)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#analyse-van-kansengelijkheid",
    "href": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#analyse-van-kansengelijkheid",
    "title": "3  Analyse van kansengelijkheid",
    "section": "3.3 Analyse van kansengelijkheid",
    "text": "3.3 Analyse van kansengelijkheid\nTot slot onderzoeken we kansengelijkheid door te kijken naar bias in de data. Dit wordt ook wel een fairness analyse genoemd. Het leidende werk voor fairness analyses is Fairness and Machine Learning: Limitations and Opportunities (Barocas et al., 2023). De methode die we in dit deel van de analyse hanteren is op dit gedachtengoed gebaseerd.\nWe onderzoeken of er bias bestaat voor verschillende groepen studenten als mogelijk teken van kansenongelijkheid. Ook hiervoor maken we gebruik van de DALEX explainer en onderzoeken de invloed van de variabelen op de kans op retentie voor verschillende groepen studenten naar geslacht, vooropleiding en aansluiting.\nDe volgende definities zijn van belang:\n\nBevoorrechte groep: Een groep die als standaard wordt beschouwd en mogelijk bevoordeeld wordt (bijv. meerderheidsgroepen, mannen, etc.).\nBeschermde groep: Een groep waarvan wordt verwacht dat deze mogelijk benadeeld wordt (bijv. minderheidsgroepen, vrouwen, etc.).\n\nIn een onderwijssituatie kunnen deze groepen verschillen van maatschappelijke situaties. Zo hebben vrouwen in het onderwijs vaak een bevoorrechte positie omdat zij over het algemeen meer studiesucces hebben, terwijl in andere domeinen, bijvoorbeeld het vinden van werk, vrouwen vaak een beschermde groep zijn.\n\n3.3.1 Ratio’s om kansengelijkheid te beoordelen\nVoor elke groep onderzoeken we 5 ratio’s, ook wel maatstaven of metrieken genoemd. Deze ratio’s zijn afgeleid van verhoudingen in de confusion matrix; ze geven inzicht in de mate van bias en kansengelijkheid vanuit verschillende perspectieven van een prognosemodel.\n\n\nToon code\nknitr::include_graphics(here::here(\"01_Includes/img\", \"confusion-matrix-fairness-lta-hhs.png\"))\n\n\n\n\n\n\n\n\nFiguur 3.1: Confusion matrix in relatie tot BSA\n\n\n\n\n\n\n1. Accuracy Equality2. Equal Opportunity3. Predictive Equality4. Predictive Parity5. Statistical Parity\n\n\n1. Accuracy Equality Ratio\nIn welke mate voorspelt het model zowel de positieve als negatieve uitkomsten goed?\nDeze maatstaf wordt gebruikt om te beoordelen of een model even accuraat is voor verschillende subgroepen binnen de dataset. Het vergelijkt de nauwkeurigheid van het model voor een beschermde groep (een minderheidsgroep) met de nauwkeurigheid voor een bevoorrechte groep (de meerderheidsgroep). Deze ratio wordt berekend als de verhouding tussen de nauwkeurigheid voor de beschermde groep en de nauwkeurigheid voor de bevoorrechte groep.\nFormule\n \\text{ACC} = \\frac{TP + TN}{TP + FP + TN + FN} \nDefinities\n\nNauwkeurigheid (Accuracy): Het percentage correcte voorspellingen van het model. Dit wordt berekend als het aantal juiste voorspellingen gedeeld door het totale aantal voorspellingen.\n\nInterpretatie\n\nRatio = 1: Het model is even accuraat voor beide groepen.\nRatio &lt; 1: Het model is minder accuraat voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model is meer accuraat voor de beschermde groep dan voor de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de nauwkeurigheid van het model voor havisten 80% is en voor mbo-ers 70%. De Accuracy Equality Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder accuraat is voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).\n\n\n\n\n2. Equal Opportunity Ratio\nIn welke mate zijn de terecht positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van kansen die een model biedt aan verschillende subgroepen in termen van de ‘True Positive Rate’ (TPR). Het vergelijkt de kans dat een model correct een positieve uitkomst voorspelt voor een beschermde groep versus een bevoorrechte groep.\nDe True Positive Rate (TPR) is een andere term voor de sensitiviteit (ook wel recall) genoemd. De Equal Opportunity Ratio wordt berekend als het aantal true positives gedeeld door het totaal aantal werkelijke positives.\nFormule\n \\text{TPR} = \\frac{TP}{TP + FN} \nDefinities\n\nTP: True Positives (correcte voorspellingen van positieve uitkomsten)\nFN: False Negatives (werkelijke positieve uitkomsten die foutief als negatief zijn voorspeld)\n\nInterpretatie\n\nRatio = 1: Het model biedt gelijke kansen aan beide groepen in termen van het correct voorspellen van positieve uitkomsten.\nRatio &lt; 1: Het model biedt minder kansen aan de beschermde groep in vergelijking met de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model biedt meer kansen aan de beschermde groep in vergelijking met de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de True Positive Rate voor havisten 70% is en voor mbo-ers 60%. De Equal Opportunity Ratio is dan 0,857 (60% / 70%). Dit betekent dat het model minder kans biedt aan de beschermde groep (mbo-ers) om correct positieve uitkomsten te voorspellen dan aan de bevoorrechte groep (havisten).\n\n\n\n\n3. Predictive Equality Ratio\nIn welke mate zijn de vals positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van het aantal False Positives (vals-positieven) tussen verschillende subgroepen. Het vergelijkt de False Positive Rate (FPR) voor een beschermde groep met de FPR voor een bevoorrechte groep.\nDe FPR is de verhouding van het aantal vals-positieve voorspellingen (False Positives, FP) ten opzichte van het totaal aantal werkelijke negatieve gevallen (True Negatives, TN en False Positives, FP). De Predictive Equality Ratio wordt berekend als de verhouding tussen de FPR voor de beschermde groep en de FPR voor de bevoorrechte groep.\nFormule\n \\text{FPR} = \\frac{FP}{FP + TN} \nDefinities\n\nFP: False Positives (foutieve voorspellingen van positieve uitkomsten)\nTN: True Negatives (correcte voorspellingen van negatieve uitkomsten)\n\nInterpretatie\n\nRatio = 1: Het model heeft een gelijke kans om False Positives te maken voor beide groepen.\nRatio &lt; 1: Het model heeft minder kans om False Positives te maken voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias ten nadele van de bevoorrechte groep.\nRatio &gt; 1: Het model heeft meer kans om False Positives te maken voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias ten nadele van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de False Positive Rate voor havisten 20% is en voor mbo-ers 30%. De Predictive Equality Ratio is dan 1,5 (30% / 20%). Dit betekent dat het model meer kans heeft om vals-positieve voorspellingen te maken voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).\n\n\n\n\n4. Predictive Parity Ratio\nIn welke mate zijn de terecht positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van de nauwkeurigheid van de voorspelling tussen verschillende subgroepen door de positieve voorspellende waarde (Positive Predictive Value, PPV) van het model voor een beschermde groep te vergelijken met die voor een bevoorrechte groep. De PVV wordt ook wel de precisie genoemd en wordt berekend als het aantal true positives (TP) gedeeld door het totaal aantal voorspelde positives (TP en FP). Het is een maat voor de nauwkeurigheid van de positieve voorspellingen van het model.\nFormule\n \\text{PPV} = \\frac{TP}{TP + FP} \nDefinities\n\nTP: True Positives (correcte voorspellingen van positieve uitkomsten)\nFP: False Positives (foutieve voorspellingen van positieve uitkomsten)\n\nInterpretatie\n\nRatio = 1: Het model heeft een gelijke nauwkeurigheid in voorspellingen voor beide groepen.\nRatio &lt; 1: Het model is minder nauwkeurig in het voorspellen van positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model is nauwkeuriger in het voorspellen van positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de Positive Predictive Value voor havisten 80% is en voor mbo-ers 70%. De Predictive Parity Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder nauwkeurig is in het voorspellen van positieve uitkomsten voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).\n\n\n\n\n5. Statistical Parity Ratio\nIn welke mate zijn de positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van de positieve voorspellingen (ongeacht of ze correct zijn of niet) tussen verschillende subgroepen. Het vergelijkt de kans dat een model een positieve uitkomst voorspelt voor een beschermde groep met de kans dat het een positieve uitkomst voorspelt voor een bevoorrechte groep. De Statistical Parity Ratio wordt berekend als de verhouding tussen de kans op een positieve voorspelling voor de beschermde groep en de kans op een positieve voorspelling voor de bevoorrechte groep.\nFormule\n \\text{SPR} = \\frac{TP + FP}{TP + FP + TN + FN} \nDefinities\n\nPositieve Voorspelling: Een voorspelling waarin het model een positieve uitkomst voorspelt (bijv. aangenomen worden, krediet goedkeuring, etc.).\n\nInterpretatie\n\nRatio = 1: Het model voorspelt even vaak positieve uitkomsten voor beide groepen.\nRatio &lt; 1: Het model voorspelt minder vaak positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model voorspelt vaker positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat kan wijzen op bias ten nadele van de bevoorrechte groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de kans op een positieve voorspelling voor havisten 80% is en voor mbo-ers 70%. De Statistical Parity Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder vaak positieve uitkomsten voorspelt voor de beschermde groep (havisten) dan voor de bevoorrechte groep (mbo-ers).\n\n\n\n\n\nNu we deze begrippen hebben gedefinieerd, kunnen we de bias en kansengelijkheid van het model voor verschillende groepen studenten analyseren. Hiervoor gebruiken we het fairmodels package van DALEX.\n\n\n\n3.3.2 Aantallen en percentages per groep\nVoor de variabelen Geslacht, Vooropleiding en Aansluiting is de verdeling binnen deze opleiding als volgt:\n\n\n\nTabel 3.1: Aantallen en percentages naar geslacht, vooropleiding en aansluiting in relatie tot retentie\n\n\n Retentie na 1 jaar VariabeleNTotaal  N = 1.6131Ja  N = 1.0021Nee  N = 6111p-value2Geslacht1.613&lt;0,001***M915 (57%)521 (52%)394 (64%)V698 (43%)481 (48%)217 (36%)Vooropleiding1.6130,015*MBO522 (32%)330 (33%)192 (31%)HAVO860 (53%)548 (55%)312 (51%)VWO58 (3,6%)34 (3,4%)24 (3,9%)BD92 (5,7%)42 (4,2%)50 (8,2%)HO51 (3,2%)27 (2,7%)24 (3,9%)CD30 (1,9%)21 (2,1%)9 (1,5%)Overig0 (0%)0 (0%)0 (0%)Onbekend0 (0%)0 (0%)0 (0%)Aansluiting1.613&lt;0,001***Direct756 (47%)455 (45%)301 (49%)Tussenjaar176 (11%)125 (12%)51 (8,3%)Switch intern202 (13%)148 (15%)54 (8,8%)Switch extern445 (28%)254 (25%)191 (31%)Na CD19 (1,2%)14 (1,4%)5 (0,8%)2e Studie15 (0,9%)6 (0,6%)9 (1,5%)Overig0 (0%)0 (0%)0 (0%)Onbekend0 (0%)0 (0%)0 (0%)1n (%)2*p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n\n\n\n\n3.3.3 Verdeling van kansen\nVoordat we in meer detail kansengelijkheid gaan analyseren, onderzoeken we eerst de verdeling van de kansen op retentie voor verschillende groepen studenten voor de variabelen Geslacht, Vooropleiding en Aansluiting. De verdeling van deze kansen is uniek per opleiding.\nToelichting\n\nDe verdeling van de kansen is te zien door de boxplot en de violin plot.\nDe boxplot geeft de vier quartielen aan van de data: de box staat voor de middelste 50% van de data, met een streep die de mediaan aangeeft (de middelste waarde van de data). De lijnen (whiskers) geven de 1e 25% en laatste 25% van de data.\nDe boxplot wordt gecombineerd met de violin plot, waarbij de breedte van de violin de dichtheid van de data aangeeft. Het kan zijn dat het lijkt alsof er geen violin is; in dat geval is de verdeling van het aantal studenten zeer breed en de violin vorm daardoor heel smal.\nSamen geven deze twee visualisaties een goed beeld van de verdeling van de voorspelde kansen van het model.\nDe blauwe gestippelde lijn geeft de 50% kans aan; alle waarden die boven deze lijn valt heeft een kans van 50% of meer op retentie. Hiervan voorspelt het model dat zij niet uitvallen. Deze grenslijn kan door de verdeling van de groepen heen lopen.\n\n\nToon code\n## Maak een fairness analyse\nfor(group in c(\"Geslacht\", \"Vooropleiding\", \"Aansluiting\")) {\n\n  ## Groep\n  Knit_Header(group, 4)\n  \n  # Bepaal de meest voorkomende subgroep = Privileged\n  sPrivileged &lt;- Get_Privileged(dfOpleiding_inschrijvingen, group)\n\n  ## Maak een fairness object\n  fobject &lt;- Get_objFairness(explain_lf, group, sPrivileged)\n  \n  ## Maak een tabel van de fairness analyse\n  dfFairness_totaal &lt;- Get_dfFairness_Total(fobject)\n  \n  ## Maak een plot van de fairness analyse\n  density_plot &lt;- suppressWarnings(\n    Get_Density_Plot(fobject, group = group) \n  ) \n\n  ## Bewaar de plot\n  sPlotname &lt;- glue(\"density_plot_{tolower(group)}\")\n  sPlotPath &lt;- Get_Plot_Outputpath(sPlotname, mode = \"plot\")\n\n  suppressWarnings(\n        Finalize_Plot(\n          plot_name = density_plot,\n          save_filepath = sPlotPath,\n          height_pixels = 250 + (50 * length(unique(dfFairness_totaal$Categorie)))\n        ))\n\n  ## Toon de bestaande plot\n  sPlot &lt;- glue(\"![Verdeling en dichtheid van kans op retentie naar  {tolower(group)}]({sPlotPath}){{#fig-fairness-check-{tolower(group)}}}\")\n  Knit_Print_Rule(sPlot)\n\n}\n\n\n3.3.3.1 Geslacht\n\n\n\n\n\n\nFiguur 3.2: Verdeling en dichtheid van kans op retentie naar geslacht\n\n\n\n\n\n3.3.3.2 Vooropleiding\n\n\n\n\n\n\nFiguur 3.3: Verdeling en dichtheid van kans op retentie naar vooropleiding\n\n\n\n\n\n3.3.3.3 Aansluiting\n\n\n\n\n\n\nFiguur 3.4: Verdeling en dichtheid van kans op retentie naar aansluiting\n\n\n\n\n\n\n3.3.4 Fairness checks\nNu we de verdeling van de kansen kennen, maken we tot slot een fairness analyse voor de variabelen Geslacht, Vooropleiding en Aansluiting. Voor elke groep berekenen we de maatstaven die we eerder hebben behandeld.\nWe maken een plot van de fairness analyse, waarbij we per variabele één categorie nemen als de bevoorrechte groep; hiervoor hanteren we per variabele de meest frequente groep. De aanname is dat een opleiding op deze groep het beste is toegerust. Daarnaast speelt mee dat Dalex bij een te laag aantal studenten in een bevoorrechte groep geen fairness analyse kan berekenen.\nAls binnen een variabele een groep een ratio heeft die naar links of naar rechts afwijkt, kan dit duiden op een verschil in kansengelijkheid. Let erop dat de bevoorrechte groep zelf hier niet in is opgenomen (!). Mochten alle overige groepen naar links of rechts afwijken, dan is er sprake van een bias naar de bevoorrechte groep.\nHet wijkt af als de balken verder buiten het groene vlak komen en in het rode vlak; dit is gebaseerd op een marge, epsilon, van 0,8. Deze marge is gebaseerd op het 4/5 principe: er is sprake van een te groot verschil als de maat voor een beschermde groep 4/5 of meer afwijkt van de bevoorrechte groep. Een epsilon van 0,8 leidt tot marges van -0,2 (epsilon/1) en +0,25 (1/espilon). Als er twee ratio’s of meer buiten deze marges vallen, is er volgens dit criterium sprake van bias. Als een maatstaf naar links afwijkt is er sprake van bias naar de beschermde groep (ten nadele), als deze naar rechts afwijkt is er sprake van bias naar de bevoorrechte groep (ten voordele).\n\n\n\n\n\n\nNota Bene\n\n\n\nAls de uitkomstmaat van een model negatief is (zoals uitval), dan moet de interpretatie precies andersom gemaakt worden. Dit geldt voor alle maatstaven van bias en fairness in dit hoofdstuk.\n\n\nOm de robuustheid en betrouwbaarheid in de detectie van bias te waarborgen, moeten er minstens twee metrieke waarden buiten de epsilon-marges vallen voordat er sprake is van bias (Barocas et al., 2023). Hiervoor is een aantal redenen:\n1. Meerdere indicatoren: Het gebruik van meerdere maatstaven zorgt ervoor dat we de detectie van bias niet baseren op slechts een, mogelijk ruisgevoelige, indicator. Als slechts één metriek buiten de marges valt, kan dit toeval zijn of te wijten zijn aan andere niet-systematische fouten in de data. We spreken dan nog niet over bias. Meerdere metrieke afwijkingen geven een sterkere indicatie van een systematisch probleem.\n2. Differentie van bias types: Bias kan zich op verschillende manieren manifesteren, bijvoorbeeld in termen van ongelijksoortige impact, ongelijke kansen in voorspellingen of ongelijke behandeling. Door meerdere maatstaven te evalueren, onderzoeken we een breder spectrum van potentiële bias en zien we geen aspecten over het hoofd.\n3. Normatieve overwegingen: Vaak is er een normatieve basis voor het definiëren van wat eerlijk is. Het vergelijken van meerdere maatstaven kan helpen om genuanceerder en vollediger beeld te krijgen van hoe een model presteert ten opzichte van verschillende fairness criteria.\nDe keuze voor twee maatstaven als minimum baseren we op een combinatie van statistische overwegingen en praktische normen binnen het machine learning vakgebied om een goed evenwicht te vinden tussen sensitiviteit (het detecteren van daadwerkelijke bias) en specificiteit (het vermijden van vals positieven) (Barocas et al., 2023).\n\nToon code\n## Maak een fairness analyse\nfor(group in c(\"Geslacht\", \"Vooropleiding\", \"Aansluiting\")) {\n\n  ## Groep\n  Knit_Header(group, 4)\n  \n  # Bepaal de meest voorkomende subgroep = Privileged\n  sPrivileged &lt;- Get_Privileged(dfOpleiding_inschrijvingen, group)\n\n  ## Maak een fairness object\n  fobject &lt;- Get_objFairness(explain_lf, group, sPrivileged)\n\n  ## Maak een tabel van de fairness analyse\n  dfFairness_totaal &lt;- Get_dfFairness_Total(fobject)\n  \n  ## Check of er bias is\n  Print_Fairness_Object_LTA(fobject)\n\n  ## Maak een plot van de fairness analyse\n  fairness_plot &lt;- suppressWarnings(\n    Get_Fairness_Plot(fobject, group = group, privileged = sPrivileged) +\n      theme(panel.border = element_rect(\n        colour = \"darkgrey\",\n        fill = NA,\n        size = 0.4\n      ))\n  )\n\n  ## Bewaar de plot\n  sPlotname &lt;- glue(\"fairness_plot_{tolower(group)}\")\n  sPlotPath &lt;- Get_Plot_Outputpath(sPlotname, mode = \"plot\")\n\n  suppressWarnings(\n        Finalize_Plot(\n          plot_name = fairness_plot,\n          save_filepath = sPlotPath,\n          height_pixels = 250 + (50 * length(unique(dfFairness_totaal$Categorie)))\n        ))\n\n  ## Toon de bestaande plot\n  sPlot &lt;- glue(\"![Fairness check naar {tolower(group)}]({sPlotPath}){{#fig-fairness-check-{tolower(group)}}}\")\n  Knit_Print_Rule(sPlot)\n  \n  ## Bewaar de fairness check data\n  sFairness_outputpath  &lt;- Get_Model_Outputpath(mode = \"fairness\", group = group)\n  dfFairness_check_data &lt;- Get_dfFairness_Check_Data(fobject[[\"fairness_check_data\"]], group = group)\n  saveRDS(dfFairness_check_data, file = sFairness_outputpath)\n  \n}\n\n\n3.3.4.1 Geslacht\nPrognosemodel (Linear Regression) niet geslaagd: 3 van 5 maatstaven Totaal verlies : 1.05\n\n\n\n\n\n\nFiguur 3.5: Fairness check naar geslacht\n\n\n\n\n\n3.3.4.2 Vooropleiding\nPrognosemodel (Linear Regression) niet geslaagd: 1 van 5 maatstaven Totaal verlies : 2.6\n\n\n\n\n\n\nFiguur 3.6: Fairness check naar vooropleiding\n\n\n\n\n\n3.3.4.3 Aansluiting\nPrognosemodel (Linear Regression) niet geslaagd: 1 van 5 maatstaven Totaal verlies : 3.03\n\n\n\n\n\n\nFiguur 3.7: Fairness check naar aansluiting",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#conclusies",
    "href": "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html#conclusies",
    "title": "3  Analyse van kansengelijkheid",
    "section": "3.4 Conclusies",
    "text": "3.4 Conclusies\nNa de uitvoering van de fairness analyse vatten we de conclusies samen in een tabel en tekst.\nToelichting:\n\nBij rood is er sprake van een negatieve bias.\nBij groen is er sprake van een positieve bias.\nBij oranje is er sprake van een bias, maar zijn de aantallen studenten te laag om conclusies over een negatieve of positieve bias aan te verbinden. We hanteren een minimum van 15 studenten per categorie binnen een variabele.\nDe bevoorrechte groep is grijs. Hiervan dient een eventuele bias nader bepaald te worden (NTB = Nader te bepalen). Dit is het geval als alle overige groepen binnen een variabelen een bias hebben.\n\n\n\n\nTabel 3.2: Fairness conclusies per groep\n\n\nVariabeleGroepNBiasGeen BiasNegatieve BiasPositieve BiasGeslachtM915NTB000V698Ja302VooropleidingMBO522Nee500HAVO860NTB000VWO58Nee500BD92Ja140HO51Nee500CD30Nee410AansluitingDirect756NTB000Tussenjaar176Nee500Switch intern202Nee401Switch extern445Nee500Na CD19Nee5002e Studie15Ja230\n\n\n\n\n\nToon code\n# Creeer op basis van de table nu een tekst per variabele\nlConclusies &lt;- list()\nfor(i in c(\"Geslacht\", \"Vooropleiding\", \"Aansluiting\")) {\n  lConclusies[[i]] &lt;- Get_Fairness_Conclusies(dfFairness_wide, i)\n}\n\n# print(lConclusies[[\"Geslacht\"]])\n# print(lConclusies[[\"Vooropleiding\"]])\n# print(lConclusies[[\"Aansluiting\"]])\n\n\n\n\nGeslacht: Er is sprake van bias in Retentie na 1 jaar op basis van geslacht. Er is een positieve bias voor: V.\nVooropleiding: Er is sprake van bias in Retentie na 1 jaar op basis van vooropleiding. Er is een negatieve bias voor: BD.\nAansluiting: Er is sprake van bias in Retentie na 1 jaar op basis van aansluiting. Er is een negatieve bias voor: 2e Studie.\n\n\n \nVerantwoording\nDeze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: No Fairness without Awareness | Het rapport is door het lectoraat ontwikkeld in Quarto 1.6.39. | Template versie: 0.9.1.9000\n\n \nCopyright\nDr. Theo Bakker, Lectoraat Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.\n\n\n\n\n\nBarocas, S., Hardt, M., & Narayanan, A. (2023). Fairness and Machine Learning: Limitations and Opportunities. fairmlbook.org. http://www.fairmlbook.org",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "Referenties.html",
    "href": "Referenties.html",
    "title": "Referenties",
    "section": "",
    "text": "Bakker, T. (2022). Study Progression and\nSuccess of Autistic Students in Higher Education. A Longitudinal,\nPropensity Score-Weighted Population Study. https://doi.org/10.5463/thesis.1\n\n\nBakker, T. (2024). No fairness without awareness. Toegepast\nonderzoek naar kansengelijkheid in het hoger onderwijs. Intreerede\nlectoraat learning technology & analytics. The Hague University\nof Applied Sciences. https://doi.org/10.5281/zenodo.14204674\n\n\nBarocas, S., Hardt, M., & Narayanan, A. (2023). Fairness and Machine Learning: Limitations and\nOpportunities. fairmlbook.org. http://www.fairmlbook.org\n\n\nShmueli, G. (2010). To Explain or to\nPredict? Statistical Science, 25(3), 289–310.\nhttps://doi.org/10.1214/10-sts330\n\n\nShmueli, G., & Koppius, O. (2011). Predictive\nAnalytics in Information Systems Research. MIS\nQuarterly, 35(3), 553. https://doi.org/10.2307/23042796\n\n\nVan der Laan, M. J. (2006). Statistical inference for variable\nimportance. The International Journal of Biostatistics,\n2(1).",
    "crumbs": [
      "Analyse",
      "Referenties"
    ]
  }
]