[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "No Fairness without Awareness - Advanced",
    "section": "",
    "text": "Samenvatting\nIn deze analyse onderzoeken we Retentie na 1 jaar voor de opleiding B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars, van de faculteit IT & Design (ITD).",
    "crumbs": [
      "Samenvatting"
    ]
  },
  {
    "objectID": "index.html#samenvatting-analyse-kansengelijkheid",
    "href": "index.html#samenvatting-analyse-kansengelijkheid",
    "title": "No Fairness without Awareness - Advanced",
    "section": "Samenvatting analyse kansengelijkheid",
    "text": "Samenvatting analyse kansengelijkheid\n\nToon code\nlDfFairness &lt;- list()\n\n# Walk over the variables\nfor(i in c(lSensitive_labels)) {\n  sFairness_outputpath  &lt;- Get_Model_Outputpath(mode = \"fairness\", group = i)\n  lDfFairness[[i]]      &lt;- readRDS(sFairness_outputpath) |&gt; \n    mutate(FRN_Bias = case_when(FRN_Score &lt; 0.8 ~ \"Negatieve Bias\",\n                                FRN_Score &gt; 1.25 ~ \"Positieve Bias\", \n                                .default = \"Geen Bias\")) \n}\n\n# Create a table from the fairness analysis\ndfFairness_wide  &lt;- Get_dfFairness_Wide(lDfFairness)\n\nDe uitkomsten van de kansengelijkheidsanalyse is:\n\n\nToon code\n# Now create a text per variable from the table\nlConclusies &lt;- list()\nfor(i in lSensitive_labels) {\n  lConclusies[[i]] &lt;- Get_Fairness_Conclusies(dfFairness_wide, i)\n  # print(lConclusies[[i]])\n}\n\n# Dynamically generate the conclusions in text\nj &lt;- 1\nfor (i in lSensitive_labels) {\n  cat(glue(\"{j}.  **{i}**: {lConclusies[[i]]} \\n\\n\"))\n  j &lt;- j + 1\n}\n\n\nGeslacht: Er is sprake van bias in Retentie na 1 jaar op basis van geslacht. Er is een positieve bias voor: V.\nAansluiting: Er is sprake van bias in Retentie na 1 jaar op basis van aansluiting. Er is een negatieve bias voor: 2e Studie.\n\nVooropleiding: Er is sprake van bias in Retentie na 1 jaar op basis van vooropleiding. Er is een negatieve bias voor: BD.\n\n\n\nToon code\nftFairness_table &lt;- Get_ftFairness(flextable(dfFairness_wide))\n\n# Print the flextable\nftFairness_table\n\n\n\n\nTabel 1: Fairness conclusies per groep\n\n\nVariabeleGroepN%BiasGeen BiasNegatieve BiasPositieve BiasGeslachtM91556,7NTB000V69843,3Ja302AansluitingDirect75646,9NTB000Tussenjaar17610,9Nee500Switch intern20212,5Nee500Switch extern44527,6Nee5002e Studie15 0,9Ja320Na CD19 1,2Nee410VooropleidingMBO52232,4Nee500HAVO86053,3NTB000VWO58 3,6Nee500BD92 5,7Ja320CD30 1,9Nee410HO51 3,2Nee500\n\n\n\nToelichting:\n\nBij rood is er sprake van een negatieve bias.\nBij groen is er sprake van een positieve bias.\nBij oranje is er sprake van een bias, maar zijn de aantallen studenten te laag om conclusies over een negatieve of positieve bias aan te verbinden.\nEr zijn vijf aspecten op basis waarvan de mate van bias gescoord wordt; het aantal in de kolommen geeft aan op hoeveel aspecten het oordeel over bias is gebaseerd. Voor een oordeel moet er minimaal op twee aspecten sprake zijn van bias.\nWe hanteren een minimum van 15 studenten per categorie binnen een variabele.\nDe bevoorrechte groep is grijs. Hiervan dient een eventuele bias nader bepaald te worden (NTB = Nader te bepalen). Dit is het geval als alle overige groepen binnen een variabelen een bias hebben.\n\nZie voor een verdere onderbouwing van deze uitkomsten de volgende hoofdstukken in de analyse.",
    "crumbs": [
      "Samenvatting"
    ]
  },
  {
    "objectID": "index.html#vragen-of-suggesties",
    "href": "index.html#vragen-of-suggesties",
    "title": "No Fairness without Awareness - Advanced",
    "section": "Vragen of suggesties",
    "text": "Vragen of suggesties\nHeb je vragen of suggesties over deze analyse? Neem dan contact op met Theo Bakker via 06-25637172 of per mail via t.c.bakker@hhs.nl.\n\n \nCopyright\nDr. Theo Bakker, lector Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.",
    "crumbs": [
      "Samenvatting"
    ]
  },
  {
    "objectID": "ch1-introduction.html",
    "href": "ch1-introduction.html",
    "title": "1  Inleiding",
    "section": "",
    "text": "1.1 Onderzoek naar kansengelijkheid\nIn deze analyse onderzoeken we Retentie na 1 jaar voor de opleiding B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars, van de faculteit IT & Design (ITD).\nHet lectoraat Learning Technology & Analytics (LTA) van De Haagse Hogeschool heeft tot doel kansengelijkheid voor studenten te verhogen met behulp van learning analytics en inzet van learning technology.\nHet lectoraat heeft een onderzoeksmethode ontwikkeld om te kunnen analyseren of er sprake is van bias in studiedata in relatie tot het succes van studenten, wat een indicatie kan zijn van een gebrek aan kansengelijkheid. Deze methode gebruikt prognosemodellen op basis van machine learning. Een prognosemodel is dus niet een doel op zich, maar het instrument voor een analyse van kansengelijkheid, ook wel een fairness analyse genoemd.\nOver deze methode heeft de lector, Dr. Theo Bakker, zijn intreerede uitgesproken op 21 november 2024, getiteld: ‘No Fairness without Awareness. Toegepast onderzoek naar kansengelijkheid in het hoger onderwijs. Intreerede lectoraat Learning Technology & Analytics.’ (Bakker, 2024). Zie voor een verdere toelichting op het gehele onderzoeksprogramma: ‘No Fairness without Awareness’.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inleiding</span>"
    ]
  },
  {
    "objectID": "ch1-introduction.html#het-nut-van-prognosemodellen",
    "href": "ch1-introduction.html#het-nut-van-prognosemodellen",
    "title": "1  Inleiding",
    "section": "1.2 Het nut van prognosemodellen",
    "text": "1.2 Het nut van prognosemodellen\nPrognosemodellen kunnen inzicht bieden in de factoren die gecorreleerd zijn aan de uitval of - als tegenhanger - de retentie van studenten. Met deze inzichten kan een opleiding interventies ontwikkelen om uitval te verminderen of te voorkomen en retentie te bevorderen. Denk aan een betere voorlichting, onboarding, begeleiding of ontwikkeling van het onderwijs.\nVoor de uitleg van de toepassing van deze methode om kansengelijkheid op te sporen is retentie beter te volgen dan uitval. Vandaar dat we in deze analyse retentie na 1 jaar als uitkomstvariabele nemen.\n\n\n\n\n\n\nDisclaimer\n\n\n\nDe prognosemodellen die we in deze analyses ontwikkelen zijn bedoeld om de dynamiek in het studiesucces van studenten een opleiding beter te begrijpen om kansengelijkheid te bevorderen.\nDeze modellen mogen op geen enkele wijze gebruikt worden om individuele studenten te beoordelen of hun succes te voorspellen.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inleiding</span>"
    ]
  },
  {
    "objectID": "ch1-introduction.html#opbouw-analyse",
    "href": "ch1-introduction.html#opbouw-analyse",
    "title": "1  Inleiding",
    "section": "1.3 Opbouw analyse",
    "text": "1.3 Opbouw analyse\nDeze analyse kent drie hoofdstukken:\n\nHoofdstuk 2: Kansengelijkheid - De uitkomsten van analyse op bias en kansengelijkheid.\nHoofdstuk 3: Factoranalyse - Een verdiepende analyse op de achterliggende factoren.\nHoofdstuk 4: Prognosemodel retentie na 1 jaar - De ontwikkeling van een aantal achterliggende prognosemodellen om retentie na 1 jaar te voorspellen, waaruit het best presterende model wordt gekozen.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inleiding</span>"
    ]
  },
  {
    "objectID": "ch1-introduction.html#vragen-of-suggesties",
    "href": "ch1-introduction.html#vragen-of-suggesties",
    "title": "1  Inleiding",
    "section": "1.4 Vragen of suggesties",
    "text": "1.4 Vragen of suggesties\nHeb je vragen of suggesties over deze analyse? Neem dan contact op met Theo Bakker via 06-25637172 of per mail via t.c.bakker@hhs.nl.\n\n\n \nVerantwoording\nDeze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: No Fairness without Awareness | Het rapport is door het lectoraat ontwikkeld in Quarto 1.6.39.\n\n \nCopyright\nDr. Theo Bakker, lector Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.\n\n\n\n\n\n\n\nBakker, T. (2024). No Fairness without Awareness. Toegepast onderzoek naar kansengelijkheid in het hoger onderwijs. Intreerede lectoraat Learning Technology & Analytics. The Hague University of Applied Sciences. https://doi.org/10.5281/zenodo.14204674",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inleiding</span>"
    ]
  },
  {
    "objectID": "ch2-equity.html",
    "href": "ch2-equity.html",
    "title": "2  Analyse van kansengelijkheid",
    "section": "",
    "text": "2.1 Inleiding\nIn dit hoofdstuk gaan we in op de onderwerpen bias, fairness en kansengelijkheid. Het doel is beter te begrijpen of er studenten zijn met minder kans op succes en of dit disproportioneel is. Dit kan duiden op kansenongelijkheid.\nDe analyse van kansengelijkheid heeft de volgende stappen:",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "ch2-equity.html#inleiding",
    "href": "ch2-equity.html#inleiding",
    "title": "2  Analyse van kansengelijkheid",
    "section": "",
    "text": "We lezen een bewerkte dataset in en prognosemodellen die we in een basis-analyse hebben gemaakt (zie hoofdstuk 3).\nWe maken een explainer om de modellen beter te begrijpen en te kunnen uitleggen.\nVervolgens berekenen we of er bias bestaat voor verschillende groepen studenten naar geslacht, aansluiting en vooropleiding. We analyseren daarvoor de verdeling van kansen en mate van fairness in het prognosemodel dat we hebben ontwikkeld.\nWe trekken er conclusies uit over de mate van bias binnen de opleiding voor retentie na 1 jaar.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "ch2-equity.html#voorbereidingen",
    "href": "ch2-equity.html#voorbereidingen",
    "title": "2  Analyse van kansengelijkheid",
    "section": "2.2 Voorbereidingen",
    "text": "2.2 Voorbereidingen\n\n2.2.1 Laad de data\nWe laden de bewerkte data en het beste prognosemodel in voor:\nOpleiding: ITD | B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars - Retentie na 1 jaar\n\n\n\nToon code\n## Create a list of dfPersonas\nlDfPersona &lt;- list()\n\n## Walk over the variables\nlDfPersona &lt;- map(lSensitive_labels,\n                  ~ Get_dfPersona_Recursive(.x)) |&gt;\n  set_names(lSensitive_labels)\n\ndfPersona_per_group &lt;- bind_rows(lDfPersona) \n\n## Save this file as an Excel spreadsheet\nsOutputPath &lt;- file.path(\"R/data\", \"dfPersona_per_group.xlsx\")\nwritexl::write_xlsx(dfPersona_per_group, sOutputPath)\n\n## Load the personas\ndfPersona_all &lt;- Get_dfPersona_Recursive()\n\n\n\n\n2.2.2 Maak een explainer\nOm het model beter te begrijpen en te kunnen uitleggen, maken we met behulp van het DALEX package een explainer.\nDALEX is onder andere ontwikkeld om uit te kunnen leggen welke verklarende variabelen van belang zijn en wat deze voor een effect hebben in een model. Een explainer is een model-onafhankelijke wrapper, die inzicht geeft in de voorspellingen van het model en de bijdrage van de variabelen aan de prognose. Een explainer maakt het verder mogelijk om modellen onderling te vergelijken en benchmarken.\n\n\n\nToon code\n# Select the best model\nsBest_model &lt;- dfModel_results$model[dfModel_results$best == TRUE]\nlast_fit    &lt;- lLast_fits[[sBest_model]]\n\nfitted_model &lt;- last_fit |&gt;\n  extract_fit_parsnip()\n\n# If the model is logistic regression, check that the coefficients of the model are numerical\nif(sBest_model == \"Logistic Regression\") {\n  \n  coefs &lt;- tidy(fitted_model)$estimate\n  \n  # Check that the coefficients are numerical\n  if (!is.numeric(coefs)) {\n    stop(\"De geëxtraheerde coëfficiënten zijn niet numeriek.\")\n  }\n  \n}\n\n\n\n\n\nToon code\n# Extract the fitted model\nfitted_model &lt;- last_fit |&gt;\n  extract_fit_parsnip()\n\n# Extract the workflow\nworkflow &lt;- last_fit |&gt;\n  extract_workflow()\n\n# Create an explainer\nexplain_lf &lt;- DALEX::explain(\n  model = workflow,\n  data = dfOpleiding_inschrijvingen |&gt; select(-Retentie),\n  y = dfOpleiding_inschrijvingen$Retentie,\n  colorize = TRUE,\n  verbose = TRUE,\n  label = sBest_model)\n\n\nPreparation of a new explainer is initiated\n  -&gt; model label       :  Random Forest \n  -&gt; data              :  1613  rows  26  cols \n  -&gt; target variable   :  1613  values \n  -&gt; predict function  :  yhat.workflow  will be used ( \u001b[33m default \u001b[39m )\n  -&gt; predicted values  :  No value for predict function target column. ( \u001b[33m default \u001b[39m )\n  -&gt; model_info        :  package tidymodels , ver. 1.2.0 , task classification ( \u001b[33m default \u001b[39m ) \n  -&gt; predicted values  :  numerical, min =  0.1759112 , mean =  0.6193215 , max =  0.9273344  \n  -&gt; residual function :  difference between y and yhat ( \u001b[33m default \u001b[39m )\n  -&gt; residuals         :  numerical, min =  -0.841733 , mean =  0.001881272 , max =  0.7484622  \n \u001b[32m A new explainer has been created! \u001b[39m \n\n\nToon code\nif(is.null(explain_lf$y_hat) || is.null(explain_lf$residuals)) {\n  cli::cli_alert_danger(glue::glue(\n    \"The explainer does not contain the correct results. \",\n    \"Check the installation of model packages: {glue::glue_collapse(explain_lf$model_info$package, sep = ', ')}\"\n  ))\n  stop(\"Solve this problem first\")\n}",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "ch2-equity.html#analyse-van-kansengelijkheid",
    "href": "ch2-equity.html#analyse-van-kansengelijkheid",
    "title": "2  Analyse van kansengelijkheid",
    "section": "2.3 Analyse van kansengelijkheid",
    "text": "2.3 Analyse van kansengelijkheid\nWe onderzoeken kansengelijkheid door bias in de data te onderzoeken. Dit wordt ook wel een fairness analyse genoemd. Bias voor verschillende groepen studenten kan een teken zijn van kansenongelijkheid.\nHet leidende werk voor fairness analyses is Fairness and Machine Learning: Limitations and Opportunities (Barocas et al., 2023). De methode die we in deze analyse hanteren hierop gebaseerd. We maken gebruik van de DALEX explainer en onderzoeken de invloed van de variabelen op de kans op retentie voor verschillende groepen studenten naar geslacht, aansluiting en vooropleiding.\nDe volgende definities zijn van belang:\n\nBevoorrechte groep: Een groep die als referentiegroep wordt beschouwd en mogelijk bevoordeeld wordt. Dit is in deze analyse altijd de meerderheidsgroep (bijv. vrouwen). Welke dit is per opleiding kan verschillen.\nBeschermde groep: Een groep waarvan wordt verwacht dat deze mogelijk benadeeld wordt (bijv. mannen). Dit zijn in deze analyse, afhankelijke van de variabele, altijd een of meer minderheidsgroepen.\n\n\n\n2.3.1 Ratio’s om kansengelijkheid te beoordelen\nVoor elke groep onderzoeken we 5 ratio’s, ook wel maatstaven of metrieken genoemd. Deze ratio’s zijn afgeleid van verhoudingen in de confusion matrix; ze geven inzicht in de mate van bias en kansengelijkheid vanuit verschillende perspectieven van een prognosemodel.\n\n\nToon code\nknitr::include_graphics(here::here(\"R/images\", \"confusion-matrix-fairness-lta-hhs.png\"))\n\n\n\n\n\n\n\n\nFiguur 2.1: Confusion matrix in relatie tot BSA\n\n\n\n\n\n\n1. Accuracy Equality2. Equal Opportunity3. Predictive Equality4. Predictive Parity5. Statistical Parity\n\n\n1. Accuracy Equality Ratio\nIn welke mate voorspelt het model zowel de positieve als negatieve uitkomsten goed?\nDeze maatstaf wordt gebruikt om te beoordelen of een model even accuraat is voor verschillende subgroepen binnen de dataset. Het vergelijkt de nauwkeurigheid van het model voor een beschermde groep (een minderheidsgroep) met de nauwkeurigheid voor een bevoorrechte groep (de meerderheidsgroep). Deze ratio wordt berekend als de verhouding tussen de nauwkeurigheid voor de beschermde groep en de nauwkeurigheid voor de bevoorrechte groep.\nFormule\n \\text{ACC} = \\frac{TP + TN}{TP + FP + TN + FN} \nDefinities\n\nNauwkeurigheid (Accuracy): Het percentage correcte voorspellingen van het model. Dit wordt berekend als het aantal juiste voorspellingen gedeeld door het totale aantal voorspellingen.\n\nInterpretatie\n\nRatio = 1: Het model is even accuraat voor beide groepen.\nRatio &lt; 1: Het model is minder accuraat voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model is meer accuraat voor de beschermde groep dan voor de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de nauwkeurigheid van het model voor havisten 80% is en voor mbo-ers 70%. De Accuracy Equality Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder accuraat is voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).\n\n\n\n\n2. Equal Opportunity Ratio\nIn welke mate zijn de terecht positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van kansen die een model biedt aan verschillende subgroepen in termen van de ‘True Positive Rate’ (TPR). Het vergelijkt de kans dat een model correct een positieve uitkomst voorspelt voor een beschermde groep versus een bevoorrechte groep.\nDe True Positive Rate (TPR) is een andere term voor de sensitiviteit (ook wel recall) genoemd. De Equal Opportunity Ratio wordt berekend als het aantal true positives gedeeld door het totaal aantal werkelijke positives.\nFormule\n \\text{TPR} = \\frac{TP}{TP + FN} \nDefinities\n\nTP: True Positives (correcte voorspellingen van positieve uitkomsten)\nFN: False Negatives (werkelijke positieve uitkomsten die foutief als negatief zijn voorspeld)\n\nInterpretatie\n\nRatio = 1: Het model biedt gelijke kansen aan beide groepen in termen van het correct voorspellen van positieve uitkomsten.\nRatio &lt; 1: Het model biedt minder kansen aan de beschermde groep in vergelijking met de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model biedt meer kansen aan de beschermde groep in vergelijking met de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de True Positive Rate voor havisten 70% is en voor mbo-ers 60%. De Equal Opportunity Ratio is dan 0,857 (60% / 70%). Dit betekent dat het model minder kans biedt aan de beschermde groep (mbo-ers) om correct positieve uitkomsten te voorspellen dan aan de bevoorrechte groep (havisten).\n\n\n\n\n3. Predictive Equality Ratio\nIn welke mate zijn de vals positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van het aantal False Positives (vals-positieven) tussen verschillende subgroepen. Het vergelijkt de False Positive Rate (FPR) voor een beschermde groep met de FPR voor een bevoorrechte groep.\nDe FPR is de verhouding van het aantal vals-positieve voorspellingen (False Positives, FP) ten opzichte van het totaal aantal werkelijke negatieve gevallen (True Negatives, TN en False Positives, FP). De Predictive Equality Ratio wordt berekend als de verhouding tussen de FPR voor de beschermde groep en de FPR voor de bevoorrechte groep.\nFormule\n \\text{FPR} = \\frac{FP}{FP + TN} \nDefinities\n\nFP: False Positives (foutieve voorspellingen van positieve uitkomsten)\nTN: True Negatives (correcte voorspellingen van negatieve uitkomsten)\n\nInterpretatie\n\nRatio = 1: Het model heeft een gelijke kans om False Positives te maken voor beide groepen.\nRatio &lt; 1: Het model heeft minder kans om False Positives te maken voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias ten nadele van de bevoorrechte groep.\nRatio &gt; 1: Het model heeft meer kans om False Positives te maken voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias ten nadele van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de False Positive Rate voor havisten 20% is en voor mbo-ers 30%. De Predictive Equality Ratio is dan 1,5 (30% / 20%). Dit betekent dat het model meer kans heeft om vals-positieve voorspellingen te maken voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).\n\n\n\n\n4. Predictive Parity Ratio\nIn welke mate zijn de terecht positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van de nauwkeurigheid van de voorspelling tussen verschillende subgroepen door de positieve voorspellende waarde (Positive Predictive Value, PPV) van het model voor een beschermde groep te vergelijken met die voor een bevoorrechte groep. De PVV wordt ook wel de precisie genoemd en wordt berekend als het aantal true positives (TP) gedeeld door het totaal aantal voorspelde positives (TP en FP). Het is een maat voor de nauwkeurigheid van de positieve voorspellingen van het model.\nFormule\n \\text{PPV} = \\frac{TP}{TP + FP} \nDefinities\n\nTP: True Positives (correcte voorspellingen van positieve uitkomsten)\nFP: False Positives (foutieve voorspellingen van positieve uitkomsten)\n\nInterpretatie\n\nRatio = 1: Het model heeft een gelijke nauwkeurigheid in voorspellingen voor beide groepen.\nRatio &lt; 1: Het model is minder nauwkeurig in het voorspellen van positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model is nauwkeuriger in het voorspellen van positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de Positive Predictive Value voor havisten 80% is en voor mbo-ers 70%. De Predictive Parity Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder nauwkeurig is in het voorspellen van positieve uitkomsten voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).\n\n\n\n\n5. Statistical Parity Ratio\nIn welke mate zijn de positieve voorspellingen gelijk?\nDeze maatstaf beoordeelt de gelijkheid van de positieve voorspellingen (ongeacht of ze correct zijn of niet) tussen verschillende subgroepen. Het vergelijkt de kans dat een model een positieve uitkomst voorspelt voor een beschermde groep met de kans dat het een positieve uitkomst voorspelt voor een bevoorrechte groep. De Statistical Parity Ratio wordt berekend als de verhouding tussen de kans op een positieve voorspelling voor de beschermde groep en de kans op een positieve voorspelling voor de bevoorrechte groep.\nFormule\n \\text{SPR} = \\frac{TP + FP}{TP + FP + TN + FN} \nDefinities\n\nPositieve Voorspelling: Een voorspelling waarin het model een positieve uitkomst voorspelt (bijv. aangenomen worden, krediet goedkeuring, etc.).\n\nInterpretatie\n\nRatio = 1: Het model voorspelt even vaak positieve uitkomsten voor beide groepen.\nRatio &lt; 1: Het model voorspelt minder vaak positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.\nRatio &gt; 1: Het model voorspelt vaker positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat kan wijzen op bias ten nadele van de bevoorrechte groep.\n\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de kans op een positieve voorspelling voor havisten 80% is en voor mbo-ers 70%. De Statistical Parity Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder vaak positieve uitkomsten voorspelt voor de beschermde groep (havisten) dan voor de bevoorrechte groep (mbo-ers).\n\n\n\n\n\nNu we deze begrippen hebben gedefinieerd, kunnen we de bias en kansengelijkheid van het model voor verschillende groepen studenten analyseren. Hiervoor gebruiken we het fairmodels package van DALEX.\n\n\n\n2.3.2 Aantallen en percentages per groep\nVoor de variabelen Geslacht, Aansluiting en Vooropleiding is de verdeling binnen deze opleiding als volgt:\n\nToon code\n# Create a table with numbers and percentages for the 3 sensitive \n\ntbl_summary &lt;- dfOpleiding_inschrijvingen |&gt; \n  select(Retentie, all_of(lSensitive_labels)) |&gt; \n  mutate(Retentie = ifelse(Retentie == 1, \"Ja\", \"Nee\")) |&gt;\n  tbl_summary(by = Retentie) |&gt; \n  add_p(pvalue_fun = ~ style_pvalue(.x, digits = 2),\n          test.args = list(\n            all_tests(\"fisher.test\") ~ list(simulate.p.value = TRUE),\n            all_tests(\"wilcox.test\") ~ list(exact = FALSE)\n          )) |&gt; \n    add_significance_stars(\n      hide_p = FALSE,\n      pattern = \"{p.value}{stars}\"\n    ) |&gt;\n  add_overall(col_label = \"**Totaal**  \\nN = {style_number(N)}\") |&gt;\n  add_n() |&gt;\n  modify_header(label ~ \"**Variabele**\") |&gt; \n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Retentie na 1 jaar**\") |&gt;\n  bold_labels() |&gt; \n  as_flex_table() |&gt; \n  flextable::border(border.top = fp_border(color = \"grey\")) |&gt; \n  set_table_properties(width = 0.8, layout = \"autofit\")\n\n\n# Print summary table\ntbl_summary\n\n\n\n\nTabel 2.1: Aantallen en percentages naar geslacht, aansluiting en vooropleiding in relatie tot retentie\n\n\n Retentie na 1 jaar VariabeleNTotaal  N = 1.6131Ja  N = 1.0021Nee  N = 6111p-value2Geslacht1.613&lt;0,001***M915 (57%)521 (52%)394 (64%)V698 (43%)481 (48%)217 (36%)Aansluiting1.613&lt;0,001***Direct756 (47%)455 (45%)301 (49%)Tussenjaar176 (11%)125 (12%)51 (8,3%)Switch intern202 (13%)148 (15%)54 (8,8%)Switch extern445 (28%)254 (25%)191 (31%)2e Studie15 (0,9%)6 (0,6%)9 (1,5%)Na CD19 (1,2%)14 (1,4%)5 (0,8%)Overig0 (0%)0 (0%)0 (0%)Onbekend0 (0%)0 (0%)0 (0%)Vooropleiding1.6130,012*MBO522 (32%)330 (33%)192 (31%)HAVO860 (53%)548 (55%)312 (51%)VWO58 (3,6%)34 (3,4%)24 (3,9%)BD92 (5,7%)42 (4,2%)50 (8,2%)CD30 (1,9%)21 (2,1%)9 (1,5%)HO51 (3,2%)27 (2,7%)24 (3,9%)Overig0 (0%)0 (0%)0 (0%)Onbekend0 (0%)0 (0%)0 (0%)1n (%)2*p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n\n\n\n\n2.3.3 Verdeling van kansen\nVoordat we in meer detail kansengelijkheid gaan analyseren, onderzoeken we de verdeling van de kansen op retentie voor verschillende groepen studenten voor Geslacht, Aansluiting en Vooropleiding. De verdeling van deze kansen is uniek per opleiding.\nToelichting\n\nDe verdeling van de kansen is te zien door de boxplot en de violin plot.\nDe boxplot geeft de vier quartielen aan van de data: de box staat voor de middelste 50% van de data, met een streep die de mediaan aangeeft (de middelste waarde van de data). De lijnen (whiskers) geven de 1e 25% en laatste 25% van de data.\nDe boxplot wordt gecombineerd met de violin plot, waarbij de breedte van de violin de dichtheid van de data aangeeft. Het kan zijn dat het lijkt alsof er geen violin is; in dat geval is de verdeling van het aantal studenten zeer breed en de violin vorm daardoor heel smal.\nSamen geven deze twee visualisaties een goed beeld van de verdeling van de voorspelde kansen van het model.\nDe blauwe gestippelde lijn geeft de 50% kans aan; alle waarden die boven deze lijn vallen hebben een kans van 50% of meer op retentie. Hiervan voorspelt het model dat zij zeker doorstuderen. Deze grenslijn kan door de verdeling van groepen heen lopen. Bedenk in zo’n situatie dat voor een deel van de studenten het model voorspelt dat zij juist wel doorstromen (50% of meer) of juist niet (minder dan 50%).\n\n\nToon code\n# Make a fairness analysis\nfor(group in c(lSensitive_labels)) {\n\n  # Group\n  Knit_Header(group, 4)\n  \n  # Determine the most common subgroup = Privileged\n  sPrivileged &lt;- Get_Privileged(dfOpleiding_inschrijvingen, group)\n\n  # Create a fairness object\n  fobject &lt;- Get_objFairness(explain_lf, group, sPrivileged)\n  \n  # Create a table from the fairness analysis\n  dfFairness_totaal &lt;- Get_dfFairness_Total(fobject)\n  \n  # Create a plot of the fairness analysis\n  density_plot &lt;- suppressWarnings(\n    Get_Density_Plot(fobject, group = group) \n  ) \n\n  # Save the plot\n  sPlotname &lt;- glue(\"density_plot_{tolower(group)}\")\n  sPlotPath &lt;- Get_Plot_Outputpath(sPlotname, mode = \"plot\", \n                                   bestmodel = sBest_model)\n\n  suppressWarnings(\n        Finalize_Plot(\n          plot_name = density_plot,\n          save_filepath = sPlotPath,\n          height_pixels = 250 + (50 * length(unique(dfFairness_totaal$Categorie)))\n        ))\n\n  # Show the existing plot\n  sPlot &lt;- glue(\"![Verdeling en dichtheid van {tolower(lResearch_settings[['sSucces_label']])} naar  {tolower(group)}]({sPlotPath}){{#fig-fairness-check-{tolower(group)}}}\")\n  Knit_Print_Rule(sPlot)\n\n}\n\n\n2.3.3.1 Geslacht\n\n\n\n\n\n\nFiguur 2.2: Verdeling en dichtheid van kans op retentie naar geslacht\n\n\n\n\n\n2.3.3.2 Aansluiting\n\n\n\n\n\n\nFiguur 2.3: Verdeling en dichtheid van kans op retentie naar aansluiting\n\n\n\n\n\n2.3.3.3 Vooropleiding\n\n\n\n\n\n\nFiguur 2.4: Verdeling en dichtheid van kans op retentie naar vooropleiding\n\n\n\n\n\n\n2.3.4 Fairness checks\nNu we de verdeling van de kansen kennen, maken we een fairness analyse voor Geslacht, Aansluiting en Vooropleiding. Voor elke groep berekenen we de maatstaven die we eerder hebben behandeld.\nWe maken een plot van de fairness analyse, waarbij we per variabele één categorie nemen als de bevoorrechte groep; hiervoor hanteren we – zoals al aangegeven – per variabele de meest frequente groep. Het is waarschijnlijk dat in een opleiding de voorlichting, begeleiding en onderwijs het meest heeft afgestemd op deze groep.\nAls binnen een variabele een groep een ratio heeft die naar links of naar rechts afwijkt, kan dit duiden op een verschil in kansengelijkheid. Let erop dat de bevoorrechte groep zelf hier niet in is opgenomen (!). Mochten alle overige groepen naar links of rechts afwijken, dan is er sprake van een bias naar de bevoorrechte groep.\nHet wijkt af als de balken verder buiten het groene vlak komen en in het rode vlak; dit is gebaseerd op een marge, epsilon, van 0,8. Deze marge is gebaseerd op het 4/5 principe: er is sprake van een te groot verschil als de maat voor een beschermde groep 4/5 of meer afwijkt van de bevoorrechte groep. Een epsilon van 0,8 leidt tot marges van -0,2 (epsilon/1) en +0,25 (1/espilon). Als er twee ratio’s of meer buiten deze marges vallen, is er volgens dit criterium sprake van bias. Als een maatstaf naar links afwijkt is er sprake van bias naar de beschermde groep (ten nadele), als deze naar rechts afwijkt is er sprake van bias naar de bevoorrechte groep (ten voordele).\nAlle afwijkingen samen worden opgeteld als absolute waarden en uitgedrukt in de maat ‘Totaal verlies’. Hoe hoger de waarde hiervan is, des te groter de verschillen zijn tussen groepen.\n\n\n\n\n\n\nNota Bene\n\n\n\nAls de uitkomstmaat van een model negatief is (zoals uitval), dan moet de interpretatie precies andersom gemaakt worden. Dit geldt voor alle maatstaven van bias en fairness in dit hoofdstuk.\n\n\nOm de robuustheid en betrouwbaarheid in de detectie van bias te waarborgen, moeten er minstens twee metrieke waarden buiten de epsilon-marges vallen voordat er sprake is van bias (Barocas et al., 2023).\n\nHiervoor is een aantal redenen:\n1. Meerdere indicatoren: Het gebruik van meerdere maatstaven zorgt ervoor dat we de detectie van bias niet baseren op slechts een, mogelijk ruisgevoelige, indicator. Als slechts één metriek buiten de marges valt, kan dit toeval zijn of te wijten zijn aan andere niet-systematische fouten in de data. We spreken dan nog niet over bias. Meerdere metrieke afwijkingen geven een sterkere indicatie van een systematisch probleem.\n2. Differentie van bias types: Bias kan zich op verschillende manieren manifesteren, bijvoorbeeld in termen van ongelijksoortige impact, ongelijke kansen in voorspellingen of ongelijke behandeling. Door meerdere maatstaven te evalueren, onderzoeken we een breder spectrum van potentiële bias en zien we geen aspecten over het hoofd.\n3. Normatieve overwegingen: Vaak is er een normatieve basis voor het definiëren van wat eerlijk is. Het vergelijken van meerdere maatstaven kan helpen om genuanceerder en vollediger beeld te krijgen van hoe een model presteert ten opzichte van verschillende fairness criteria.\nDe keuze voor twee maatstaven als minimum baseren we op een combinatie van statistische overwegingen en praktische normen binnen het machine learning vakgebied om een goed evenwicht te vinden tussen sensitiviteit (het detecteren van daadwerkelijke bias) en specificiteit (het vermijden van vals positieven) (Barocas et al., 2023).\n\nToon code\n# Make a fairness analysis\nfor(group in c(lSensitive_labels)) {\n\n  # Group\n  Knit_Header(group, 4)\n  \n  # Determine the most common subgroup = Privileged\n  sPrivileged &lt;- Get_Privileged(dfOpleiding_inschrijvingen, group)\n\n  # Create a fairness object\n  fobject &lt;- Get_objFairness(explain_lf, group, sPrivileged)\n\n  # Create a table from the fairness analysis\n  dfFairness_totaal &lt;- Get_dfFairness_Total(fobject)\n  \n  # Check for bias\n  Print_Fairness_Object_LTA(fobject)\n\n  # Create a plot of the fairness analysis\n  fairness_plot &lt;- suppressWarnings(\n    Get_Fairness_Plot(fobject, group = group, privileged = sPrivileged) +\n      theme(panel.border = element_rect(\n        colour = \"darkgrey\",\n        fill = NA,\n        size = 0.4\n      ))\n  )\n\n  # Save the plot\n  sPlotname &lt;- glue(\"fairness_plot_{tolower(group)}\")\n  sPlotPath &lt;- Get_Plot_Outputpath(sPlotname, mode = \"plot\", bestmodel = sBest_model)\n\n  suppressWarnings(\n        Finalize_Plot(\n          plot_name = fairness_plot,\n          save_filepath = sPlotPath,\n          height_pixels = 250 + (50 * length(unique(dfFairness_totaal$Categorie)))\n        ))\n\n  # Show the existing plot\n  sPlot &lt;- glue(\"![Fairness check naar {tolower(group)}]({sPlotPath}){{#fig-fairness-check-{tolower(group)}}}\")\n  Knit_Print_Rule(sPlot)\n  \n  # Keep the fairness check data\n  sFairness_outputpath  &lt;- Get_Model_Outputpath(mode = \"fairness\", group = group)\n  dfFairness_check_data &lt;- Get_dfFairness_Check_Data(fobject[[\"fairness_check_data\"]], group = group)\n  saveRDS(dfFairness_check_data, file = sFairness_outputpath)\n  \n}\n\n\n2.3.4.1 Geslacht\nPrognosemodel (Random Forest) niet geslaagd: 3 van 5 maatstaven Totaal verlies : 1.84\n\n\n\n\n\n\nFiguur 2.5: Fairness check naar geslacht\n\n\n\n\n\n2.3.4.2 Aansluiting\nPrognosemodel (Random Forest) niet geslaagd: 1 van 5 maatstaven Totaal verlies : 2.82\n\n\n\n\n\n\nFiguur 2.6: Fairness check naar aansluiting\n\n\n\n\n\n2.3.4.3 Vooropleiding\nPrognosemodel (Random Forest) niet geslaagd: 3 van 5 maatstaven Totaal verlies : 3.16\n\n\n\n\n\n\nFiguur 2.7: Fairness check naar vooropleiding",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "ch2-equity.html#conclusies",
    "href": "ch2-equity.html#conclusies",
    "title": "2  Analyse van kansengelijkheid",
    "section": "2.4 Conclusies",
    "text": "2.4 Conclusies\n\nToon code\nlDfFairness &lt;- list()\n\n# Walk over the variables\nfor(i in c(lSensitive_labels)) {\n  sFairness_outputpath  &lt;- Get_Model_Outputpath(mode = \"fairness\", group = i)\n  lDfFairness[[i]]      &lt;- readRDS(sFairness_outputpath) |&gt; \n    mutate(FRN_Bias = case_when(FRN_Score &lt; 0.8 ~ \"Negatieve Bias\",\n                                FRN_Score &gt; 1.25 ~ \"Positieve Bias\", \n                                .default = \"Geen Bias\")) \n}\n\n# Create a table from the fairness analysis\ndfFairness_wide  &lt;- Get_dfFairness_Wide(lDfFairness)\n\nDe uitkomsten van de kansengelijkheidsanalyse is:\n\n\nToon code\n# Now create a text per variable from the table\nlConclusies &lt;- list()\nfor(i in lSensitive_labels) {\n  lConclusies[[i]] &lt;- Get_Fairness_Conclusies(dfFairness_wide, i)\n  # print(lConclusies[[i]])\n}\n\n# Dynamically generate the conclusions in text\nj &lt;- 1\nfor (i in lSensitive_labels) {\n  cat(glue(\"{j}.  **{i}**: {lConclusies[[i]]} \\n\\n\"))\n  j &lt;- j + 1\n}\n\n\nGeslacht: Er is sprake van bias in Retentie na 1 jaar op basis van geslacht. Er is een positieve bias voor: V.\nAansluiting: Er is sprake van bias in Retentie na 1 jaar op basis van aansluiting. Er is een negatieve bias voor: 2e Studie.\n\nVooropleiding: Er is sprake van bias in Retentie na 1 jaar op basis van vooropleiding. Er is een negatieve bias voor: BD.\n\n\n\nToon code\nftFairness_table &lt;- Get_ftFairness(flextable(dfFairness_wide))\n\n# Print the flextable\nftFairness_table\n\n\n\n\nTabel 2.2: Fairness conclusies per groep\n\n\nVariabeleGroepN%BiasGeen BiasNegatieve BiasPositieve BiasGeslachtM91556,7NTB000V69843,3Ja302AansluitingDirect75646,9NTB000Tussenjaar17610,9Nee500Switch intern20212,5Nee500Switch extern44527,6Nee5002e Studie15 0,9Ja320Na CD19 1,2Nee410VooropleidingMBO52232,4Nee500HAVO86053,3NTB000VWO58 3,6Nee500BD92 5,7Ja320CD30 1,9Nee410HO51 3,2Nee500\n\n\n\nToelichting:\n\nBij rood is er sprake van een negatieve bias.\nBij groen is er sprake van een positieve bias.\nBij oranje is er sprake van een bias, maar zijn de aantallen studenten te laag om conclusies over een negatieve of positieve bias aan te verbinden.\nEr zijn vijf aspecten op basis waarvan de mate van bias gescoord wordt; het aantal in de kolommen geeft aan op hoeveel aspecten het oordeel over bias is gebaseerd. Voor een oordeel moet er minimaal op twee aspecten sprake zijn van bias.\nWe hanteren een minimum van 15 studenten per categorie binnen een variabele.\nDe bevoorrechte groep is grijs. Hiervan dient een eventuele bias nader bepaald te worden (NTB = Nader te bepalen). Dit is het geval als alle overige groepen binnen een variabelen een bias hebben.\n\n\n\n \nVerantwoording\nDeze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: No Fairness without Awareness | Het rapport is door het lectoraat ontwikkeld in Quarto 1.6.39.\n\n \nCopyright\nDr. Theo Bakker, lector Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.\n\n\n\n\n\nBarocas, S., Hardt, M., & Narayanan, A. (2023). Fairness and Machine Learning: Limitations and Opportunities. fairmlbook.org. http://www.fairmlbook.org",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Analyse van kansengelijkheid</span>"
    ]
  },
  {
    "objectID": "ch3-factors.html",
    "href": "ch3-factors.html",
    "title": "3  Analyse van factoren",
    "section": "",
    "text": "3.1 Inleiding\nIn deze verdiepende analyse gaan we in op de factoren om beter te begrijpen hoe deze retentie verklaren.\nDeze verdiepende factoranalyse heeft de volgende stappen:\nDeze verdiepende factoranalyse heeft 6 stappen:",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "ch3-factors.html#inleiding",
    "href": "ch3-factors.html#inleiding",
    "title": "3  Analyse van factoren",
    "section": "",
    "text": "We gebruiken het beste model om de prognose te verklaren en te begrijpen. We kijken naar de bijdrage van de variabelen aan de voorspelling en passen het model toe op de meest voorkomende studenten.\nVervolgens onderzoeken we de stabiliteit van de invloed van de verklarende variabelen met behulp van Shapley waarden.\nDaarna onderzoeken we hoe de retentie er anders uit zou kunnen zien als de studenten andere kenmerken zouden hebben met een Ceteris Paribus analyse.\nTot slot onderzoeken we per variabele de variantie van de voorspellingen met een Partial Dependence analyse.\n\n\n\n\nWe lezen de bewerkte dataset in en de modellen die we in de basis-analyse hebben gemaakt.\nWe maken een explainer om de modellen beter te begrijpen en te kunnen uitleggen. Dit lichten we later in deze pagina toe.\nWe gebruiken het beste model om de prognose te verklaren en te begrijpen. We kijken naar de bijdrage van de variabelen aan de voorspelling en passen het model toe op de meest voorkomende studenten.\nVervolgens onderzoeken we de stabiliteit van de invloed van de verklarende variabelen met behulp van Shapley waarden.\nDaarna onderzoeken we hoe de retentie er anders uit zou kunnen zien als de studenten andere kenmerken zouden hebben met een Ceteris Paribus analyse.\nTot slot onderzoeken we per variabele de variantie van de voorspellingen met een Partial Dependence analyse.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "ch3-factors.html#voorbereidingen",
    "href": "ch3-factors.html#voorbereidingen",
    "title": "3  Analyse van factoren",
    "section": "3.2 Voorbereidingen",
    "text": "3.2 Voorbereidingen\n\n3.2.1 Laad de data\nWe laden de bewerkte data en prognosemodellen in voor:\nOpleiding: ITD | B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars - Retentie na 1 jaar\n\n\n\nToon code\n## Create a list of dfPersonas\nlDfPersona &lt;- list()\n\n## Walk over the variables\nlDfPersona &lt;- map(lSensitive_labels,\n                  ~ Get_dfPersona_Recursive(.x)) |&gt;\n  set_names(lSensitive_labels)\n\ndfPersona_per_group &lt;- bind_rows(lDfPersona) \n\n## Save this file as an Excel spreadsheet\nsOutputPath &lt;- file.path(\"R/data\", \"dfPersona_per_group.xlsx\")\nwritexl::write_xlsx(dfPersona_per_group, sOutputPath)\n\n## Load the personas\ndfPersona_all &lt;- Get_dfPersona_Recursive()",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "ch3-factors.html#verdiepende-analyse-van-het-model",
    "href": "ch3-factors.html#verdiepende-analyse-van-het-model",
    "title": "3  Analyse van factoren",
    "section": "3.3 Verdiepende analyse van het model",
    "text": "3.3 Verdiepende analyse van het model\nWe weten van de factoren nog niet hoe en in welke richting ze retentie verklaren: dragen ze sterk bij of juist niet, verhogen of verlagen ze retentie?\n\n3.3.1 Maak een explainer\nWe gaan nu een stap verder met behulp van het DALEX package. Op basis van het tidymodels model (zie hoofdstuk 3) extraheren we de informatie voor de explainer van Dalex.\n\n\n\nToon code\n# Select the best model\nsBest_model &lt;- dfModel_results$model[dfModel_results$best == TRUE]\nlast_fit    &lt;- lLast_fits[[sBest_model]]\n\nfitted_model &lt;- last_fit |&gt;\n  extract_fit_parsnip()\n\n# If the model is logistic regression, check that the coefficients of the model are numerical\nif(sBest_model == \"Logistic Regression\") {\n  \n  coefs &lt;- tidy(fitted_model)$estimate\n  \n  # Check that the coefficients are numerical\n  if (!is.numeric(coefs)) {\n    stop(\"De geëxtraheerde coëfficiënten zijn niet numeriek.\")\n  }\n  \n}\n\n\n\n\n\nToon code\n# Extract the fitted model\nfitted_model &lt;- last_fit |&gt;\n  extract_fit_parsnip()\n\n# Extract the workflow\nworkflow &lt;- last_fit |&gt;\n  extract_workflow()\n\n# Create an explainer\nexplain_lf &lt;- DALEX::explain(\n  model = workflow,\n  data = dfOpleiding_inschrijvingen |&gt; select(-Retentie),\n  y = dfOpleiding_inschrijvingen$Retentie,\n  colorize = TRUE,\n  verbose = TRUE,\n  label = sBest_model)\n\n\nPreparation of a new explainer is initiated\n  -&gt; model label       :  Random Forest \n  -&gt; data              :  1613  rows  26  cols \n  -&gt; target variable   :  1613  values \n  -&gt; predict function  :  yhat.workflow  will be used ( \u001b[33m default \u001b[39m )\n  -&gt; predicted values  :  No value for predict function target column. ( \u001b[33m default \u001b[39m )\n  -&gt; model_info        :  package tidymodels , ver. 1.2.0 , task classification ( \u001b[33m default \u001b[39m ) \n  -&gt; predicted values  :  numerical, min =  0.1759112 , mean =  0.6193215 , max =  0.9273344  \n  -&gt; residual function :  difference between y and yhat ( \u001b[33m default \u001b[39m )\n  -&gt; residuals         :  numerical, min =  -0.841733 , mean =  0.001881272 , max =  0.7484622  \n \u001b[32m A new explainer has been created! \u001b[39m \n\n\nToon code\nif(is.null(explain_lf$y_hat) || is.null(explain_lf$residuals)) {\n  cli::cli_alert_danger(glue::glue(\n    \"The explainer does not contain the correct results. \",\n    \"Check the installation of model packages: {glue::glue_collapse(explain_lf$model_info$package, sep = ', ')}\"\n  ))\n  stop(\"Solve this problem first\")\n}\n\n\n\n\n3.3.2 Toets de Root Mean Square Error na permutaties\nDe eerste analyse is de Root Mean Square Error (RMSE) na permutaties.\n\nDe RMSE is een maatstaf voor de gemiddelde afwijking van de voorspellingen van een model ten opzichte van de werkelijke waarden. Het wordt berekend als de wortel van de gemiddelde kwadratische fout.\nRMSE na permutaties wil zeggen dat de RMSE is berekend na het herhaaldelijk willekeurig herschikken (permuteren) van de waarden van een variabele in de dataset en daarmee de voorspellingen. Deze techniek passen we toe om de robuustheid en betrouwbaarheid van het model te evalueren.\n\nWaarom is RMSE na permutaties nodig?\n\nModelvalidatie: Door de variabelen te permuteren en de RMSE te berekenen, kunnen we de prestatie van het model vergelijken met een willekeurige schatting. Variabelen die significant beter presteren dan de gemiddelde RMSE na permutaties hebben meer voorspellende kracht.\nOverfit detectie: Als de RMSE van het originele model niet veel beter is dan de RMSE na permutaties, kan dit een indicatie zijn dat het model overfit op de trainingsdata en niet goed generaliseert naar nieuwe data.\n\nDe meeste voorspellende factoren en hun RMSE zijn:\n\n\nToon code\nsPlotPath &lt;- file.path(Get_Plot_Outputpath(plotname = \"lf_model_parts_rmse\", \n                                           bestmodel = sBest_model))\n\n# If the plot does not exist or if recreateplots - T, create a new plot\nif(!file.exists(sPlotPath) | params$recreateplots == TRUE) {\n\n  # Calculate the model parts based on the RMSE; remove ID\n  mp_rmse &lt;- model_parts(explain_lf, loss_function = loss_root_mean_square) |&gt; \n    filter(variable != \"ID\")\n  \n  # Create a plot of the RMSE\n  mp_rmse_plot &lt;- Get_RMSE_Plot(mp_rmse)\n  \n  # Save the plot\n  suppressWarnings(\n    Finalize_Plot(\n      plot_name = mp_rmse_plot,\n      save_filepath = sPlotPath,\n      height_pixels = 50 + (15 * length(unique(mp_rmse$variable)))\n    ))\n\n  # Show the existing plot\n  knitr::include_graphics(sPlotPath)\n      \n} else {\n  \n  # Show the existing plot\n  knitr::include_graphics(sPlotPath)\n  \n}\n\n\n\n\n\n\n\n\nFiguur 3.1: Meest voorspellende factoren - RMSE\n\n\n\n\n\nHet valt op dat de meest voorspellende variabelen ook een hoge RMSE hebben. Dit betekent dat deze variabelen een grote invloed hebben op de voorspelling van het model, maar per toepassing op een individuele student uit het verleden ook sterk kunnen variëren.\n\n\n3.3.3 Inspecteer variabelen met de meeste invloed\nEen volgende analyse gaat in op de variabelen met de meeste invloed. Doordat deze analyse rekening houdt met interactie effecten, niet lineaire effecten en collineariteit, kan de volgorde van variabelen wat verschillen van die van een op RMSE gebaseerde analyse.\nDeze analyse passen we toe op de meest voorkomende student. We onderzoeken eerst de meest voorkomende student in de gehele populatie van deze opleiding. Vervolgens analyseren we de meest voorkomende student in meerdere groepen: naar geslacht, aansluiting, vooropleiding, etc. We gebruiken hiervoor bij numerieke variabelen de mediaan en van categorische variabelen de meest frequente categorie.\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat we een onderscheid maken tussen mannen en vrouwen, dan zullen zij verschillen in bijvoorbeeld de meest voorkomende leeftijd, het meest voorkomende studiekeuzeprofiel, etc. Zo ontstaat er per groep een unieke selectie van variabelen en waarden. De volgorde in belangrijkheid kan ook per groep verschillen.\n\n\nWe onderzoeken zo de voorspelling van het model per groep en de bijdrage van de verklarende variabelen aan die specifieke voorspelling. Dit geeft een verder inzicht in de werking van het model. Een categorie met 20 studenten of minder laten we buiten beschouwing.\n\n3.3.3.1 Toelichting op de opbouw van de kans op retentie\nDe opbouw van het model bestaat uit een intercept, gevolgd door verklarende variabelen die een verschil maken ten opzichte van die intercept. De intercept is de basiskans op retentie voor alle studenten. Deze kans is voor de B Communication and Multimedia Design (CMD) voltijd 61,9%. De cumulatieve bijdrage van de variabelen aan de voorspelling kan positief of negatief zijn. Een positieve bijdrage betekent dat de variabele de kans op retentie verhoogt, een negatieve bijdrage betekent dat het de kans op retentie verlaagt.\nHet kan zijn dat nieuwe variabelen geen invloed meer hebben op de kans. Dit betekent niet per se dat ze niet belangrijk zijn. Het kan zijn dat de invloed die ze hebben op de kans al is ‘afgevangen’ door variabelen die eerder in het model zijn opgenomen.\n\n\n\n\n\n\nTer illustratie\n\n\n\nDe variabele Cijfer_CE_VO_missing = Ja betekent dat een student geen VO cijfers heeft voor het centraal schriftelijk examen. Dit geldt voor vrijwel alle MBO studenten. Doordat de variabele Cijfer_CE_VO_missing de kans op retentie net wat sterker beïnvloedt, komt Vooropleiding = MBO niet meer voor als invloedrijke variabele, maar is dit wel de achterliggende reden dat het cijfer ontbreekt.\n\n\nUiteindelijk tellen alle verklarende variabelen op tot een definitieve voorspelling die per persoon verschilt, afhankelijk van hun persoonlijke verschillen per variabele.\n\n\n3.3.3.2 De meest voorkomende student (totaal)\nWe onderzoeken eerst de meest voorkomende student in de opleiding. We analyseren de kans op retentie voor deze fictieve student en de bijdrage van de variabelen aan die kans. Daarbij tonen we de verdeling van de voorspellingen voor deze student voor alle variabelen en per variabele. Dit laat zien welke variabelen belangrijk zijn, naar welke kant de verdeling neigt en welke spreiding de kansverdeling heeft.\nToelichting\n\nAll data - De eerste variabele all data is eigenlijk geen variabele, maar geeft aan wat alle data samen aan kans op retentie voorspellen. Variabelen die daarna bovenaan staan, wegen het zwaarst in de voorspelling van de kans.\nRichting - Als de verdeling van de kansen naar de linkerkant van de x-as gaat, draagt deze variabele meer bij aan een toename op de kans op retentie; als deze naar de rechterkant beweegt, draagt deze variabele juist bij aan een afname op de kans op retentie\nSpreiding - Als de spreiding breed is, geeft dit aan dat er binnen deze variabele veel variatie is in de kans op retentie en er voorzichtig mee omgegaan moet worden. Als de spreiding heel smal is, betekent dit dat de variabele weinig of geen invloed heeft op de kans op retentie. Deze variabelen bevinden zich op de intercept.\nVorm - De vorm achter de variabele (een viool) geeft de verdeling van de kans op retentie weer. Hoe breder de viool-vorm, hoe meer studenten op die locatie een kans op retentie hebben.\n\n\n\n\n\n\n\nFiguur 3.2: Opbouw van de kans op retentie\n\n\n\n\n\n3.3.3.3 De meest voorkomende student (per groep)\nNu de algemene opbouw van de kans op retentie bekend is voor de meest voorkomende student, gaan we verder met een analyse van de meest voorkomende studenten per groep.\nDe volgorde van de variabelen is zo gesorteerd dat per groep de meest voorspellende variabelen bovenaan staat. De volgorde verschilt per groep en geeft inzicht in wat er per groep speelt. De variabelen zijn vaak proxies voor onderliggende verschillen.\n\n3.3.3.3.1 Naar geslacht\n\nMV\n\n\n\n\n\n\n\n\nFiguur 3.3: Breakdown naar geslacht: M\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.4: Breakdown naar geslacht: V\n\n\n\n\n\n\n\n\n3.3.3.3.2 Naar aansluiting\nDe subtotalen voor de categorieën 2e Studie en Na CD zijn te laag voor een betrouwbare analyse.\n\nDirectTussenjaarSwitch internSwitch extern\n\n\n\n\n\n\n\n\nFiguur 3.5: Breakdown naar aansluiting: Direct\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.6: Breakdown naar aansluiting: Tussenjaar\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.7: Breakdown naar aansluiting: Switch intern\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.8: Breakdown naar aansluiting: Switch extern\n\n\n\n\n\n\n\n\n3.3.3.3.3 Naar vooropleiding\n\nMBOHAVOVWOBDCDHO\n\n\n\n\n\n\n\n\nFiguur 3.9: Breakdown naar vooropleiding: MBO\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.10: Breakdown naar vooropleiding: HAVO\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.11: Breakdown naar vooropleiding: VWO\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.12: Breakdown naar vooropleiding: BD\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.13: Breakdown naar vooropleiding: CD\n\n\n\n\n\n\n\n\n\n\n\nFiguur 3.14: Breakdown naar vooropleiding: HO\n\n\n\n\n\n\n\n\n\n\n3.3.4 Shapley\nNa deze factorentanalyse kijken we naar de stabiliteit van de invloed van de verklarende variabelen. We gebruiken hiervoor Shapley waarden.\nEen Shapley analyse houdt rekening met een andere volgorde van de variabelen. De volgorde van de variabelen is cumulatief (additief) en maakt dus uit voor de bijdrage aan het model: als er een andere variabele al in het model is toegevoegd, heeft dat invloed op de daaropvolgende variabele. Een Shapley analyse permuteert de volgorde van de variabelen om daarmee de verschillen te berekenen in de bijdrage aan de voorspelling. Zo krijgen we nog beter zicht op het belang en de invloed van de individuele variabelen in het prognosemodel. Variabelen zonder bijdrage hebben we verwijderd.\nDe volgorde van de variabelen in deze Shapley analyse is gelijk aan die van Figuur 3.2.\n\n\nToon code\n# Save the plot\nsPlotPath &lt;- file.path(Get_Plot_Outputpath(plotname = \"lf_shapley\", \n                                           bestmodel = sBest_model))\n\n# If the plot does not exist or if recreateplots - T, create a new plot\nif(!file.exists(sPlotPath) | params$recreateplots == TRUE) {\n\n  # Determine the Shapley values\n  lf_shapley &lt;- \n    predict_parts(\n      explainer = explain_lf,\n      new_observation = dfPersona_all[1, ],\n      type = \"shap\",\n      B = 20\n    )\n\n  # Convert these to a data frame\n  dfShapley &lt;- Get_dfShapley(lf_shapley)\n\n  # Build the plot\n  shapley_plot &lt;- Get_Shapley_Plot(dfShapley)\n  \n  # Save the plot\n  suppressWarnings(\n    Finalize_Plot(\n      plot_name = shapley_plot,\n      save_filepath = sPlotPath,\n      height_pixels = 50 + (25 * length(unique(dfShapley$variable_name)))\n    ))\n  \n  # Print the existing plot\n  knitr::include_graphics(sPlotPath)\n\n} else {\n\n  # Print the existing plot\n  knitr::include_graphics(sPlotPath)\n\n}\n\n\n\n\n\n\n\n\nFiguur 3.15: Shapley values\n\n\n\n\n\nToelichting:\n\nDe variabelen met blauwe balken verhogen de kans op retentie, de variabelen met rode balken verlagen de kans op retentie\nDe boxplot in iedere balk geeft de spreiding van de bijdrage van de variabelen aan de voorspelling weer. Hoe breder de boxplot, des te meer variatie in de bijdrage van de variabele aan de voorspelling.\nDe positie van de variabele geeft het belang van de variabele aan in de voorspelling. Hoe hoger de variabele, des te belangrijker de variabele is in de voorspelling.\n\n\n\n\n3.3.5 What-if: een Ceteris Paribus analyse\nVervolgens analyseren we een aantal scenario’s (wat als…). We nemen opnieuw de meest voorkomende studenten, maar beelden nu af hoe de kans op retentie eruit zou zien als telkens een van de variabelen net wat anders was geweest.\n\n\n\n\n\n\nLet op!\n\n\n\nDit is de invloed van de variabelen bij de unieke combinatie van deze meest voorkomende student per categorie. Zie voor de invloed van een variabelen ongeacht deze unieke combinatie de analyse van Partial Dependence Profielen in de volgende paragraaf.\n\n\nHiervoor houden we steeds alle variabelen gelijk, op één na (ceteris paribus is Latijn voor ‘al het overige gelijk’). Van die ene variabelen passen we de waarden aan en zien dan het effect op de voorspelde kans op retentie. Dit geeft beter inzicht in het effect van de individuele variabelen in het model. We voeren deze analyse uit voor numerieke variabelen.\n\n\n\n\n\n\nTer illustratie\n\n\n\nStel dat de student in dit model net een wat hoger eindexamencijfer zou hebben gehad op de middelbare school, wat zou dan de kans op retentie zijn geweest? Het is waarschijnlijk dat de kans op retentie dan hoger zou zijn geweest. Bij hbo-opleidingen die goed aansluiten hebben met een opleiding aan een universiteit, zou de kans op retentie juist lager zijn geweest omdat studenten dan na een hbo-diploma vaak doorstromen naar een universiteit.\n\n\nOpnieuw kijken we naar geslacht, aansluiting en vooropleiding. N.B. Het kan zijn dat een van de categorieën niet zichtbaar is, dit komt doordat deze dan over elkaar heen vallen.\n\n\n\n\n\n\nFiguur 3.16: Ceteris-paribus profiel naar geslacht\n\n\n\n\n\n\n\n\n\nFiguur 3.17: Ceteris-paribus profiel naar aansluiting\n\n\n\n\n\n\n\n\n\nFiguur 3.18: Ceteris-paribus profiel naar vooropleiding\n\n\n\n\n\n\n3.3.6 Partial Dependence analyse\nTot slot analyseren we Partial Dependence. Hierbij onderzoeken we de invloed van individuele variabelen op de kans op retentie, ongeacht de combinatie van de meest voorkomende studenten. Per (numerieke) variabele analyseren we de variantie binnen de kansen op retentie. We gebruiken hiervoor het gemiddelde van alle Ceteris Paribus profielen. Vandaar dat we ook wel spreken over Partial Dependence profielen (PDP’s).\nWe analyseren eerst de variabelen voor alle studenten. We tonen niet alleen de gemiddelde lijn, maar ook de lijnen van individuele CP-profielen. Vervolgens analyseren op dezelfde manier de variabelen per groep: geslacht, aansluiting en vooropleiding.\nToelichting\n\nDe gemiddelde lijn geeft de gemiddelde kans op retentie weer voor alle studenten in de dataset voor alle waarden per variabele.\nDe individuele lijnen geven de kans op retentie weer voor individuele studenten in de dataset voor alle waarden per variabele. De bandbreedte van de individuele lijnen geeft de spreiding van de kans op retentie weer binnen de variabele. Het toont dat de kans op retentie per student kan verschillen, zelfs als de variabele gelijk is; de richting van het verband is wel gelijk.\nStandaard worden 100 willekeurige profielen gekozen om deze afbeeldingen op te bouwen; door deze selectie kan het zijn dat sommige categorieën met weinig observaties in de populatie niet afgebeeld worden.\nDoordat lijnen kunnen overlappen kan het zijn dat sommige lijnen niet zichtbaar zijn. De legenda geeft aan welke mogelijke categorieën voorkomen in de analyse.\n\n\n3.3.6.1 Alle studenten\n\n\n\n\n\n\nFiguur 3.19: Partial Dependence profiel naar alle studenten\n\n\n\n\n\n3.3.6.2 Geslacht\n\n\n\n\n\n\nFiguur 3.20: Partial Dependence profiel naar geslacht\n\n\n\n\n\n3.3.6.3 Aansluiting\n\n\n\n\n\n\nFiguur 3.21: Partial Dependence profiel naar aansluiting\n\n\n\n\n\n3.3.6.4 Vooropleiding\n\n\n\n\n\n\nFiguur 3.22: Partial Dependence profiel naar vooropleiding\n\n\n\n\n\n \nVerantwoording\nDeze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: No Fairness without Awareness | Het rapport is door het lectoraat ontwikkeld in Quarto 1.6.39.\n\n \nCopyright\nDr. Theo Bakker, lector Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Analyse van factoren</span>"
    ]
  },
  {
    "objectID": "ch4-models.html",
    "href": "ch4-models.html",
    "title": "4  Prognosemodel Retentie na 1 jaar",
    "section": "",
    "text": "4.1 Methode, data en analyse",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "ch4-models.html#methode-data-en-analyse",
    "href": "ch4-models.html#methode-data-en-analyse",
    "title": "4  Prognosemodel Retentie na 1 jaar",
    "section": "",
    "text": "4.1.1 Toelichting op de methode\nVoor de ontwikkeling van prognosemodellen gebruiken we de aanpak van Tidymodels. Tidymodels is een framework voor het bouwen van een prognosemodel. Hiermee verzekeren we ons van een systematische, herhaalbare en schaalbare aanpak. De code in deze pagina wordt getoond als deze hoort bij de ontwikkeling van een model. Overige code, voor bijvoorbeeld algemene tabellen of grafieken, kan zichtbaar gemaakt worden.\n\n\n4.1.2 Toelichting op de data\nDe basis voor deze analyse is studiedata van De Haagse Hogeschool (De HHs), verrijkt door het lectoraat LTA. De data bevat informatie over de inschrijvingen van studenten in het eerste jaar van de opleiding:\n\nDemografische kenmerken: geslacht, leeftijd, reistijd en SES totaalscore.\nVooropleidingskenmerken: toelaatgevende vooropleiding, studiekeuzeprofiel en gemiddeld eindcijfer in de vooropleiding.\nAanmeldingskenmerken: aansluiting (direct na diploma, tussenjaar, switch), dag van aanmelding, aantal parallelle studies aan De HHs en collegejaar.\n\nDe variabelen die we hebben geselecteerd voor analyse is op basis van standaardgegevens van een popoluatie (leeftijd en geslacht), eerdere analsyes op voorspelkracht voor retentie na 1 jaar (Bakker, 2022), of omdat een kenmerk volgens Europese normen geldt als een sensitief kenmerk voor discriminatie (European Union Agency for Fundamental Rights, 2018).\n\n\nToon code\n# Read the data dictionary\ndfData_dictionary &lt;- Get_Data_Dictionary()\n\n# Show the data dictionary\nGet_tblData_Dictionary(dfData_dictionary)\n\n\n\n\nTabel 4.1: Variabelen en mogelijke waarden\n\n\n\nVariabeleToelichtingMogelijke waardenAanmeldingDe dag van de aanmelding voor de studie gerekend vanaf 1 september-366 - 366AansluitingDe manier waarop een student instroomt in de opleiding2e studie, Direct, Na CD, Onbekend, Overig, Switch Extern, Switch Intern, TussenjaarAPCGOf de student ten tijde van het behalen van de toelaatgevende vooropleiding in een armoedeprobleemcumulatiegebied woondeJa, Nee, OnbekendCijfer_CE_EngelsHet gemiddelde cijfer Engels van het centaal examen van de middelbare school0-10Cijfer_CE_NatuurkundeHet gemiddelde cijfer voor Natuurkunde van het centaal examen van de middelbare school0-10Cijfer_CE_NederlandsHet gemiddelde cijfer Nederlands van het centaal examen van de middelbare school0-10Cijfer_CE_VOHet gemiddelde cijfer voor het centaal examen van de middelbare school0-10Cijfer_CE_WiskundeHet gemiddelde cijfer voor Wiskunde van het centaal examen van de middelbare school0-10Cijfer_SE_VOHet gemiddelde cijfer voor het schoolexamen van de middelbare school0-10CollegejaarHet collegejaar van de inschrijving2012-2022Dubbele_studieGegeven of de student meer dan 1 studie volgtJa, NeeGeslachtHet geslacht van de studentM, VIDUniek nummer per studentLeeftijdDe leeftijd van de student op 1 oktober16-100RankingDe positie die de student heeft in de selectie voor de opleiding (alleen bij de B Huidtherapie)0-350ReistijdDe reistijd van de student naar de vestiging van de opleiding op een maandag om 9 uur met het openbaar vervoer vanaf de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding in minuten0-120RetentieOf de student doorstudeert na het eerste studiejaarJa, NeeSES_ArbeidDe sociaaleconomische status score op arbeid van het CBS op basis van de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding-1 - 1SES_TotaalDe sociaaleconomische status score totaal van het CBS op basis van de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding-1 - 1SES_WelvaartDe sociaaleconomische status score op welvaart van het CBS op basis van de postcode waarop de student woonde ten tijde van het behalen van de toelaatgevende vooropleiding-1 - 1StudiekeuzeprofielHet studiekeuzeprofiel in het voortgezet onderwijs (havo of vwo) of profiel in het mboAHO, ALG, CERT, CM, EA, EM, EM&CM, HB, HO, ICT, MedV, NG, NT, NT&NG, Onbekend, TP, TR, TSL, VNL, VS, ZWVooropleidingDe toelaatgevende vooropleidingBD, CD, HAVO, HO, MBO, Overig, VWO\n\n\n\n\n\n\n\n4.1.3 Toelichting op de analyse\nWe toetsen in deze analyse Retentie na 1 jaar, voortaan Retentie genoemd.\n\nRetentie is gedefinieerd als ingeschreven staan in dezelfde opleiding in een aansluitend collegejaar. Een wisseling van opleidingsvorm binnen de opleiding, bijvoorbeeld van voltijd in jaar 1 naar duaal in jaar 2, geldt ook als retentie.\nUitval is het tegenovergestelde van retentie: niet ingeschreven staan in dezelfde opleiding in een aansluitend collegejaar.\nEen wisseling van opleidingsvorm binnen de opleiding, bijvoorbeeld van voltijd in jaar 1 naar duaal in jaar 2, geldt niet als uitval.",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "ch4-models.html#voorbereidingen",
    "href": "ch4-models.html#voorbereidingen",
    "title": "4  Prognosemodel Retentie na 1 jaar",
    "section": "4.2 Voorbereidingen",
    "text": "4.2 Voorbereidingen\n\n4.2.1 Laad de data\nWe laden een subset in van historische data specifiek voor:\nOpleiding: ITD | B Communication and Multimedia Design (Synth) (CMD), voltijd, eerstejaars - Retentie na 1 jaar\n\n\nToon code\n# Read the data for this study progamme\nif(params$use_synthetic_data) {\n  dfOpleiding_inschrijvingen_base &lt;- Get_Studyprogram_Enrollments_Synthetic(\n    studytrack = params$opleiding,\n    studyform = toupper(params$opleidingsvorm_afkorting)) |&gt; \n    mutate(\n      ID = as.character(ID),\n      INS_Opleiding = as.character(INS_Opleiding),\n      INS_Opleidingsvorm = as.character(INS_Opleidingsvorm)\n    ) |&gt; \n    mutate(\n      INS_Student_UUID_opleiding_vorm = paste(ID, INS_Opleiding, INS_Opleidingsvorm, sep = \"_\"),\n      INS_Opleidingsnaam_huidig = paste(INS_Opleidingsnaam_huidig, \"(Synth.)\", sep = \" \")\n    )\n} else {\n  dfOpleiding_inschrijvingen_base &lt;- get_lta_studyprogram_enrollments_pin(\n    board = \"HHs/Inschrijvingen\",\n    faculty = params$faculteit,\n    studyprogram = params$opleidingsnaam,\n    studytrack = params$opleiding,\n    studyform = toupper(params$opleidingsvorm),\n    range = \"eerstejaars\")\n}\n\n# Adjust dfOpleiding_inschrijvingen_base\ndfOpleiding_inschrijvingen_base &lt;- dfOpleiding_inschrijvingen_base |&gt; \n  \n  # Rearrange the levels\n  mutate(across(all_of(names(lLevels_formal)), ~ factor(.x, \n                                                   levels = lLevels_formal[[cur_column()]]))) |&gt; \n\n  # Create a simple success variable\n  Mutate_Retentie(sSucces_model) |&gt;\n  \n  # Convert the success variable into a factor\n  mutate(SUC_Retentie = as.factor(SUC_Retentie)) |&gt; \n\n  ## Special possibly based on the propaedeutic diploma\n  # Filter_Propedeusediploma(sPropedeusediploma) |&gt;\n\n  # Make the Dual Study variable a Yes/No variable\n  Mutate_Dubbele_studie() |&gt;  \n\n  # Remove INS_Aantal_inschrijvingen\n  select(-INS_Aantal_inschrijvingen) \n\n  ## Adjust the levels of sensitive variables\n  for(i in lSentitive_formal_variables){\n    dfOpleiding_inschrijvingen_base &lt;- dfOpleiding_inschrijvingen_base |&gt;\n      Mutate_Levels(\n        i,\n        list(lLevels_formal[[i]])\n      )\n  }\n  \n# B Huidtherapie: Filter on only students with a grade number (selection)\nif(opleiding == \"HDT\") {\n  dfOpleiding_inschrijvingen_base &lt;- dfOpleiding_inschrijvingen_base |&gt; \n    filter(!is.na(RNK_Rangnummer)) \n} \n\n\n\n\n4.2.2 Selecteer en inspecteer de data\nWe selecteren eerst de relevante variabelen. We verwijderen daarbij variabelen die maar één waarde hebben, omdat die geen voorspellende waarde kunnen hebben.\n\n\nToon code\nlSelect &lt;- Get_lSelect(dfVariables, \"VAR_Formal_variable\")\n\n# B Huidtherapie: add the variable RNK_Rangnummer unless it is HDT\nif(opleiding == \"HDT\") {\n  lSelect &lt;- c(lSelect, \"RNK_Rangnummer\")\n}\n\n# Create a mapping with formal and simple maes\nlName_mapping &lt;- setNames(dfVariables$VAR_Simple_variable, dfVariables$VAR_Formal_variable)\n\n# Create a subset\ndfOpleiding_inschrijvingen &lt;- dfOpleiding_inschrijvingen_base |&gt;\n  \n  # Select the relevant variables\n  select(all_of(lSelect)) |&gt;\n  \n  # Rename variables for more readable names\n  rename_with(~ lName_mapping[.x], .cols = everything()) |&gt; \n  \n  # Adjust CBS_APCG_tf to a factor\n  Mutate_APCG() |&gt;\n\n  # Indicate where missing numbers are in VO\n  Mutate_Cijfers_VO() |&gt;\n  \n  # Remove variables, where there is only 1 value\n  select(where(~ n_distinct(.) &gt; 1)) |&gt;\n  \n  # Sort\n  arrange(Collegejaar, ID)\n\ndfOpleiding_inschrijvingen &lt;- dfOpleiding_inschrijvingen |&gt; \n Sort_Distinct()\n\n## Remove the base dataset\n#rm(dfOpleiding_inschrijvingen_base)\n\n\nWe inspecteren de variabelen in een samenvatting in relatie tot retentie en corrigeren daarbij voor multiple testing; de gecorrigeerde significantie-waarden staan vermeld als q-value.\n\nToon code\n# Create a summary of the data\ndfSummary &lt;- dfOpleiding_inschrijvingen |&gt;\n  \n  # Remove columns not relevant to the analysis\n  select(-c(ID, Collegejaar)) |&gt; \n  \n  # Adjust the labels of Retention from True to Ja, and from False to Nee\n  mutate(Retentie = fct_recode(Retentie, \"Nee\" = \"FALSE\", \"Ja\" = \"TRUE\")) |&gt;\n  \n  # Adjust the order of the labels of Retentie\n  mutate(Retentie = fct_relevel(Retentie, \"Ja\", \"Nee\")) |&gt; \n  \n  # Adjust Studiekeuzeprofiel: if NA, then unknown\n  mutate(Studiekeuzeprofiel = coalesce(Studiekeuzeprofiel, \"Onbekend\")) |&gt; \n  \n  # Factor all character variables\n  mutate(across(where(is.character), as.factor))\n\n# Create a tbl_df of the summary\ntbl_dfSummary &lt;- Get_tblSummary(dfSummary) \n\ntbl_dfSummary\n\n\n\n\nTabel 4.2: Variabelen in relatie tot de uitkomstmaat: Retentie na 1 jaar\n\n\n Retentie VariabeleJa, N=1002 (62%)1Nee, N=611 (38%)1p-value2q-value3Totaal, N = 16131Aanmelding135,80 (62,44)112,36 (68,57)&lt;0,001&lt;0,001***126,92 (65,80)Aansluiting&lt;0,0010,012***Direct455 (60%)301 (40%)756 (100%)Tussenjaar125 (71%)51 (29%)176 (100%)Switch intern148 (73%)54 (27%)202 (100%)Switch extern254 (57%)191 (43%)445 (100%)2e Studie6 (40%)9 (60%)15 (100%)Na CD14 (74%)5 (26%)19 (100%)Overig0 (NA%)0 (NA%)0 (NA%)Onbekend0 (NA%)0 (NA%)0 (NA%)APCG&lt;0,0010,013***Ja224 (63%)133 (37%)357 (100%)Nee721 (64%)411 (36%)1.132 (100%)Onbekend57 (46%)67 (54%)124 (100%)Cijfer_CE_Engels6,93 (1,18)7,07 (1,10)0,16&gt;0,996,98 (1,15)Cijfer_CE_Engels_missing0,70&gt;0,99Ja533 (62%)331 (38%)864 (100%)Nee469 (63%)280 (37%)749 (100%)Cijfer_CE_Natuurkunde6,18 (0,96)6,31 (0,95)0,21&gt;0,996,23 (0,95)Cijfer_CE_Natuurkunde_missing0,68&gt;0,99Ja867 (62%)533 (38%)1.400 (100%)Nee135 (63%)78 (37%)213 (100%)Cijfer_CE_Nederlands5,94 (0,85)5,96 (0,91)0,86&gt;0,995,95 (0,87)Cijfer_CE_Nederlands_missing0,61&gt;0,99Ja533 (62%)333 (38%)866 (100%)Nee469 (63%)278 (37%)747 (100%)Cijfer_CE_VO6,46 (0,37)6,35 (0,34)&lt;0,001&lt;0,001***6,42 (0,36)Cijfer_CE_VO_missing0,59&gt;0,99Ja488 (61%)306 (39%)794 (100%)Nee514 (63%)305 (37%)819 (100%)Cijfer_CE_Wiskunde6,35 (1,12)6,28 (1,07)0,65&gt;0,996,33 (1,10)Cijfer_CE_Wiskunde_missing0,64&gt;0,99Ja544 (62%)339 (38%)883 (100%)Nee458 (63%)272 (37%)730 (100%)Cijfer_SE_VO6,46 (0,38)6,35 (0,36)&lt;0,001&lt;0,001***6,42 (0,38)Cijfer_SE_VO_missing0,59&gt;0,99Ja501 (61%)314 (39%)815 (100%)Nee501 (63%)297 (37%)798 (100%)Dubbele_studie&lt;0,001&lt;0,001***Ja12 (26%)34 (74%)46 (100%)Nee990 (63%)577 (37%)1.567 (100%)Geslacht&lt;0,001&lt;0,001***M521 (57%)394 (43%)915 (100%)V481 (69%)217 (31%)698 (100%)Leeftijd20,01 (2,26)20,19 (2,61)0,48&gt;0,9920,08 (2,40)Reistijd37,01 (18,38)38,84 (22,79)0,79&gt;0,9937,70 (20,17)SES_Arbeid0,01 (0,08)0,01 (0,08)0,57&gt;0,990,01 (0,08)SES_Totaal0,02 (0,28)0,01 (0,27)0,45&gt;0,990,02 (0,28)SES_Welvaart0,01 (0,13)0,01 (0,13)0,36&gt;0,990,01 (0,13)Studiekeuzeprofiel0,048&gt;0,99*AHO2 (67%)1 (33%)3 (100%)ALG0 (0%)1 (100%)1 (100%)CERT1 (100%)0 (0%)1 (100%)CM78 (72%)30 (28%)108 (100%)EA36 (67%)18 (33%)54 (100%)EM118 (56%)93 (44%)211 (100%)EM&CM152 (70%)66 (30%)218 (100%)HB8 (62%)5 (38%)13 (100%)HO27 (57%)20 (43%)47 (100%)ICT82 (64%)47 (36%)129 (100%)MedV132 (65%)72 (35%)204 (100%)NG115 (63%)68 (37%)183 (100%)NT56 (60%)38 (40%)94 (100%)NT&NG62 (60%)41 (40%)103 (100%)Onbekend90 (52%)83 (48%)173 (100%)TP2 (40%)3 (60%)5 (100%)TR5 (56%)4 (44%)9 (100%)TSL4 (80%)1 (20%)5 (100%)VNL8 (80%)2 (20%)10 (100%)VS1 (33%)2 (67%)3 (100%)ZW23 (59%)16 (41%)39 (100%)Vooropleiding0,0150,37*MBO330 (63%)192 (37%)522 (100%)HAVO548 (64%)312 (36%)860 (100%)VWO34 (59%)24 (41%)58 (100%)BD42 (46%)50 (54%)92 (100%)CD21 (70%)9 (30%)30 (100%)HO27 (53%)24 (47%)51 (100%)Overig0 (NA%)0 (NA%)0 (NA%)Onbekend0 (NA%)0 (NA%)0 (NA%)1Mean (SD); n (%)2Wilcoxon rank sum test; Fisher's Exact Test for Count Data with simulated p-value  (based on 2000 replicates); Pearson's Chi-squared test3*p&lt;0.05; **p&lt;0.01; ***p&lt;0.001\n\n\n\nDaarnaast inspecteren we de kwaliteit van de data op missende waarden.\n\n\nToon code\n# Load dlookr (temporary to avoid conflicts)\nsuppressMessages(library(dlookr))\n\n# Show a summary of the data, sorted by missing values\ndiagnose(dfOpleiding_inschrijvingen) |&gt; \n  mutate(missing_percent = round(missing_percent, 2),\n         unique_rate = round(missing_percent, 2)) |&gt;\n  arrange(desc(missing_percent)) |&gt;\n  knitr::kable(col.names = c(\"Variabelen\",\n                           \"Type\",\n                           \"# Missende waarden\",\n                           \"% Missende waarden\",\n                           \"# Unieke waarden\",\n                           \"Ratio unieke waarden\"))\n# Detach dlookr\ndetach(\"package:dlookr\", unload = TRUE)\n\n\n\n\nTabel 4.3: Kwaliteit van de data voor bewerkingen (gesorteerd op missende waarden)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabelen\nType\n# Missende waarden\n% Missende waarden\n# Unieke waarden\nRatio unieke waarden\n\n\n\n\nCijfer_CE_Natuurkunde\nnumeric\n1400\n86.79\n42\n86.79\n\n\nCijfer_CE_Wiskunde\nnumeric\n883\n54.74\n56\n54.74\n\n\nCijfer_CE_Nederlands\nnumeric\n866\n53.69\n45\n53.69\n\n\nCijfer_CE_Engels\nnumeric\n864\n53.56\n57\n53.56\n\n\nCijfer_SE_VO\nnumeric\n815\n50.53\n23\n50.53\n\n\nCijfer_CE_VO\nnumeric\n794\n49.23\n23\n49.23\n\n\nStudiekeuzeprofiel\nfactor\n173\n10.73\n21\n10.73\n\n\nSES_Welvaart\nnumeric\n126\n7.81\n355\n7.81\n\n\nSES_Arbeid\nnumeric\n125\n7.75\n261\n7.75\n\n\nSES_Totaal\nnumeric\n125\n7.75\n459\n7.75\n\n\nReistijd\nnumeric\n20\n1.24\n362\n1.24\n\n\nAanmelding\nnumeric\n0\n0.00\n266\n0.00\n\n\nAansluiting\nfactor\n0\n0.00\n6\n0.00\n\n\nAPCG\ncharacter\n0\n0.00\n3\n0.00\n\n\nCijfer_CE_Engels_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_Natuurkunde_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_Nederlands_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_VO_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_CE_Wiskunde_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCijfer_SE_VO_missing\ncharacter\n0\n0.00\n2\n0.00\n\n\nCollegejaar\nnumeric\n0\n0.00\n11\n0.00\n\n\nDubbele_studie\ncharacter\n0\n0.00\n2\n0.00\n\n\nGeslacht\nfactor\n0\n0.00\n2\n0.00\n\n\nID\ncharacter\n0\n0.00\n1613\n0.00\n\n\nLeeftijd\nnumeric\n0\n0.00\n17\n0.00\n\n\nRetentie\nfactor\n0\n0.00\n2\n0.00\n\n\nVooropleiding\nfactor\n0\n0.00\n6\n0.00\n\n\n\n\n\n\n\n\n\n\n4.2.3 Bewerk de data\n\nUit de eerste diagnose blijkt dat niet alle variabelen goed genoeg zijn voor het bouwen van een prognosemodel: er zijn missende waarden en niet alle veldtypes zijn geschikt.\nOm bias te voorkomen verwijderen we geen rijen met missende waarden, maar vullen die op (imputatie). We bewerken de data zo dat alle missende waarden worden opgevuld: bij numerieke waarden met het gemiddelde en bij categorische variabelen met ‘Onbekend’.\nWe passen het type van sommige variabelen aan, zodat ze in het model gebruikt kunnen worden: tekstvelden zetten we om naar factor (een categorische variabele); logische variabelen (Ja/Nee) zetten we om naar een numerieke variabele (1/0).\nDe uitkomstvariabele, Retentie, leiden we af van de variabele SUC_Uitval_aantal_jaar_LTA. Als de waarde daar 1 is, is de student na 1 jaar uitgevallen, 2 na 2 jaar, etc. Zolang de waarde daar 0 is, is de student niet uitgevallen.\nEen fictief studentnummer (INS_Student_UUID_opleiding_vorm) gebruiken we, zodat we – als er afwijkende resultaten zijn – de dataset gericht kunnen onderzoeken als dat nodig is.\n\n\n\nToon code\n# Edit the data\ndfOpleiding_inschrijvingen &lt;- dfOpleiding_inschrijvingen |&gt; \n  \n  # Imputate all numeric variables with the mean\n  mutate(across(where(is.numeric), ~ ifelse(\n    is.na(.x),\n    mean(.x, na.rm = T),\n    .x\n  )) ) |&gt;\n  \n  # Convert character variables to factor\n  mutate(across(where(is.character), as.factor)) |&gt; \n  \n  # Convert logical variables to 0 or 1\n  mutate(across(where(is.logical), as.integer)) |&gt;\n  \n  # Fill in factors missing values with “Unknown”\n  mutate(across(where(is.factor), ~ suppressWarnings(\n    fct_explicit_na(.x, na_level = \"Onbekend\")\n  ))) |&gt; \n  \n  # Rearrange the columns so that Retentie is in front\n  select(Retentie, everything()) \n\n## View the data\n# glimpse(dfOpleiding_inschrijvingen) \n\n# Load dlookr (temporary to avoid conflicts)\nsuppressMessages(library(dlookr))\n\n# Diagnose the data\ndiagnose(dfOpleiding_inschrijvingen) |&gt; \n  mutate(missing_percent = round(missing_percent, 2),\n         unique_rate = round(unique_rate, 2)) |&gt;\n  knitr::kable(col.names = c(\"Variabelen\",\n                           \"Type\",\n                           \"# Missende waarden\",\n                           \"% Missende waarden\",\n                           \"# Unieke waarden\",\n                           \"Ratio unieke waarden\"))\n# Detach dlookr\ndetach(\"package:dlookr\", unload = TRUE)\n\n\n\n\nTabel 4.4: Kwaliteit van de data na bewerkingen (gesorteerd op missende waarden)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabelen\nType\n# Missende waarden\n% Missende waarden\n# Unieke waarden\nRatio unieke waarden\n\n\n\n\nRetentie\nfactor\n0\n0\n2\n0.00\n\n\nAanmelding\nnumeric\n0\n0\n266\n0.16\n\n\nAansluiting\nfactor\n0\n0\n6\n0.00\n\n\nAPCG\nfactor\n0\n0\n3\n0.00\n\n\nCijfer_CE_Engels\nnumeric\n0\n0\n57\n0.04\n\n\nCijfer_CE_Engels_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_Natuurkunde\nnumeric\n0\n0\n42\n0.03\n\n\nCijfer_CE_Natuurkunde_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_Nederlands\nnumeric\n0\n0\n45\n0.03\n\n\nCijfer_CE_Nederlands_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_VO\nnumeric\n0\n0\n23\n0.01\n\n\nCijfer_CE_VO_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_CE_Wiskunde\nnumeric\n0\n0\n56\n0.03\n\n\nCijfer_CE_Wiskunde_missing\nfactor\n0\n0\n2\n0.00\n\n\nCijfer_SE_VO\nnumeric\n0\n0\n23\n0.01\n\n\nCijfer_SE_VO_missing\nfactor\n0\n0\n2\n0.00\n\n\nCollegejaar\nnumeric\n0\n0\n11\n0.01\n\n\nDubbele_studie\nfactor\n0\n0\n2\n0.00\n\n\nGeslacht\nfactor\n0\n0\n2\n0.00\n\n\nID\nfactor\n0\n0\n1613\n1.00\n\n\nLeeftijd\nnumeric\n0\n0\n17\n0.01\n\n\nReistijd\nnumeric\n0\n0\n362\n0.22\n\n\nSES_Arbeid\nnumeric\n0\n0\n261\n0.16\n\n\nSES_Totaal\nnumeric\n0\n0\n459\n0.28\n\n\nSES_Welvaart\nnumeric\n0\n0\n355\n0.22\n\n\nStudiekeuzeprofiel\nfactor\n0\n0\n21\n0.01\n\n\nVooropleiding\nfactor\n0\n0\n6\n0.00\n\n\n\n\n\n\n\n\n\n\n4.2.4 Inspecteer de onderlinge correlaties\nHet is verstandig om voorafgaand aan het bouwen van een model te kijken naar de onderlinge correlaties tussen numerieke variabelen. Dit geeft inzicht in de data en kan helpen bij het maken van keuzes voor het model of de duiding van de uitkomsten.\nWe selecteren uitsluitend numerieke waarden en variabelen die een standaard deviatie hebben die groter is dan 0. We clusteren de data op basis van 4 clusters. De correlatie van de diagonaal verbergen we, aangezien deze altijd 1 is.\nClusters in correlaties kunnen per opleiding verschillen. Onderzoek in de correlaties hoe sterk deze zijn, welke clusters gevormd worden en of deze – vanuit de context van de opleiding, faculteit of onderwijsinstelling – logisch zijn. Verwerk de inzichten eventueel in een oplegger. Gangbare clusters zijn:\n\nCijfers: Een correlatie tussen Cijfer SO en Cijfer VO: dit geeft aan dat het schoolexamen hetzelfde meet als het centraal examen. Exacte vakken en talen kunnen met elkaar correleren.\nReistijd en SES: Deze zijn gecorreleerd aangezien SES scores zijn afgeleid van wijken. Wijken hebben een specifieke reistijd en positionering ten opzichte van de vestigingslocaties van De HHs kennen.\nLeeftijd is vaak niet gecorreleerd met andere variabelen.\n\n\n\nToon code\n# Create a plot of the intercorrelations in numerical variables\n# Remove columns with a standard deviation of 0\ndfCorrelation &lt;- dfOpleiding_inschrijvingen |&gt; \n  select(-Collegejaar) |&gt;\n  select(where(is.numeric)) |&gt; \n  select_if(~ sd(.) != 0) |&gt;\n  cor()\n\ndfCorrelation |&gt;  \ncorrplot::corrplot(\n  order = 'hclust', \n  addrect = 4,\n  method = \"number\",\n  hclust.method = \"complete\",\n  tl.cex = 0.8,       \n  tl.col = \"black\",\n  diag = FALSE)\n\n\n\n\n\n\n\n\nFiguur 4.1: Correlatiematrix\n\n\n\n\n\n\n\nToon code\n# Apply hierarchical clustering\ndist   &lt;- as.dist(1 - dfCorrelation)      # Create a distance matrix\nhclust &lt;- hclust(dist, method = \"complete\")  # Hierarchical clustering\n\n# Plot the dendrogram\n# plot(hclust, cex = 0.8)\n\n# Create a clustering\ndfClusters &lt;- cutree(hclust, k = 4)\n\n# Show clustering\n# dfClusters\n\n\n\n\n4.2.5 Bouw de trainingset, validatieset en testset\n\nDe data is nu geschikt om een prognosemodel mee te bouwen.\nOm het model te bouwen, testen en valideren, splitsen we de data in drie delen van 60%, 20% en 20%. We doen dit op zo’n manier, dat elk deel ongeveer een gelijk aantal studenten bevat dat doorstudeert (dus niet uitvalt).\nWe trainen het model op basis van 60% en valideren de modellen tijdens het trainen op de overige 20% (de validatieset).\nDe verdeling van de training- en validatieset muteren we 10x (10 folds) om te voorkomen dat het model te veel leert van de trainingset en daardoor slecht presteert op de validatieset.\nAls het model klaar is, testen we het op de 20% studenten uit de testset. De testset blijft dus de gehele tijd ongemoeid, zodat we overfitting - een te goed model op bekende data, maar slechte presetaties (performance) op onbekende data - voorkomen.\nEen willekeurig, maar vaststaand seed-getal voorkomt dat we bij elke run van het model c.q. deze code een net iets andere uitkomst krijgen.\n\nWe ontwikkelen in de verdere analyse eerst een aantal modellen en testen de prestaties daarvan op de trainingset en validiatieset. Vervolgens bepalen we welk model het beste presteert en passen dat model dan toe op de testset (de uiteindelijke fit). Vandaar dat het toetsen van de prestaties van de modellen meerdere keren behandeld wordt.\n\n\nToon code\nknitr::include_graphics(here::here(\"R/images\", \"prognosemodel-dataset-lta-hhs.png\"))\n\n\n\n\n\n\n\n\nFiguur 4.2: Splitsing van de dataset in trainingset, validatieset en testset\n\n\n\n\n\n\n\nToon code\nset.seed(0821)\n\n# Split the data into 3 parts: 60%, 20% and 20%\nsplits      &lt;- initial_validation_split(dfOpleiding_inschrijvingen,\n                                        strata = Retentie,\n                                        prop = c(0.6, 0.2))\n\n# Create three sets: a training set, a test set and a validation set\ndfRetentie_train      &lt;- training(splits)\ndfRetentie_test       &lt;- testing(splits)\ndfRetentie_validation &lt;- validation_set(splits)\n\n# Create a resample set based on 10 folds (default)\ndfRetentie_resamples  &lt;- vfold_cv(dfRetentie_train, strata = Retentie)\n\n\n\n\n\n\nTabel 4.5: Verhouding van de uitkomstvariabele in de training- en testset\n\n\n\n\n\n\nNaam\nRetentie\nAantal\nProportie\n\n\n\n\nTrainingset\nFALSE\n366\n37.8%\n\n\nTrainingset\nTRUE\n601\n62.2%\n\n\nTestset\nFALSE\n123\n38.0%\n\n\nTestset\nTRUE\n201\n62.0%",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "ch4-models.html#model-i-logistische-regressie",
    "href": "ch4-models.html#model-i-logistische-regressie",
    "title": "4  Prognosemodel Retentie na 1 jaar",
    "section": "4.3 Model I: Logistische Regressie",
    "text": "4.3 Model I: Logistische Regressie\n\nHet eerste model is een logistische regressie met penalized likelihood; we gebruiken de glmnet engine voor het bouwen van het model. Penalized likelihood is een techniek die helpt bij het voorkomen van overfitting: het voegt voor elke extra variabele een strafterm toe om eenvoudige modellen te belonen. Glmnet is een veelgebruikt package voor het bouwen van logistische regressiemodellen.\nWe gebruiken de Area under the ROC Curve (AUC/ROC) als performance metric. De ROC-curve (Receiver Operating Characteristic) is een grafiek die de prestaties van een classificatiemodel afbeeldt door de verhouding tussen de true positives (sensitiviteit) en de false positives (aspecficiteit = 1-specificiteit) te plotten bij verschillende drempelwaarden. De oppervlakte onder deze curve, bekend als de AUC (Area Under the Curve), kwantificeert het onderscheidingsvermogen van het model; een AUC van 1 duidt op een perfect onderscheidend vermogen, terwijl een AUC van 0,5 wijst op een model zonder onderscheidend vermogen.\n\n\n4.3.1 Maak het model\nEerst bouwen we het model.\n\n# Build the model: logistic regression\nlr_mod &lt;- \n  logistic_reg(penalty = tune(), mixture = 1) |&gt; \n  set_engine(\"glmnet\")\n\n\n\n4.3.2 Maak de recipe\nVervolgens zetten we meerdere stappen in een ‘recipe’:\n\nWe definiëren de student-ID als ID variabele. Daarmee krijgt deze variabele de rol van uniek rij-kenmerk.\nWe verwijderen vervolgens de oorspronkelijke student-ID en het collegejaar uit de data, omdat deze verder niet gebruikt moeten worden in het model.\nWe converteren factoren naar dummy variabelen: voor elke categorie wordt er een nieuwe logische variabele (Ja/Nee) aangemaakt.\nWe verwijderen variabelen die geen waarde toevoegen: variabelen met uitsluitend nullen.\nWe normaliseren numerieke variabelen om ze met elkaar te kunnen vergelijken door ze te centreren en schalen: het transformeert numerieke gegevens zodat ze een standaard deviatie van één en een gemiddelde van nul hebben.\nSterk gecorreleerde waarden verwijderen we nu niet, omdat we later in de analyse de eventuele samenhang met andere variabelen in een prognosemodel nog willen kunnen visualiseren.\n\n\n# Build the recipe: logistic regression\nlr_recipe &lt;- \n  recipe(Retentie ~ ., data = dfRetentie_train) |&gt;  \n  update_role(ID, new_role = \"ID\") |&gt;           # Set the student ID as an ID variable\n  step_rm(ID, Collegejaar) |&gt;                   # Remove ID and college year from the model\n  step_unknown(Studiekeuzeprofiel, \n               new_level = \"Onbekend skp\") |&gt;   # Add unknown skp\n  step_dummy(all_nominal_predictors()) |&gt;       # Create dummy variables from categorical variables\n  step_zv(all_predictors()) |&gt;                  # Remove zero values\n  step_normalize(all_numeric_predictors())      # Center and scale numeric variables\n\n\n\nToon code\n# Show the recipe\ntidy(lr_recipe) |&gt; \n  knitr::kable(col.names = c(\"Nummer\", \n                             \"Operatie\", \n                             \"Type\",\n                             \"Getraind\",\n                             \"Sla over\",\n                             \"ID\"))\n\n\n\n\nTabel 4.6: Recipesteps voor logistische regressie\n\n\n\n\n\n\nNummer\nOperatie\nType\nGetraind\nSla over\nID\n\n\n\n\n1\nstep\nrm\nFALSE\nFALSE\nrm_t7fOp\n\n\n2\nstep\nunknown\nFALSE\nFALSE\nunknown_KV8Lp\n\n\n3\nstep\ndummy\nFALSE\nFALSE\ndummy_bUMsj\n\n\n4\nstep\nzv\nFALSE\nFALSE\nzv_beaLb\n\n\n5\nstep\nnormalize\nFALSE\nFALSE\nnormalize_3WTmw\n\n\n\n\n\n\n\n\nDe variabelen die nu nog overblijven zijn:\n\n\n\n\nTabel 4.7: Resterende variabelen voor logistische regressie na bewerkingen\n\n\n\n\n\n\n\n\n\n\n\nAanmelding\nAPCG_Nee\nStudiekeuzeprofiel_HB\n\n\nCijfer_CE_Engels\nAPCG_Onbekend\nStudiekeuzeprofiel_HO\n\n\nCijfer_CE_Natuurkunde\nCijfer_CE_Engels_missing_Nee\nStudiekeuzeprofiel_ICT\n\n\nCijfer_CE_Nederlands\nCijfer_CE_Natuurkunde_missing_Nee\nStudiekeuzeprofiel_MedV\n\n\nCijfer_CE_VO\nCijfer_CE_Nederlands_missing_Nee\nStudiekeuzeprofiel_TP\n\n\nCijfer_CE_Wiskunde\nCijfer_CE_VO_missing_Nee\nStudiekeuzeprofiel_TR\n\n\nCijfer_SE_VO\nCijfer_CE_Wiskunde_missing_Nee\nStudiekeuzeprofiel_TSL\n\n\nLeeftijd\nCijfer_SE_VO_missing_Nee\nStudiekeuzeprofiel_VNL\n\n\nReistijd\nDubbele_studie_Nee\nStudiekeuzeprofiel_VS\n\n\nSES_Arbeid\nGeslacht_V\nStudiekeuzeprofiel_ZW\n\n\nSES_Totaal\nStudiekeuzeprofiel_CM\nStudiekeuzeprofiel_Onbekend\n\n\nSES_Welvaart\nStudiekeuzeprofiel_EM.CM\nVooropleiding_HAVO\n\n\nRetentie\nStudiekeuzeprofiel_NT\nVooropleiding_VWO\n\n\nAansluiting_Tussenjaar\nStudiekeuzeprofiel_NG\nVooropleiding_BD\n\n\nAansluiting_Switch.intern\nStudiekeuzeprofiel_NT.NG\nVooropleiding_CD\n\n\nAansluiting_Switch.extern\nStudiekeuzeprofiel_AHO\nVooropleiding_HO\n\n\nAansluiting_X2e.Studie\nStudiekeuzeprofiel_ALG\n\n\n\nAansluiting_Na.CD\nStudiekeuzeprofiel_EA\n\n\n\n\n\n\n\n\n\n\n\n4.3.3 Maak de workflow\nVoor de uitvoering bouwen we een workflow. Daaraan voegen we het model en de bewerkingen in de recipe toe.\n\n# Create the workflow: logistic regression\nlr_workflow &lt;- \n  workflow() |&gt;         # Create a workflow\n  add_model(lr_mod) |&gt;  # Add the model\n  add_recipe(lr_recipe) # Add the recipe\n\n# Show workflow\nlr_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_unknown()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\n4.3.4 Tune en train het model\nHet model moet getuned worden. Dit houdt in dat we de beste parameters voor het model moeten vinden. We maken een grid met verschillende penalty waarden. Daarmee kunnen we vervolgens het beste model selecteren met de hoogste ROC/AUC. We plotten de resultaten van de tuning, zodat we hieruit het beste model kunnen kiezen.\n\n# Create a grid: logistic regression\nlr_reg_grid &lt;- tibble(penalty = 10 ^ seq(-4, -1, length.out = 30))\n\n# Train and tune the model: logistic regression\nlr_res &lt;- \n  lr_workflow |&gt; \n  tune_grid(dfRetentie_validation,\n            grid = lr_reg_grid,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n\n\n\nToon code\n# Plot the results + a red vertical line for the max AUC\nlr_plot &lt;- \n  lr_res |&gt; \n  collect_metrics() |&gt; \n  ggplot(aes(x = penalty, y = mean)) + \n  geom_point() + \n  geom_line() + \n  \n  # Make the scale of the x-axis logarithmic\n  scale_x_log10(labels = scales::label_number()) +\n    theme(\n      axis.title.x = element_text(margin = margin(t = 20))\n    ) +\n  \n  # Define the title, subtitle and caption\n  labs(\n    caption = sCaption,\n    x = \"Area under the ROC Curve\",\n    y = \"Penalty\"\n  )\n  \n  # Add theme elements\n  lr_plot &lt;- Add_Theme_Elements(lr_plot, title_subtitle = FALSE)\n  \n# Find the penalty value with the max AUC\nmax_auc_penalty &lt;- lr_res |&gt; \n  collect_metrics() |&gt; \n  filter(mean == max(mean)) |&gt; \n  pull(penalty)\n\n# Add the red vertical line to lr_plot\nlr_plot_plus &lt;- lr_plot + \n  geom_vline(xintercept = max_auc_penalty, color = \"red\")\n\n# Find a mean for the max AUC that is higher\nmax_auc_mean &lt;- lr_res |&gt; \n  collect_metrics() |&gt; \n  filter(mean == max(mean)) |&gt; \n  pull(penalty)\n\n# Print the final plot\nlr_plot_plus\n\n\n\n\n\n\n\n\nFiguur 4.3: Tuning resultaten logistische regressie\n\n\n\n\n\n\n\n4.3.5 Kies het beste model\nDe prestaties van een model gevisualiseerd met behulp van een ROC curve. De sensitiviteit (True Positive Rate) en specificiteit (True Negative Rate) worden hierin tegenover elkaar uitgezet. De Area under the ROC Curve (AUC/ROC) geeft de prestaties van het model weer. Het model scoort beter naarmate de AUC/ROC dichter bij de 1 ligt, de linker bovenhoek. De linker bovenhoek houdt in dat alle prognoses exact overeenstemmen met de werkelijkheid. Een AUC/ROC van 0,5 betekent dat het model niet beter presteert dan een willekeurige voorspelling.\nWe gebruiken modellen met een zo hoog mogelijke Area under the ROC Curve (AUC/ROC) en een zo laag mogelijke penalty. Zo kunnen we uit de resultaten het beste model kiezen en visualiseren.\n\n# Show the best model\ntop_models &lt;-\n  lr_res |&gt; \n  show_best(metric = \"roc_auc\", n = 10) |&gt; \n  mutate(mean = round(mean, 6)) |&gt;\n  arrange(penalty) \n\n\n\nToon code\ntop_models|&gt; \n  knitr::kable(col.names = c(\"Penalty\", \n                             \"Metriek\", \n                             \"Estimator\",\n                             \"Gemiddelde\",\n                             \"Aantal\",\n                             \"SE\",\n                             \"Configuratie\"))\n\n\n\n\nTabel 4.8: Model performance voor logistische regressie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPenalty\nMetriek\nEstimator\nGemiddelde\nAantal\nSE\nConfiguratie\n\n\n\n\n0.0017433\nroc_auc\nbinary\n0.669959\n1\nNA\nPreprocessor1_Model13\n\n\n0.0022122\nroc_auc\nbinary\n0.671680\n1\nNA\nPreprocessor1_Model14\n\n\n0.0028072\nroc_auc\nbinary\n0.672992\n1\nNA\nPreprocessor1_Model15\n\n\n0.0035622\nroc_auc\nbinary\n0.674549\n1\nNA\nPreprocessor1_Model16\n\n\n0.0045204\nroc_auc\nbinary\n0.675041\n1\nNA\nPreprocessor1_Model17\n\n\n0.0057362\nroc_auc\nbinary\n0.676516\n1\nNA\nPreprocessor1_Model18\n\n\n0.0072790\nroc_auc\nbinary\n0.678566\n1\nNA\nPreprocessor1_Model19\n\n\n0.0092367\nroc_auc\nbinary\n0.678975\n1\nNA\nPreprocessor1_Model20\n\n\n0.0117210\nroc_auc\nbinary\n0.675492\n1\nNA\nPreprocessor1_Model21\n\n\n0.0148735\nroc_auc\nbinary\n0.668443\n1\nNA\nPreprocessor1_Model22\n\n\n\n\n\n\n\n\n\n# Select the best model: logistic regression\nlr_best &lt;- \n  lr_res |&gt; \n  collect_metrics() |&gt; \n  filter(mean == max(mean)) |&gt;\n  slice(1) \n\n\n\nToon code\nlr_best|&gt; \n  mutate(mean = round(mean, 6)) |&gt;\n  knitr::kable(col.names = c(\"Penalty\", \n                             \"Metriek\", \n                             \"Estimator\",\n                             \"Gemiddelde\",\n                             \"Aantal\",\n                             \"SE\",\n                             \"Configuratie\"))\n\n\n\n\nTabel 4.9: Hoogste model performance voor logistische regressie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPenalty\nMetriek\nEstimator\nGemiddelde\nAantal\nSE\nConfiguratie\n\n\n\n\n0.0092367\nroc_auc\nbinary\n0.678975\n1\nNA\nPreprocessor1_Model20\n\n\n\n\n\n\n\n\n\n# Collect the predictions and evaluate the model (AUC/ROC): logistic regression\nlr_auc &lt;- \n  lr_res |&gt; \n  collect_predictions(parameters = lr_best) |&gt; \n  roc_curve(Retentie, .pred_FALSE) |&gt; \n  mutate(model = \"Logistisch Regressie\")\n\n\n\nToon code\n# Plot the ROC curve\nGet_ROC_Plot(lr_auc, position = 1)\n\n\n\n\n\n\n\n\nFiguur 4.4: ROC curve voor logistische regressie\n\n\n\n\n\n\n\nToon code\n# Determine the AUC of the best model\nlr_auc_highest   &lt;-\n  lr_res |&gt;\n  collect_predictions(parameters = lr_best) |&gt; \n  roc_auc(Retentie, .pred_FALSE)\n\n# Add model name and AUC dfModel_results\ndfModel_results &lt;- \n  dfModel_results |&gt;\n  add_row(model = \"Logistic Regression\", auc = lr_auc_highest$.estimate)",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "ch4-models.html#model-ii-tree-based-ensemble",
    "href": "ch4-models.html#model-ii-tree-based-ensemble",
    "title": "4  Prognosemodel Retentie na 1 jaar",
    "section": "4.4 Model II: Tree-based ensemble",
    "text": "4.4 Model II: Tree-based ensemble\n\nHet tweede model is een random forest: een ensemble van beslisbomen (decision trees). Het is een krachtig model dat goed om kan gaan met complexe data en veel variabelen.\nWe gebruiken de ranger engine voor het bouwen van het model.\n\n\n4.4.1 Bepaal het aantal PC-cores\nOmdat een random forest model veel berekeningen vereist, willen we daarvoor alle computerkracht gebruiken die beschikbaar is. Het aantal CPU’s (cores), wat verschilt per computer, bepaalt hoe snel het model getraind kan worden. We bepalen het aantal cores en gebruiken dat bij het bouwen van het model.\n\n\nToon code\n# Determine the number of cores\ncores &lt;- parallel::detectCores()\n\n\n\n\n4.4.2 Maak het model\nWe bouwen eerst het model. We gebruiken de rand_forest functie om het model te bouwen. We tunen de mtry en min_n parameters. De mtry parameter bepaalt het aantal variabelen dat per boom wordt gebruikt. De min_n parameter bepaalt het minimum aantal observaties dat in een blad van de boom moet zitten. De functie tune() is hier nog een placeholder om de beste waarden voor deze parameters - die we later bepalen - in te kunnen stellen. We gebruiken 1.000 bomen c.q. versies van het model.\n\n# Build the model: random forest\n\nrf_mod &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) |&gt; \n  set_engine(\"ranger\", num.threads = cores) |&gt; \n  set_mode(\"classification\")\n\n\n\n4.4.3 Maak de recipe\nWe maken een recipe voor het random forest model. We verwijderen de student ID en het collegejaar uit de data, omdat deze niet moet worden gebruikt in het model. Overige stappen zijn bij een random forest minder relevant in tegenstelling tot een regressiemodel.\n\n# Create the recipe: random forest\nrf_recipe &lt;- \n  recipe(Retentie ~ ., data = dfRetentie_train) |&gt; \n  step_unknown(Studiekeuzeprofiel, \n               new_level = \"Onbekend skp\") |&gt;   # Add unknown skp\n  step_rm(ID, Collegejaar)                      # Remove ID and Collegejaar from the model\n\n\n\nToon code\n# Show the recipe\ntidy(rf_recipe) |&gt; \n  knitr::kable(col.names = c(\"Nummer\", \n                             \"Operatie\", \n                             \"Type\",\n                             \"Getraind\",\n                             \"Sla over\",\n                             \"ID\"))\n\n\n\n\nTabel 4.10: Recipesteps voor random forest\n\n\n\n\n\n\nNummer\nOperatie\nType\nGetraind\nSla over\nID\n\n\n\n\n1\nstep\nunknown\nFALSE\nFALSE\nunknown_QY996\n\n\n2\nstep\nrm\nFALSE\nFALSE\nrm_Q9GeT\n\n\n\n\n\n\n\n\n\n\n4.4.4 Maak de workflow\nWe voegen het model en de recipe toe aan de workflow voor dit model.\n\n# Create the workflow: random forest\nrf_workflow &lt;- \n  workflow() |&gt; \n  add_model(rf_mod) |&gt; \n  add_recipe(rf_recipe)\n\n# Show workflow\nrf_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_unknown()\n• step_rm()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: ranger \n\n\n\n\n4.4.5 Tune en train het model\nWe trainen en tunen het model in de workflow. We maken een grid met verschillende waarden voor de parameters mtry en min_n. We gebruiken de Area under the ROC Curve (AUC/ROC) als performance metric. Met de resultaten van de tuning kiezen we het beste model.\n\n# Show the parameters that can be tuned\nrf_mod\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: ranger \n\n# Extract the parameters being tuned\nextract_parameter_set_dials(rf_mod)\n\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n\n# Determine the seed\nset.seed(2904)\n\n# Build the grid: random forest\nrf_res &lt;- \n  rf_workflow |&gt; \n  tune_grid(dfRetentie_validation,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(roc_auc))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n\n\n4.4.6 Kies het beste model\nWe evalueren de beste modellen en maken een ROC curve om de performance van het model te visualiseren. Vervolgens vergelijken we de prestaties van de modellen en kiezen daaruit het beste model.\n\n# Show the best models\nrf_res |&gt; \n  show_best(metric = \"roc_auc\", n = 15) |&gt; \n  mutate(mean = round(mean, 6)) |&gt;\n  knitr::kable(col.names = c(\"Mtry\", \n                             \"Min. aantal\", \n                             \"Metriek\",\n                             \"Estimator\",\n                             \"Gemiddelde\",\n                             \"Aantal\",\n                             \"SE\",\n                             \"Configuratie\"))\n\n\n\nTabel 4.11: Model performance voor random forest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMtry\nMin. aantal\nMetriek\nEstimator\nGemiddelde\nAantal\nSE\nConfiguratie\n\n\n\n\n4\n26\nroc_auc\nbinary\n0.698525\n1\nNA\nPreprocessor1_Model23\n\n\n2\n32\nroc_auc\nbinary\n0.697869\n1\nNA\nPreprocessor1_Model03\n\n\n7\n35\nroc_auc\nbinary\n0.697869\n1\nNA\nPreprocessor1_Model14\n\n\n8\n31\nroc_auc\nbinary\n0.696393\n1\nNA\nPreprocessor1_Model24\n\n\n22\n38\nroc_auc\nbinary\n0.695656\n1\nNA\nPreprocessor1_Model01\n\n\n18\n40\nroc_auc\nbinary\n0.695533\n1\nNA\nPreprocessor1_Model16\n\n\n5\n36\nroc_auc\nbinary\n0.695369\n1\nNA\nPreprocessor1_Model09\n\n\n6\n23\nroc_auc\nbinary\n0.695164\n1\nNA\nPreprocessor1_Model17\n\n\n3\n8\nroc_auc\nbinary\n0.693402\n1\nNA\nPreprocessor1_Model08\n\n\n13\n25\nroc_auc\nbinary\n0.692172\n1\nNA\nPreprocessor1_Model25\n\n\n16\n34\nroc_auc\nbinary\n0.691885\n1\nNA\nPreprocessor1_Model07\n\n\n11\n29\nroc_auc\nbinary\n0.691721\n1\nNA\nPreprocessor1_Model02\n\n\n9\n12\nroc_auc\nbinary\n0.691721\n1\nNA\nPreprocessor1_Model05\n\n\n12\n13\nroc_auc\nbinary\n0.690697\n1\nNA\nPreprocessor1_Model19\n\n\n11\n21\nroc_auc\nbinary\n0.690246\n1\nNA\nPreprocessor1_Model15\n\n\n\n\n\n\n\n\n\n\nToon code\n# Plot the results\nautoplot &lt;- autoplot(rf_res) +\n  theme_minimal() +\n  labs(\n    y = \"roc/auc\",\n    caption = sCaption\n  )\n  \n  # Add theme elements\n  autoplot &lt;- Add_Theme_Elements(autoplot, title_subtitle = FALSE)\n  \n  print(autoplot)\n\n\n\n\n\n\n\n\nFiguur 4.5: Model performance random forest\n\n\n\n\n\n\n# Select the best model\nrf_best &lt;- \n  rf_res |&gt; \n  select_best(metric = \"roc_auc\")\n\n\n\nToon code\nrf_best|&gt; \n  knitr::kable(col.names = c(\"Mtry\", \n                             \"Min. aantal\", \n                             \"Configuratie\"))\n\n\n\n\nTabel 4.12: Hoogste model performance voor random forest\n\n\n\n\n\n\nMtry\nMin. aantal\nConfiguratie\n\n\n\n\n4\n26\nPreprocessor1_Model23\n\n\n\n\n\n\n\n\n\n\nToon code\n# Collect the predictions\nrf_res |&gt; \n  collect_predictions() |&gt; \n  head(10) |&gt;\n  mutate(.pred_FALSE = scales::percent(.pred_FALSE, accuracy = 0.1),\n         .pred_TRUE = scales::percent(.pred_TRUE, accuracy = 0.1)) |&gt;\n  knitr::kable(col.names = c(\"% Voorsp. FALSE\", \n                             \"% Voorsp. TRUE\", \n                             \"ID\",\n                             \"Rij\",\n                             \"Mtry\", \n                             \"Min. aantal\", \n                             \"Retentie\",\n                             \"Configuratie\"))\n\n\n\n\nTabel 4.13: Predicties voor random forest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n% Voorsp. FALSE\n% Voorsp. TRUE\nID\nRij\nMtry\nMin. aantal\nRetentie\nConfiguratie\n\n\n\n\n52.6%\n47.4%\nvalidation\n968\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n42.9%\n57.1%\nvalidation\n969\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n40.4%\n59.6%\nvalidation\n970\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n39.5%\n60.5%\nvalidation\n971\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n30.4%\n69.6%\nvalidation\n972\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n49.0%\n51.0%\nvalidation\n973\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n21.2%\n78.8%\nvalidation\n974\n22\n38\nFALSE\nPreprocessor1_Model01\n\n\n48.2%\n51.8%\nvalidation\n975\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n50.1%\n49.9%\nvalidation\n976\n22\n38\nFALSE\nPreprocessor1_Model01\n\n\n27.4%\n72.6%\nvalidation\n977\n22\n38\nTRUE\nPreprocessor1_Model01\n\n\n\n\n\n\n\n\n\n\nToon code\n# Determine the AUC/ROC curve\nrf_auc &lt;- \n  rf_res |&gt; \n  collect_predictions(parameters = rf_best) |&gt; \n  roc_curve(Retentie, .pred_FALSE) |&gt; \n  mutate(model = \"Random Forest\")\n\n# Plot the ROC curve\nGet_ROC_Plot(rf_auc, position = 2)\n\n# Determine the AUC of the best model\nrf_auc_highest   &lt;-\n  rf_res |&gt;\n  collect_predictions(parameters = rf_best) |&gt; \n  roc_auc(Retentie, .pred_FALSE)\n\n# Add model name and AUC to dfModel_results\ndfModel_results &lt;- \n  dfModel_results |&gt;\n  add_row(model = \"Random Forest\", \n          auc = rf_auc_highest$.estimate)\n\n\n\n\n\n\n\n\nFiguur 4.6: ROC curve voor random forest",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "ch4-models.html#de-uiteindelijke-fit",
    "href": "ch4-models.html#de-uiteindelijke-fit",
    "title": "4  Prognosemodel Retentie na 1 jaar",
    "section": "4.5 De uiteindelijke fit",
    "text": "4.5 De uiteindelijke fit\n\nIn de laatste stap van deze analyse maken we het model definitief.\nWe testen het model op de testset en evalueren het model met metrieken en de Variable Importance (VI). De VI kwantificeert de bijdrage van elke variabele aan de voorspellende kracht van een model. Het identificeert welke variabelen significant zijn voor de modelprestaties, wat essentieel is voor het interpreteren en optimaliseren van een model (Van der Laan, 2006). Methoden zoals de Shapley-waarde en permutation importance worden vaak toegepast om dit belang te meten. Op deze methoden komen we terug in het volgende hoofdstuk.\n\n\n4.5.1 Combineer de AUC/ROC curves en kies het beste model\nEerst combineren we de AUC/ROC curves van de modellen om ze te vergelijken. We kiezen het beste model op basis van de hoogste AUC/ROC.\n\n\nToon code\n# Combine the AUC/ROC curves to compare the models\nGet_ROC_Plot(list(lr_auc, rf_auc))\n\n\n\n\n\n\n\n\nFiguur 4.7: Gecombineerde ROC curves\n\n\n\n\n\n\n\nToon code\n# Determine which of the models is best based on highest AUC/ROC\ndfModel_results &lt;- dfModel_results |&gt;\n  mutate(number = row_number()) |&gt; \n  mutate(best = ifelse(auc == max(auc), TRUE, FALSE)) |&gt; \n  arrange(number)\n\n# Determine the best model\nsBest_model     &lt;- dfModel_results$model[dfModel_results$best == TRUE]\nsBest_model_auc &lt;- round(dfModel_results$auc[dfModel_results$best == TRUE], 4)\n\n\nHet beste model is het Random Forest model met een AUC/ROC van 0.6985. Het Logistic Regression model heeft een AUC van 0.679. We ronden de analyse verder af met het Random Forest model op de validatieset.\n\n\n4.5.2 Maak het finale model\nWe maken het finale model op basis van de beste parameters die we hebben gevonden. Door in de engine bij importance de impurity op te geven, wordt het beste random forest model gekozen om de data definitief mee te classificeren.\n\n# Test the developed model on the test set\n# Determine the optimal parameters\n\n# Build the final models\nlast_lr_mod &lt;-\n    logistic_reg(penalty = lr_best$penalty,\n                 mixture = 1) |&gt;\n    set_engine(\"glmnet\") |&gt;\n    set_mode(\"classification\")\n\nlast_rf_mod &lt;-\n    rand_forest(mtry = rf_best$mtry,\n                min_n = rf_best$min_n,\n                trees = 1000) |&gt;\n    set_engine(\"ranger\", num.threads = cores, importance = \"impurity\") |&gt;\n    set_mode(\"classification\")\n\n\n\n4.5.3 Maak de workflow\nWe voegen het model toe aan de workflow en updaten de workflow met het finale model.\n\n# Update the workflows\n last_lr_workflow &lt;- \n    lr_workflow |&gt; \n    update_model(last_lr_mod)\n\n last_rf_workflow &lt;- \n    rf_workflow |&gt; \n    update_model(last_rf_mod)\n\n\n\n4.5.4 Fit het finale model\nWe voeren de finale fit uit. De functie last_fit past het model toe op de validatieset.\n\n# Perform the final fit\nset.seed(2904)\n\n# Make a final fit for both models so we can save it for later use\nlast_fit_lr &lt;- \n    last_lr_workflow |&gt; \n    last_fit(splits)\n\nlast_fit_rf &lt;- \n    last_rf_workflow |&gt; \n    last_fit(splits)\n\nlLast_fits &lt;- list(last_fit_lr, last_fit_rf) |&gt; \n  set_names(c(\"Logistic Regression\", \"Random Forest\"))\n\n# Determine which model is best\nif(sBest_model == \"Logistic Regression\") {\n  last_fit &lt;- last_fit_lr\n} else if(sBest_model == \"Random Forest\") {\n  last_fit &lt;- last_fit_rf\n}\n\n# Keep results, model results and associated data\nsFittedmodels_outputpath &lt;- Get_Model_Outputpath(mode = \"last-fits\")\nsaveRDS(lLast_fits, file = sFittedmodels_outputpath)\n\nsModelresults_outputpath &lt;- Get_Model_Outputpath(mode = \"modelresults\")\nsaveRDS(dfModel_results, file = sModelresults_outputpath)\n\nsData_outputpath &lt;- Get_Model_Outputpath(mode = \"data\")\nsaveRDS(dfOpleiding_inschrijvingen, file = sData_outputpath)\n\n\n\n4.5.5 Evalueer het finale model: metrieken en variable importance\nWe evalueren het finale model nu grondiger op basis van 4 metrieken: 1) accuraatheid, 2) ROC/AUC en 3) de Brier score (de Mean Squared Error). Het is zinvol om accuraatheid, ROC/AUC en de Brier-score pas bij het finale model toe te passen, omdat dit efficiënter is en overfitting voorkomt. Zo combineren we een snelle modelselectie met een grondige evaluatie van het uiteindelijke model.\n\n# Collect the metrics\nlast_fit |&gt; \n  collect_metrics() |&gt; \n  mutate(.estimate = round(.estimate, 4)) |&gt;\n  knitr::kable(col.names = c(\"Metriek\", \n                             \"Estimator\",\n                             \"Estimate\",\n                             \"Configuratie\"))\n\n\n\n\nMetriek\nEstimator\nEstimate\nConfiguratie\n\n\n\n\naccuracy\nbinary\n0.6420\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.6642\nPreprocessor1_Model1\n\n\nbrier_class\nbinary\n0.2189\nPreprocessor1_Model1\n\n\n\n\n\n\n\n4.5.6 Plot de ROC curve\nTot slot visualiseren we de prestaties weer met een ROC curve van het beste model.\n\n# Show the roc curve\nauc_lf &lt;- last_fit |&gt; \n  collect_predictions() |&gt; \n  roc_curve(Retentie, .pred_FALSE) |&gt; \n  mutate(model = \"Last fit\")\n\nGet_ROC_Plot(auc_lf, position = 3)\n\n\n\n\n\n\n\nFiguur 4.8: ROC curve finale model",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "ch4-models.html#conclusies",
    "href": "ch4-models.html#conclusies",
    "title": "4  Prognosemodel Retentie na 1 jaar",
    "section": "4.6 Conclusies",
    "text": "4.6 Conclusies\n\n4.6.1 Het beste prognosemodel voor deze opleiding\nHet beste prognosemodel blijkt het Random Forest model te zijn.\n\nVan de prognosemodellen die we hebben ontwikkeld om retentie na 1 jaar te voorspellen, had het Random Forest model de hoogste AUC/ROC waarde (0.6985).\n\n\n\n4.6.2 Mate van accuraatheid en lift\nEen prognosemodel moet minimaal beter presteren dan een base-model om waarde op basis van accuraatheid toe te voegen. Het base-model neemt als basis de grootste klasse van de gemiddelde retentie na 1 jaar van de afgelopen jaren. Stel we zouden tegen alle studenten zeggen dat ze hun studie gaan halen, dan is de mate van accuratesse gelijk aan dit base-model. Dit base-model is dus altijd hoger dan de 50% lijn van de AUC/ROC curve, tenzij het base-model toevallig precies 50% is.\n\n\nToon code\nknitr::include_graphics(here::here(\"R/images\", \"basemodel-lift.png\"))\n\n\n\n\n\n\n\n\nFiguur 4.9: Lift afhankelijk van base-model en accuraatheid\n\n\n\n\n\nDe mate van accuraatheid van het prognosemodel is vrij laag (64.2%).\n\nBase-model: 62.12% – Voor deze opleiding berekenen we het base-model als volgt. Van alle studenten studeerde 62.12% door; 100% - 62.12% = 37.88% studeerde niet door. De grootste klasse van deze twee, 62.12%, is daarmee de accuratesse van het base-model.\nAccuratesse prognose: 64.2% – Het model voorspelt Retentie na 1 jaar met een accuratesse van 64.2%.\nLift: 2.08% – Het model scoort in de huidige opbouw met een verschil van 2.08% (de lift) iets beter dan de accuraatheid van het base-model.\n\n\n\n4.6.3 Confusion Matrix\n\n\nToon code\n# Determine the confusion matrix\nconfusion_matrix &lt;- last_fit |&gt;\n  collect_predictions() |&gt;\n  conf_mat(truth = Retentie, estimate = .pred_class) \n\ndfConf_matrix &lt;- as_tibble(confusion_matrix$table) |&gt;\n  rename(Werkelijkheid = Truth) |&gt;\n  mutate(Werkelijkheid = ifelse(Werkelijkheid == \"TRUE\", \"Retentie\", \"Geen retentie\"),\n         Prediction    = ifelse(Prediction == \"TRUE\", \"Retentie\", \"Geen retentie\"))\n\npTP  &lt;- Change_Number_Marks((dfConf_matrix$n[4]/sum(dfConf_matrix$n)*100),1)\npFP  &lt;- Change_Number_Marks((dfConf_matrix$n[2]/sum(dfConf_matrix$n)*100),1)\npTN  &lt;- Change_Number_Marks((dfConf_matrix$n[1]/sum(dfConf_matrix$n)*100),1)\npFN  &lt;- Change_Number_Marks((dfConf_matrix$n[3]/sum(dfConf_matrix$n)*100),1)\npACC &lt;- Change_Number_Marks(Last_fit_Accuracy,1)\n\n\nDe prestaties van het model kunnen we verder uitdrukken in een confusion matrix. Hierin zien we de voorspellingen van het model en de werkelijke uitkomsten. De matrix geeft inzicht in de mate van correcte en incorrecte voorspellingen. Ter illustratie werken we de matrix uit voor een voorspelling waarop een bindend studieadvies (BSA) gebaseerd zou kunnen zijn.\n\n\nToon code\nknitr::include_graphics(here::here(\"R/images\", \"confusion-matrix-retention-lta-hhs.png\"))\n\n\n\n\n\n\n\n\nFiguur 4.10: Confusion matrix in relatie tot BSA\n\n\n\n\n\nWe passen de confusion matrix nu toe op het model dat als beste naar voren kwam. De accuraatheid van dit model is 64,2%. De accuraatheid van het model berekenen we door de som van de diagonaal te berekenen: het aandeel goed voorspelde uitkomsten, Retentie = Retentie (True Positive) en Geen retentie = Geen retentie (True Negative), af te zetten tegen het totaal aantal voorspellingen: 56,5% + 7,7% = 64,2%. (NB. De weergave in deze confusion matrix is diagonaal gespiegeld vergeleken met het voorbeeld.)\n\n\nToon code\nconfusion_plot &lt;- plot_confusion_matrix(\n    dfConf_matrix,\n    target_col = \"Werkelijkheid\",\n    prediction_col = \"Prediction\",\n    counts_col = \"n\",\n    palette = \"Blues\",\n    add_sums = TRUE,\n    theme_fn = ggplot2::theme_light,\n    sums_settings = sum_tile_settings(\n      palette = \"Greens\",\n      label = \"Totaal\",\n      tc_tile_border_color = \"black\"\n    )) +\n    \n    # Customize the labels\n    labs(\n      x = \"Werkelijke uitkost\",\n      y = \"Voorspelde uitkomst\",\n      caption = sCaption\n    ) +\n    \n    Set_Theme()\n  \n  # Add theme elements\n  confusion_plot &lt;- Add_Theme_Elements(confusion_plot, \n                                           title_subtitle = TRUE)\n  \n  print(confusion_plot)\n\n\n\n\n\n\n\n\nFiguur 4.11: Confusion matrix ten opzichte van Retentie na 1 jaar\n\n\n\n\n\n\n\n4.6.4 Uitleggen of verklaren?\nNaast de accuraatheid van het model is het ook belangrijk om te weten welke factoren het meest bijdragen aan de voorspelling van retentie na 1 jaar. Daarin gaat de vergelijking met de prestaties van het basemodel mank. Dat model geeft op geen enkele manier aan waarom een student een kans op succes heeft, anders dan - ‘dit is gebruikelijk in deze opleiding’.\nOngeacht de mate van accuraatheid, is het voor onderzoek naar kansengelijkheid essentieel om te weten welke factoren het meest bijdragen aan de voorspelling van retentie na 1 jaar. Het gaat erom dat we het belang van de factoren in de voorspellingen kunnen begrijpen en duiden. Machine Learning is hiervoor uitstekend geschikt, omdat het de mogelijkheid biedt om de belangrijkste factoren en hun invloed te leren kennen (Shmueli, 2010; Shmueli & Koppius, 2011).\n\n\n\n \nVerantwoording\nDeze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: No Fairness without Awareness | Het rapport is door het lectoraat ontwikkeld in Quarto 1.6.39.\n\n \nCopyright\nDr. Theo Bakker, lector Learning Technology & Analytics, De Haagse Hogeschool © 2023-2025. Alle rechten voorbehouden.\n\n\n\n\n\nBakker, T. (2022). Study Progression and Success of Autistic Students in Higher Education. A Longitudinal, Propensity Score-Weighted Population Study. https://doi.org/10.5463/thesis.1\n\n\nHandboek over het Europese non-discriminatierecht, Editie 2018. (2018). [Computer software]. https://fra.europa.eu/sites/default/files/fra\\_uploads/fra-2018-handbook-non-discrimination-law-2018\\_nl.pdf\n\n\nShmueli, G. (2010). To Explain or to Predict? Statistical Science, 25(3), 289–310. https://doi.org/10.1214/10-sts330\n\n\nShmueli, G., & Koppius, O. (2011). Predictive Analytics in Information Systems Research. MIS Quarterly, 35(3), 553. https://doi.org/10.2307/23042796\n\n\nVan der Laan, M. J. (2006). Statistical inference for variable importance. The International Journal of Biostatistics, 2(1).",
    "crumbs": [
      "Analyse",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prognosemodel {{< meta params.model >}}</span>"
    ]
  },
  {
    "objectID": "ch5-references.html",
    "href": "ch5-references.html",
    "title": "Referenties",
    "section": "",
    "text": "Bakker, T. (2022). Study Progression and\nSuccess of Autistic Students in Higher Education. A Longitudinal,\nPropensity Score-Weighted Population Study. https://doi.org/10.5463/thesis.1\n\n\nBakker, T. (2024). No fairness without awareness. Toegepast\nonderzoek naar kansengelijkheid in het hoger onderwijs. Intreerede\nlectoraat learning technology & analytics. The Hague University\nof Applied Sciences. https://doi.org/10.5281/zenodo.14204674\n\n\nBarocas, S., Hardt, M., & Narayanan, A. (2023). Fairness and Machine Learning: Limitations and\nOpportunities. fairmlbook.org. http://www.fairmlbook.org\n\n\nHandboek over het Europese\nnon-discriminatierecht, Editie 2018. (2018). [Computer\nsoftware]. https://fra.europa.eu/sites/default/files/fra\\_uploads/fra-2018-handbook-non-discrimination-law-2018\\_nl.pdf\n\n\nShmueli, G. (2010). To Explain or to\nPredict? Statistical Science, 25(3), 289–310.\nhttps://doi.org/10.1214/10-sts330\n\n\nShmueli, G., & Koppius, O. (2011). Predictive\nAnalytics in Information Systems Research. MIS\nQuarterly, 35(3), 553. https://doi.org/10.2307/23042796\n\n\nVan der Laan, M. J. (2006). Statistical inference for variable\nimportance. The International Journal of Biostatistics,\n2(1).",
    "crumbs": [
      "Analyse",
      "Referenties"
    ]
  },
  {
    "objectID": "x-a-appendix-abbreviations.html",
    "href": "x-a-appendix-abbreviations.html",
    "title": "Bijlage A — Afkortingen",
    "section": "",
    "text": "1  Studiekeuzeprofielen\nIn dit onderzoek worden de volgende afkortingen gehanteerd:",
    "crumbs": [
      "Bijlagen",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Afkortingen</span>"
    ]
  },
  {
    "objectID": "x-a-appendix-abbreviations.html#studiekeuzeprofielen",
    "href": "x-a-appendix-abbreviations.html#studiekeuzeprofielen",
    "title": "Bijlage A — Afkortingen",
    "section": "",
    "text": "Afkortingen van studiekeuzeprofielen (SKP) per vooropleiding\n\n\nVooropleiding\nAfkorting\nStudiekeuzeprofiel\n\n\n\n\nMBO\nAHO\nAfbouw, hout en onderhoud\n\n\n\nALG\nAmbacht, laboratorium en gezondheidstechniek\n\n\n\nBI\nBouw en infra\n\n\n\nEA\nEconomie en administratie\n\n\n\nHO\nHandel en ondernemerschap\n\n\n\nHB\nHoreca en bakkerij\n\n\n\nICT\nInformatie en communicatietechnologie\n\n\n\nMedV\nMedia en vormgeving\n\n\n\nMobV\nMobiliteit en voertuigen\n\n\n\nTP\nTechniek en procesindustrie\n\n\n\nTR\nToerisme en recreatie\n\n\n\nTSL\nTransport, scheepvaart en logistiek\n\n\n\nUV\nUiterlijke verzorging\n\n\n\nVS\nVeiligheid en sport\n\n\n\nVNL\nVoedsel, natuur en leefomgeving\n\n\n\nZW\nZorg en welzijn\n\n\nHAVO/VWO\nCM\nCultuur en maatschappij\n\n\n\nEM\nEconomie en maatschappij\n\n\n\nEM&CM\nEconomie en maatschappij & Cultuur en maatschappij\n\n\n\nNG\nNatuur en gezondheid\n\n\n\nNT\nNatuur en techniek\n\n\n\nNG&NT\nNatuur en gezondheid & Natuur en techniek\n\n\n\nNG&CM\nNatuur en gezondheid & Cultuur en maatschappij\n\n\n\nNG&EM\nNatuur en gezondheid & Economie en maatschappij\n\n\n\nNT&CM\nNatuur en techniek & Cultuur en maatschappij\n\n\n\nNT&EM\nNatuur en techniek & Economie en maatschappij\n\n\n\nOS\nOude stijl\n\n\n\nCERT\nCertificaat",
    "crumbs": [
      "Bijlagen",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Afkortingen</span>"
    ]
  },
  {
    "objectID": "x-a-appendix-abbreviations.html#overige-afkortingen",
    "href": "x-a-appendix-abbreviations.html#overige-afkortingen",
    "title": "Bijlage A — Afkortingen",
    "section": "2  Overige afkortingen",
    "text": "2  Overige afkortingen\n\nOverige afkortingen per onderwerp\n\n\nOnderwerp\nAfkorting\nBetekenis\n\n\n\n\nGeslacht\nM\nMan\n\n\n\nV\nVrouw\n\n\nVooropleiding\nBD\nBuitenlands diploma\n\n\n\nCD\nColloquium Doctum\n\n\n\nHO\nHoger onderwijs",
    "crumbs": [
      "Bijlagen",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Afkortingen</span>"
    ]
  },
  {
    "objectID": "x-b-appendix-packages.html",
    "href": "x-b-appendix-packages.html",
    "title": "Bijlage B — Packages",
    "section": "",
    "text": "B.1 Session Info\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.3\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Amsterdam\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4   compiler_4.4.2      BiocManager_1.30.25\n [4] fastmap_1.2.0       cli_3.6.3           htmltools_0.5.8.1  \n [7] tools_4.4.2         rstudioapi_0.17.1   yaml_2.3.10        \n[10] rmarkdown_2.29      knitr_1.49          jsonlite_1.8.9     \n[13] xfun_0.50           digest_0.6.37       rlang_1.1.5        \n[16] renv_1.0.9          evaluate_1.0.3",
    "crumbs": [
      "Bijlagen",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Packages</span>"
    ]
  }
]