---
title: "Tidymodels workflow"
format:
  html:
    toc: true
    html-math-method: katex
theme: cosmo
---

```{r setup, include=FALSE}

## Gebaseerd op https://www.tidymodels.org/start/case-study/

## 0.0 Laad bibliotheken

## Laad bibliotheken
library(tidymodels)  
library(readr)       # for importing data
library(vip)         # for variable importance plots
```

# 1. VOORBEREIDINGEN

## 1.0 Laad de data

```{r}
## Laad de hoteldata
hotels <- 
  read_csv("https://tidymodels.org/start/case-study/hotels.csv") |>
  mutate(across(where(is.character), as.factor))

dim(hotels)
#> [1] 50000    23
#> 
glimpse(hotels)

```

## 1.1 Splits & resample de data

```{r}
set.seed(123)

## Bereken de proportie van kinderen
hotels |> 
  count(children) |> 
  mutate(prop = n/sum(n))

## Maak de splitsing in een training en test set
splits      <- initial_split(hotels, strata = children)

hotel_other <- training(splits)
hotel_test  <- testing(splits)

# Training set proporties kinderen
hotel_other |> 
  count(children) |> 
  mutate(prop = n/sum(n))

# Test set proportions by children
hotel_test  |> 
  count(children) |> 
  mutate(prop = n/sum(n))

```

## 1.2 Maak de validatieset

```{r}

set.seed(234)

## Bouw de validatieset: 80% van de overige data
val_set <- validation_split(hotel_other, 
                            strata = children, 
                            prop = 0.80)

#> Warning: `validation_split()` was deprecated in rsample 1.2.0.
#> â„¹ Please use `initial_validation_split()` instead.

val_set

```

# 2. MODEL I: PENALIZED LOGISTIC REGRESSION

## 2.1 Maak het model

```{r}

## Bouw het model: logistische regressie
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet")
```

## 2.2 Maak de recipe

```{r}

## Bepaal de vakantiedagen
holidays <- c(
  "AllSouls",
  "AshWednesday",
  "ChristmasEve",
  "Easter",
  "ChristmasDay",
  "GoodFriday",
  "NewYearsDay",
  "PalmSunday"
)

## Bouw de recipe: logistische regressie
lr_recipe <- 
  recipe(children ~ ., data = hotel_other) |>  
  step_date(arrival_date)|>                          ## Converteer arrival_date naar een daum object
  step_holiday(arrival_date, holidays = holidays)|>  ## Maak de holiday variabelen
  step_rm(arrival_date)|>                            ## Verwijder arrival_date
  step_dummy(all_nominal_predictors())|>             ## Converteer factoreren naar dummy variabelen
  step_zv(all_predictors())|>                        ## Verwijder zero values
  step_normalize(all_predictors())                   ## Centreek en schaale numerieke variabelen
```

## 2.3 Maak de workflow

```{r}

## Maak de workflow: logistische regressie
lr_workflow <- 
  workflow() |>         ## Maak een workflow
  add_model(lr_mod) |>  ## Voeg het model toe
  add_recipe(lr_recipe) ## Voeg de recipe toe
```

## 2.4 Maak een grid voor tuning

```{r}

## Maak een grid: logistische regressie
lr_reg_grid <- tibble(penalty = 10 ^ seq(-4, -1, length.out = 30))

## Toon het grid (laagste en hoogste penalty values)
lr_reg_grid |> top_n(-5) # Laatgte 5 penalty values
lr_reg_grid |> top_n(5)  # Hoogste 5 penalty values

```

## 2.5 Train en tune het model

```{r}

## Train en tune het model: logistische regressie
lr_res <- 
  lr_workflow |> 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

## Plot de resultaten
lr_plot <- 
  lr_res |> 
  collect_metrics() |> 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

lr_plot 
```

## 2.6 Evalueer het beste model

```{r}

## Toon het beste model
top_models <-
  lr_res |> 
  show_best(metric = "roc_auc", n = 15) |> 
  arrange(penalty) 

top_models

```

## 2.7 Kies het beste model

```{r}

## Selecteer het beste model: logistische regressie
lr_best <- 
  lr_res |> 
  collect_metrics() |> 
  arrange(penalty) |> 
  slice(12)

lr_best


## Verzamel de predictions en evalueer het model (AUC/ROC): logistische regressie
lr_auc <- 
  lr_res |> 
  collect_predictions(parameters = lr_best) |> 
  roc_curve(children, .pred_children) |> 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```

# 3. MODEL II: TREE-BASED ENSEMBLE

## 3.0 Bepaal het aantal cores

```{r}

## Bepaal het aantal cores
cores <- parallel::detectCores()
cores
```

## 3.1 Bouw het model

```{r}

## Bouw het model: random forest

rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) |> 
  set_engine("ranger", num.threads = cores) |> 
  set_mode("classification")
```

## 3.2 Maak de recipe

```{r}

## Maak de recipe: random forest
rf_recipe <- 
  recipe(children ~ ., data = hotel_other) |> 
  step_date(arrival_date) |> 
  step_holiday(arrival_date) |> 
  step_rm(arrival_date) 

```

## 3.3 Maak de workflow

```{r}

## Maak de workflow: random forest
rf_workflow <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(rf_recipe)
```

## 3.4 Train en tune het model

```{r}

## Toon de parameters die getuned kunnen worden
rf_mod

# Extraheer de parameters die getuned worden
extract_parameter_set_dials(rf_mod)

```

## 3.5 Maak een grid voor tuning

```{r}
set.seed(345)

## Bouw het grid: random forest
rf_res <- 
  rf_workflow |> 
  tune_grid(val_set,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```

## 3.6 Evalueer het beste model

```{r}

## Toon de beste modellen
rf_res |> 
  show_best(metric = "roc_auc")

## Plot de resultaten
autoplot(rf_res)

## Selecteer het beste model
rf_best <- 
  rf_res |> 
  select_best(metric = "roc_auc")

rf_best

## Verzamel de predicties
rf_res |> 
  collect_predictions()

## Bepaal de AUC/ROC curve
rf_auc <- 
  rf_res |> 
  collect_predictions(parameters = rf_best) |> 
  roc_curve(children, .pred_children) |> 
  mutate(model = "Random Forest")
```

# 4. DE LAATSTE FIT

## 4.0 Combineer de AUC/ROC curves en kies

```{r}

## Combineer de AUC/ROC curves om de modellen te vergelijken
bind_rows(rf_auc, lr_auc) |> 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)

```

## 4.1 Maak het model

```{r}

## Test het ontwikkelde model op de testset

# Bouw het laatste model
last_rf_mod <-
  rand_forest(mtry = 8,
              min_n = 7,
              trees = 1000) |>
  set_engine("ranger", num.threads = cores, importance = "impurity") |>
  set_mode("classification")

```

## 4.2 Maak de workflow

```{r}

# Bouw de laatste workflow op basis van het laatste model
last_rf_workflow <- 
  rf_workflow |> 
  update_model(last_rf_mod)

```

## 4.3 Fit het model

```{r}

# Execute the last fit
set.seed(345)

last_rf_fit <- 
  last_rf_workflow |> 
  last_fit(splits)

## Show the results
last_rf_fit

```

## 4.4 Evalueer het model: metrieken en vif

```{r}

## Verzame de metrieken
last_rf_fit |> 
  collect_metrics()

## Extraheer de feature importance
last_rf_fit |> 
  extract_fit_parsnip() |> 
  vip(num_features = 20)
```

## 4.5 Plot de ROC curve

```{r}

## Toon de roc curve
last_rf_fit |> 
  collect_predictions() |> 
  roc_curve(children, .pred_children) |> 
  autoplot()
```

# 5. SESSIE INFORMATIE

```{r}
sessionInfo()
```
