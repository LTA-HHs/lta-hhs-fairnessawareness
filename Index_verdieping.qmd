---
title: "2. Kansengelijkheid - `r params$uitval` `r ifelse(params$propedeusediploma == 'Nvt', '', paste0(' - ', params$propedeusediploma))`"
subtitle: "`r params$faculteit` | `r params$opleidingsnaam` (`r params$opleiding`) - `r params$opleidingsvorm` - versie `r params$versie`"

## Auteur en datum
author: "`r params$author`, De HHs"
date: last-modified

## LTA Template
ltatemplate: 0.9.1.9000

## Format en output
output-file: "lta-hhs-tidymodels-uitval-verdieping.html"

## Parameters        
params:
  versie: "1.0"
  uitval: "Uitval na 1 jaar"
  propedeusediploma: "Zonder P" ## Nvt/Met P/Zonder P
  faculteit: "GVS"
  
  # GVS:HBO-V
  opleidingsnaam: "B Opleiding tot Verpleegkundige"
  opleiding: "HBO-V"
  opleidingsvorm: "voltijd"
  opleidingsvorm_afkorting: "VT"
  selectie: false
  
  ## GVS:MT
  # opleidingsnaam: "B Mens en Techniek"
  # opleiding: "MT"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: false
  
  ## GVS:HDT
  # opleidingsnaam: "B Huidtherapie"
  # opleiding: "HDT"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: true
  
  ## FDR:ORM DT
  # opleidingsnaam: "B Ondernemerschap Retail Management"
  # opleiding: "ORM"
  # opleidingsvorm: "deeltijd"
  # opleidingsvorm_afkorting: "DT"
  # selectie: false
  
  ## TIS:IPO
  # opleidingsnaam: "B Industrieel Product Ontwerpen"
  # opleiding: "IPO"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: false
  
  ## TIS:EC
  # opleidingsnaam: "B Elektrotechniek"
  # opleiding: "E"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: false
  
  ## TIS:B
  # opleidingsnaam: "B Bouwkunde"
  # opleiding: "B"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: false
  
  ## BFM:AC
  # opleidingsnaam: "B International Business"
  # opleiding: "IB-ES-3"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: false
  
  ## BFM:AC
  # opleidingsnaam: "B Accountancy"
  # opleiding: "AC"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: false
  
  ## ITD:CMD
  # opleidingsnaam: "B Communication and Multimedia Design"
  # opleiding: "CMD"
  # opleidingsvorm: "voltijd"
  # opleidingsvorm_afkorting: "VT"
  # selectie: false
  
  ## Author
  author: "Theo Bakker, lector Learning Technology & Analytics"
  
## Content
includes:
  inleiding:      true
  data:           true
  model_lr:       true
  model_rf:       true
  model_svm:      false
  final_fit:      true
  conclusies:     true
  verantwoording: true
  copyright:      true
---

```{r setup, include = FALSE}
#| label: setup

## Sluit het _Setup.R bestand in
source("_Setup.R")

```

<!-- Inleiding -->

::: {.content-hidden unless-meta="includes.inleiding"}
# Inleiding

Na de basis-analyse van de data en het bouwen van de prognosemodellen, gaan we in deze verdiepende analyse dieper in op de onderliggende mechanismen van de modellen. Het doel is beter te begrijpen of er studenten zijn met minder kans op succes en of dit disproportioneel is. Dit kan duiden op kansenongelijkheid.

De verdiepende analyse heeft een aantal stappen:

1.  We lezen de bewerkte dataset in en de modellen die we in de basis-analyse hebben gemaakt.
2.  We maken een *explainer* om de modellen beter te begrijpen en te kunnen uitleggen. Dit lichten we later in deze pagina toe.
3.  We gebruiken het beste model om de prognosemodellen te verklaren en te begrijpen. We kijken naar de bijdrage van de variabelen aan de voorspelling en passen het model toe op gemiddelde studenten.
4.  Tot slot berekenen we of er een bias bestaat voor verschillende groepen studenten en of er mogelijk sprake is van kansenongelijkheid.
:::

<!-- Data -->

# Voorbereidingen

## Laad de data

We laden de bewerkte data en prognosemodellen in voor:

**Opleiding**: `r params$faculteit` \| `r params$opleidingsnaam` (`r params$opleiding`), `r params$opleidingsvorm`, eerstejaars - **`r sUitval_model`**

```{r}
#| label: load_data

## Bepaal de paden
sData_outputpath         <- Get_Model_outputpath(mode = "data")
sFittedmodels_outputpath <- Get_Model_outputpath(mode = "last-fits")
sModelresults_outputpath <- Get_Model_outputpath(mode = "modelresults")

## Laad de data voor de opleiding: data, last fits en model results
dfOpleiding_inschrijvingen <- rio::import(sData_outputpath, trust = TRUE)
lLast_fits                 <- rio::import(sFittedmodels_outputpath, trust = TRUE)
dfModel_results            <- rio::import(sModelresults_outputpath, trust = TRUE)

```

# Verdiepende analyse van het model

We weten vanuit de basis-analyse welke variabelen van invloed zijn, maar niet hoe en in welke richting: dragen ze sterk bij of juist niet, verhogen of verlagen ze uitval? Om het model beter te begrijpen en te kunnen uitleggen, maken met behulp van het [`Dalex` package](https://dalex.drwhy.ai) een *explainer*. Dit package is ontwikkeld om beter uit te leggen welke variabelen van belang zijn en wat deze voor een effect hebben in een model. Een explainer is een model-onafhankelijke *wrapper* om het model heen en geeft inzicht in de voorspellingen van het model en de bijdrage van de variabelen aan de prognose. Een explainer maakt het verder mogelijk om modellen onderling te vergelijken en benchmarken.

## Recap van de basis-analyse

Uit de basis-analyse kwam de volgende lijst met meest voorspellende factoren: 

```{r, include=FALSE}
#| label: fitted_model

sBest_model <- dfModel_results$model[dfModel_results$number == 1]
last_fit    <- lLast_fits[[sBest_model]]

fitted_model <- last_fit |>
  extract_fit_parsnip()

## Controleer of de coefficienten van het model numeriek zijn
coefs <- tidy(fitted_model)$estimate

# Controleer of de coëfficiënten numeriek zijn
if (!is.numeric(coefs)) {
  stop("De geëxtraheerde coëfficiënten zijn niet numeriek.")
}

vip::vip(fitted_model, num_features = 20) +
  ggtitle("Meest voorspellende factoren") +
  ylab("Importance")


```
## Maak een explainer

We gaan nu een stap verder met behulp van het `Dalex` package. Op basis van het tidymodels model extraheren we de informatie voor de explainer van Dalex.

```{r}
#| label: last_fit_explainer

## Extraheer het fitted model en de workflow
fitted_model <- last_fit |>
  extract_fit_parsnip()

workflow <- last_fit |>
  extract_workflow()

# Pas de Uitval variabele aan naar numeric (0/1), 
# zodat er een explainer van gemaakt kan worden
dfOpleiding_inschrijvingen$Uitval <- as.numeric(dfOpleiding_inschrijvingen$Uitval) - 1

# Maak een explainer
explain_lm <- DALEX::explain(
  model = workflow,
  data = dfOpleiding_inschrijvingen,
  y = dfOpleiding_inschrijvingen$Uitval,
  label = "Linear Regression")

```

```{r}
#| label: last_fit_model_parts

## Bereken de model parts op basis van de RMSE
mp <- model_parts(explain_lm, loss_function = loss_root_mean_square)

# Toon de resultaten
plot(mp) 

```

## Pas het model toe op 'meest voorkomende' studenten

Nu we deze explainer hebben, kunnen we het model toepassen op de meest voorkomende student. We kijken eerst naar de meest voorkomende student in het algemeen. We analyseren vervolgens de meest voorkomende student in meerdere groepen: naar vooropleiding, geslacht, leeftijd en aansluiting. Om de meest voorkomende student te bepalen, gebruiken we de meest frequente waarden van de variabelen in de dataset per groep. 

_Ter illustratie_ Stel dat we een onderscheid maken tussen mbo en havo studenten, dan bepalen we de mediaan van numerieke variabelen en de meest frequente waarde van categorische variabelen. De meest voorkomende student is dus geen daadwerkelijke student, maar een representatie van de groep op basis van de meest frequente kenmerken.

We kijken hiermee naar de voorspelling van het model per groep en de bijdrage van de variabelen aan die specifieke voorspelling. Dit geeft een verder inzicht in de werking van het model. Een categorie met 20 studenten of minder laten we buiten beschouwing.

```{r}
#| label: last_fit_break_down_tmp
#| echo: false
#| results: asis

source("01. Includes/Studentpersonas_opleidingen.R")

breakdown_lm_tmp <- predict_parts(explainer = explain_lm,
                                  new_observation = dfOpleiding_inschrijvingen[1, ],
                                  type = "break_down")

nIntercept <- breakdown_lm_tmp |> 
filter(variable == "intercept") |>
pull(cumulative) * 100 |> 
round(1) 

sIntercept <- Number_to_readable(nIntercept, digits = 1)

```

### Toelichting op de opbouw van de kans op uitval
De opbouw van het model bestaat uit een _intercept_, gevolgd door variabelen die een verschil maken ten opzichte van die intercept. De intercept is de basiskans op uitval voor alle studenten. Deze kans is voor de `r params$opleidingsnaam` (`r params$opleiding`) `r params$opleidingsvorm` `r sIntercept`%. De cumulatieve bijdrage van de variabelen aan de voorspelling kan positief of negatief zijn. Een positieve bijdrage betekent dat de variabele de kans op uitval verhoogt, een negatieve bijdrage betekent dat het de kans op uitval verlaagt. 

Het kan zijn dat nieuwe variabelen geen invloed meer hebben op de kans. Dit betekent niet per se dat ze niet belangrijk zijn. Het kan zijn dat de invloed die ze hebben op de kans al is afgevangen door variabelen die eerder in het model zijn opgenomen. Een voorbeeld: de variabele `Cijfer_CE_VO_missing = Ja` betekent dat een student geen VO cijfers heeft voor het Centraal Examen. Dit geldt voor vrijwel alle MBO studenten. Doordat de variabele Cijfer_CE_VO_missing de kans op uitval net wat sterker beïnvloedt, komt `Vooropleiding = MBO` niet meer voor als invloedrijke variabele, maar is dit wel de achterliggende reden dat het cijfer ontbreekt.

Uiteindelijk tellen alle variabelen op tot een definitieve voorspelling die per persoon verschilt, afhankelijk van hun persoonlijke kenmerken per variabele. 
 
### De meest voorkomende student

We kijken eerst naar de meest voorkomende student in de opleiding. We analyseren de kans op uitval voor deze _fictieve_ student en de bijdrage van de variabelen aan die kans. Daarbij tonen we de verdeling van de voorspellingen voor deze student voor alle variabelen en per variabele. Dit laat zien welke variabelen belangrijk zijn, naar welke kant de verdeling neigt en welke spreiding de kansverdeling heeft. Wat betekent dit?

-   **All data** - De eerste variabele `all data` is eigenlijk geen variabele, maar geeft aan wat alle data samen aan kans op uitval voorspellen. Variabelen die daarna bovenaan staan, wegen het zwaarst in de voorspelling van de kans. 
-   **Richting** - Als de verdeling van de kansen naar de rechterkant van de x-as gaat, draagt deze variabele meer bij aan een toename op de kans op uitval; als deze naar de linkerkant beweegt, draagt deze variabele juist bij aan een afname op de kans op uitval. 
-   **Spreiding** Als de spreiding breed is, geeft dit aan dat er binnen deze variabele veel variatie is in de kans op uitval en er voorzichtig mee omgegaan moet worden. Als de spreiding heel smal is, betekent dit dat de variabele weinig of geen invloed heeft op de kans op uitval. Deze variabelen bevinden zich op de intercept.
 
```{r}
#| label: last_fit_break_down_distribution_tmp
#| echo: false
#| results: asis

## Bepaal de plot
sPlotPath <- file.path(Get_Plot_outputpath(plotname = "last_fit_break_down_distribution_tmp"))

## Als de plot niet bestaat, maak dan een nieuwe plot
if(!file.exists(sPlotPath)) {

  ## Bepaal de algemene persona en de breakdown (met distributie)
  dfPersona_all <- Get_dfPersona()
  breakdown_lm_all <- predict_parts(explainer = explain_lm,
                                  new_observation = dfPersona_all[1, ],
                                  type = "break_down",  
                                  keep_distributions = TRUE)

  ## Bouw de plot
  plot <- plot(breakdown_lm_all, plot_distributions = TRUE)
  suppressWarnings(print(plot))
  
  ## Sla de plot op
  ggsave(sPlotPath, plot, dpi = 72, units = "in", device = 'png')

} else {
  
  ## Toon de bestaande plot
  knitr::include_graphics(sPlotPath)
  
}



```

Nu de globale opbouw van de kans op uitval bekend is, gaan we verder met de analyse van de meest voorkomende studenten per groep.

```{r}
#| label: last_fit_break_down
#| echo: false
#| results: asis

## Loop over de persona's
for (name in names(lDfPersona)) {
  
  dfPersona <- lDfPersona[[name]]

  ## Print de naam van lDfPersona
  knit_print(glue("\n\n\n### Naar {tolower(name)}\n\n"))

  ## Code om aan te geven of we een categorie buiten beschouwing laten
  ## Bepaal of er in de dataset een groep is met minder dan 21 studenten
  if (any(dfPersona$Subtotaal < 21)) {

    lCategorie_te_laag <- dfPersona |>
        filter(Subtotaal < 21) |> 
        pull(Categorie) |> 
        paste(collapse = ", ")

    cat(glue("\n\n\nSubtotaal voor {name}: {lCategorie_te_laag} is te laag voor een betrouwbare analyse. \n\n"))
  }

  # Loop over de persona's
  for (j in 1:nrow(dfPersona)) {

    ## Bepaal de huidige student
    student_current   <- dfPersona[j, ]
    student_groep     <- student_current$Groep
    student_categorie <- levels(student_current[[student_groep]])[j]
    
    breakdown_lm <- predict_parts(explainer = explain_lm,
                                  new_observation = student_current,
                                  type = "break_down")
    
    # Maak een dataframe for ggplot
    dfBreakdown_lm <- Get_dfBreakdown_lm(breakdown_lm)

    ## Bepaal de uitvalskans, totalen en de titel/ondertitel
    nUitval <- Number_to_readable(as.numeric(dfBreakdown_lm$cumulative[dfBreakdown_lm$variable == 'Voorspelling']) * 100, digits = 1)
    nSubtotaal  <- Number_to_readable(as.numeric(dfPersona[j, 'Subtotaal']))
    nTotaal     <- Number_to_readable(as.numeric(dfPersona[j, 'Totaal']))
    nPercentage <- Number_to_readable(as.numeric(dfPersona[j, 'Percentage']) *
                                        100, digits = 1)

    # Bouw de titel
    student_current_title    <- glue("Opbouw van de kans op uitval naar {tolower(student_groep)}")
    student_current_subtitle <- glue(
      "{student_groep}: **{student_categorie}**",
      " | kans op uitval: {nUitval}%",
      " | _N_ = {nSubtotaal} van {nTotaal} ({nPercentage}%)"
    )

    ## Als het subtotaal < 11, ga dan door naar het volgende item
    if (as.numeric(dfPersona[j, 'Subtotaal']) < 21) {
      # cat(glue("\n\n\nSubtotaal voor {student_groep}: **{student_categorie}** is te laag voor een betrouwbare analyse. \n\n"))
      next
    }

    # Bepaal de breaks voor de x-as
    y_breaks <- seq(0, 1, by = 0.2)
    y_labels <- paste0(seq(0, 100, by = 20), "%")

    # Watervalplot met ggplot
    p <- Get_Waterfall_plot(dfBreakdown_lm)

    # Print de plot
    suppressWarnings(print(p))
    
  }
  
}

```

<!-- Conclusies -->

::: {.content-hidden unless-meta="includes.conclusies"}
# Conclusies

Hier komen de conclusies.
:::

<!-- Verantwoording -->

::: {.content-hidden unless-meta="includes.verantwoording"}
```{r, echo=FALSE, results='asis'}
sQuarto_version <- quarto::quarto_version()
```

 

**Verantwoording**

Deze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: [No Fairness without Awareness](https://www.dehaagsehogeschool.nl/onderzoek/kenniscentra/no-fairness-without-awareness) \| Het rapport is door het lectoraat ontwikkeld in [Quarto](https://quarto.org/) `r sQuarto_version`. \| Template versie: `r rmarkdown::metadata$ltatemplate`
:::

<!-- Copyright -->

::: {.content-hidden unless-meta="includes.copyright"}
```{r, echo=FALSE, results='asis'}
nCurrent_year   <- as.numeric(format(Sys.Date(), "%Y"))
```

 

**Copyright**

Dr. Theo Bakker, Lectoraat Learning Technology & Analytics, De Haagse Hogeschool © 2023-`r nCurrent_year` Alle rechten voorbehouden.
:::

<!-- Opschonen -->

```{r, echo = FALSE}
#| label: cleanup

## Datasets


## Collect garbage
invisible(gc())
  
```
