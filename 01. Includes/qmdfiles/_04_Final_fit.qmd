---
format: html
---

# De uiteindelijke fit

-   In de laatste stap van deze analyse maken we het model definitief.
-   We testen het model op de testset en evalueren het model met metrieken en de Variable Importance Factor (VIF).

## Combineer de AUC/ROC curves en kies het beste model

Eerst combineren we de AUC/ROC curves van de modellen om ze te vergelijken. We kiezen het beste model op basis van de hoogste AUC/ROC.

```{r}

## Combineer de AUC/ROC curves om de modellen te vergelijken
bind_rows(lr_auc, rf_auc) |> 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  theme_minimal() +
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6)

```

```{r}

## Bepaal welke van de modellen het beste is op basis van de hoogste AUC/ROC
dfModel_results <- dfModel_results |>
  mutate(number = row_number()) |> 
  mutate(best = ifelse(auc == max(auc), TRUE, FALSE)) |> 
  arrange(number)

## Bepaal het beste model
sBest_model <- dfModel_results$model[dfModel_results$best == TRUE]
```

```{r, echo=FALSE, results='asis'}

## Bouw de tekst voor de beste modellen op
sText_best_model <- ""

for (i in 1:nrow(dfModel_results)) {
  sText_best_model <-
    glue(
      sText_best_model,
      "Het {dfModel_results[i,]$model} model heeft een AUC van {round(dfModel_results[i,]$auc, 4)}. "
    )
}

sText_best_model <-
  glue(
    sText_best_model,
    "Het beste model is het **{sBest_model}** model. We ronden de analyse verder af met dit model."
  )

```

`r sText_best_model`

## Maak het finale model

```{r, echo=FALSE, results='asis'}

## Bouw de tekst voor het laatste model op
if(sBest_model == "Logistisch Regressie") {
  
  ## Maak het laatste model
  sText_final_model <- "We maken het finale model op basis van de beste parameters die we hebben gevonden. Voor het Logistisch Regressie model is dit het model met de beste penalty en mixture."

} else if (sBest_model == "Random Forest") {
  
  ## Maak het laatste model
  sText_final_model <- "We maken het finale model op basis van de beste parameters die we hebben gevonden. Door in de engine bij `importance` de `impurity` op te geven, wordt het beste random forest model gekozen om de data definitief mee te classificeren."

}
```

We maken het finale model op basis van de beste parameters die we hebben gevonden. Door in de engine bij `importance` de `impurity` op te geven, wordt het beste random forest model gekozen om de data definitief mee te classificeren.

```{r}
#| code-fold: false

## Test het ontwikkelde model op de testset
## Bepaal de optimale parameters

## Bouw het laatste model
if (sBest_model == "Logistic Regression") {
  
  last_lr_mod <-
    logistic_reg(penalty = lr_best$penalty,
                 mixture = lr_best$mixture) |>
    set_engine("glmnet") |>
    set_mode("classification")

} else if (sBest_model == "Random Forest") {
  
  last_rf_mod <-
    rand_forest(mtry = rf_best$mtry,
                min_n = rf_best$min_n,
                trees = 1000) |>
    set_engine("ranger", num.threads = cores, importance = "impurity") |>
    set_mode("classification")

}
```

## Maak de workflow

We voegen het model toe aan de workflow en updaten de workflow met het finale model.

```{r}
#| code-fold: false

## Bouw de laatste workflow op basis van het laatste model
if (sBest_model == "Logistic Regression") {
  
  last_lr_workflow <- 
    lr_workflow |> 
    update_model(last_lr_mod)
  
} else if (sBest_model == "Random Forest") {
  
  last_rf_workflow <- 
    rf_workflow |> 
    update_model(last_rf_mod)
  
}

```

## Fit het finale model

We voeren de finale fit uit. De functie `last_fit` past het model toe op de validatieset.

```{r}
#| code-fold: false

## Voer de laatste fit uit
set.seed(2904)

if(sBest_model == "Logistic Regression") {
  
  last_fit <- 
    last_lr_workflow |> 
    last_fit(splits)
  
} else if(sBest_model == "Random Forest") {
  
  last_fit <- 
    last_rf_workflow |> 
    last_fit(splits)
  
}
```

## Evalueer het finale model: metrieken en vif

We evalueren het finale model op basis van 3 metrieken (accuraatheid, ROC/AUC en de [Brier score](https://en.wikipedia.org/wiki/Brier_score) = de Mean Squared Error) en de Variable Importance Factor (VIF). Uit de VIF is op te maken welke variabelen het meest bijdragen aan de voorspelling van de uitkomstvariabele.

```{r}
#| code-fold: false

## Verzamel de metrieken
last_fit |> 
  collect_metrics() |> 
  mutate(.estimate = round(.estimate, 4)) |>
  knitr::kable()

## Extraheer de feature importance
last_fit |>
  extract_fit_parsnip() |>
  vip(num_features = 20) +
  ggtitle("Belangrijkste Kenmerken") +
  ylab("Importance") +
  theme_minimal()
  

```

## Plot de ROC curve

Tot slot maken we een ROC curve om de prestaties van het definitieve model te visualiseren. De Sensitivity (True Positive Rate) en Specificity (True Negative Rate) worden hierin uitgezet. De Area under the ROC Curve (AUC/ROC) geeft de prestaties van het model weer. Het model scoort beter naarmate de AUC/ROC dichter bij de 1 ligt (in de linkerbovenhoek). Een AUC/ROC van 0,5 betekent dat het model niet beter presteert dan een willekeurige voorspelling.

```{r}
#| code-fold: false

## Toon de roc curve
last_fit |> 
  collect_predictions() |> 
  roc_curve(Uitval, .pred_FALSE) |> 
  autoplot() +
  theme_minimal()

```
