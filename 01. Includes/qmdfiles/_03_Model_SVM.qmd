# Model III: Support Vector Machine

-   Het derde model is een [Support Vector Machine (SVM)](https://en.wikipedia.org/wiki/Support_vector_machine). Ook SVM is een krachtig model dat goed om kan gaan met complexe data en veel variabelen.

## Maak het model

We bouwen eerst het model.

```{r}
#| code-fold: false

## Bouw het model: svm
svm_mod <- 
  svm_poly(cost = tune(), degree = tune()) |>
  set_engine("kernlab") |>
  set_mode("classification")

```

## Maak de recipe

Vervolgens zetten we meerdere stappen in een 'recipe'. We verwijderen de student ID en het collegejaar uit de data, omdat deze niet moet worden gebruikt in het model. We converteren factoren naar dummy variabelen, verwijderen zero values en centreren en schalen numerieke variabelen.

```{r}
#| code-fold: false

## Bouw de recipe: svm
svm_recipe <- 
  recipe(Uitval ~ ., data = dfUitval_train) |>  
  update_role(ID, new_role = "ID") |>           ## Zet de student ID als ID variabele
  step_rm(ID, Collegejaar) |>                   ## Verwijder ID en collegejaar uit het model
  step_dummy(all_nominal_predictors()) |>       ## Converteer factoren naar dummy variabelen
  step_zv(all_predictors()) |>                  ## Verwijder zero values
  step_normalize(all_numeric_predictors())      ## Centreer en schaal numerieke variabelen

## Toon de recipe
tidy(svm_recipe) |> 
  knitr::kable()
```

## Maak de workflow

Voor de uitvoering bouwen we een nieuwe workflow. Daaraan voegen we het model en de bewerkingen in de recipe toe.

```{r}
#| code-fold: false

## Maak de workflow: svm
svm_workflow <- 
  workflow() |>          ## Maak een workflow
  add_model(svm_mod) |>  ## Voeg het model toe
  add_recipe(svm_recipe) ## Voeg de recipe toe

## Toon de workflow
svm_workflow
```

## Tune en train het model

Het model moet getuned worden. Dit houdt in dat we de beste parameters voor het model moeten vinden. We maken een grid met verschillende penalty waarden. Daarmee kunnen we vervolgens het beste model selecteren met de hoogste ROC/AUC. We plotten de resultaten van de tuning, zodat we hieruit het beste model kunnen kiezen.

```{r}
#| code-fold: false

## Maak een grid: svm
svm_reg_grid <- grid_regular(cost(),
                             degree(range = c(1, 3)),
                             levels = c(cost = 5, degree = 3))

## Train en tune het model: svm
svm_res <- 
  svm_workflow |> 
  tune_grid(dfUitval_validation,
            grid = svm_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
saveRDS(svm_res, file = "10. Output/modelresults/svm_initial_tune.rds")

autoplot(svm_res)

```

```{r}

# Plot de resultaten
svm_plot <-
  svm_res |>
  collect_metrics() |>
  filter(.metric == "roc_auc") |>
  roc_curve(Uitval, .pred_FALSE) |> 
  autoplot()
# ggplot(aes(x = cost, y = mean)) +
# geom_point() +
# geom_line() +
# ylab("Area under the ROC Curve")

svm_plot
```

## Kies het beste model

We evalueren modellen met een zo hoog mogelijke Area under the ROC Curve (AUC/ROC) en een zo laag mogelijke penalty. Zo kunnen we uit de resultaten het beste model kiezen. Tot slot maken we een ROC curve om de prestaties van het model te visualiseren.

```{r}
#| code-fold: false

## Toon de beste modellen: svm
top_models <-
  svm_res |> 
  show_best(metric = "roc_auc", n = 10) |> 
  mutate(mean = round(mean, 4)) |>
  arrange(-mean) 

top_models|> 
  knitr::kable()

```

```{r}
#| code-fold: false

## Selecteer het beste model: svm
svm_best <- 
  svm_res |> 
  select_best(metric = "roc_auc") 

svm_best|> 
  knitr::kable()

```

```{r}
#| code-fold: false

## Verzamel de predicties en evalueer het model (AUC/ROC): logistische regressie
svm_auc <- 
  svm_res |> 
  collect_predictions(parameters = svm_best) |> 
  roc_curve(Uitval, .pred_FALSE) |> 
  mutate(model = "Logistic Regression")

autoplot(svm_auc)

tmp_svm <- svm_res |> 
  collect_predictions(parameters = svm_best) |>
  ## haal de accuracy eruit
  collect_metrics() |>
  filter(.metric == "accuracy") |>
  pull(.estimate)

```
