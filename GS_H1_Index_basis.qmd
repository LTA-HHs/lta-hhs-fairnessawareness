---
title: "Prognosemodel retentie na 1 jaar (Gewogen)"
subtitle: "`r params$faculteit` | `r params$opleidingsnaam` (`r params$opleiding`) - `r params$opleidingsvorm` - versie `r params$versie`"

## Auteur en datum
author: "Theo Bakker, lector Learning Technology & Analytics, De HHs"
date: last-modified

## LTA Template
ltatemplate: 0.9.1.9000

## Format en output
output-file: "lta-hhs-tidymodels-retentie-basis-gewogen.html"

## Parameters        
params:
  versie: "1.0"
  succes: "Retentie na 1 jaar"
  propedeusediploma: "Nvt" ## Nvt/Met P/Zonder P
  
  ## Recreate plots
  recreateplots: true
  
  ## BRV:ORM DT
  faculteit: "BRV"
  opleidingsnaam: "B Bestuurskunde Overheidsmanagement"
  opleiding: "BO"
  opleidingsvorm: "duaal"
  opleidingsvorm_afkorting: "DU"
  selectie: false
  
  ## Author
  author: "Theo Bakker, lector Learning Technology & Analytics"
  
## Content
includes:
  inleiding:      true
  data:           true
  model_lr:       true
  model_rf:       true
  model_svm:      false
  final_fit:      true
  conclusies:     true
  verantwoording: true
  nextsteps:      true
  copyright:      true
---

```{r setup, include = FALSE}
#| label: setup

## Sluit het _Setup.R bestand in
source("_Setup.R")

## Maak een df om de resultaten per model in op te slaan
dfModel_results <- data.frame(
  model = character(),
  auc = numeric()
)
```

<!-- Data -->

## Voorbereidingen

### Laad de data

We laden een subset in van historische data specifiek voor:

**Opleiding**: `r params$faculteit` \| `r params$opleidingsnaam` (`r params$opleiding`), `r params$opleidingsvorm`, eerstejaars - **`r sSucces_model`**

```{r}
#| label: load_data

## Laad de data voor de opleiding
dfOpleiding_inschrijvingen_base <- get_lta_studyprogram_enrollments_pin(
    board = "HHs/Inschrijvingen",
    faculty = faculteit,
    studyprogram = opleidingsnaam_huidig,
    studytrack = opleiding,
    studyform = toupper(opleidingsvorm),
    range = "eerstejaars")

## Herschik de levels
Set_Levels(dfOpleiding_inschrijvingen_base)

dfOpleiding_inschrijvingen_base <- dfOpleiding_inschrijvingen_base |>  
  
  ## Maak een eenvoudige succes variabele aan
  Mutate_Retentie(sSucces_model) |>
  
  ## Maak van de succes variabele een factor
  mutate(SUC_Retentie = as.factor(SUC_Retentie)) |> 

  ## Verbijzonder eventueel op basis van het propedeusediploma
  # Filter_Propedeusediploma(sPropedeusediploma) |>

  ## Maak van de Dubbele studie variabele een Ja/Nee variabele
  mutate(INS_Dubbele_studie = ifelse(INS_Aantal_inschrijvingen > 1, "Ja", "Nee")) |>  

  ## Verwijder INS_Aantal_inschrijvingen
  select(-INS_Aantal_inschrijvingen) |> 

  ## Pas voor een aantal variabelen de levels aan
  Mutate_Levels(
  c(
    "VOP_Studiekeuzeprofiel_LTA_afkorting",
    "INS_Aansluiting_LTA",
    "VOP_Toelaatgevende_vooropleiding_soort"
  ),
    list(lLevels_skp, lLevels_vop, lLevels_vop)
  )
  
## B Huidtherapie: Filter op uitsluitend studenten met een rangnummer (selectie)
if(opleiding == "HDT") {
  dfOpleiding_inschrijvingen_base <- dfOpleiding_inschrijvingen_base |> 
    filter(!is.na(RNK_Rangnummer)) 
} 

```

### Selecteer en inspecteer de data

We selecteren eerst de relevante variabelen. We verwijderen daarbij variabelen die maar 1 waarde hebben. We bekijken de variabelen in een samenvatting in relatie tot retentie. Daarnaast bekijken we de kwaliteit van de data op missende waarden.

```{r}
#| label: select_inspect_data

lSelect <- c(
    "INS_Student_UUID_opleiding_vorm",
    "CBS_APCG_tf",
    "DEM_Geslacht",
    "DEM_Leeftijd_1_oktober",
    "GIS_Tijd_fiets_OV",
    "INS_Collegejaar",
    "INS_Dagen_tussen_aanmelding_en_1_september",
    "INS_Dubbele_studie",
    "INS_Aansluiting_LTA",
    "INS_Navitas_tf",
    "SES_Deelscore_arbeid",
    "SES_Deelscore_welvaart",
    "SES_Totaalscore",
    "SUC_Retentie",
    "VOP_Gemiddeld_cijfer_cijferlijst",
    "VOP_Gemiddeld_eindcijfer_VO_van_de_hoogste_vooropleiding_voor_het_HO",
    "VOP_Cijfer_CE1_nederlands",
    "VOP_Cijfer_CE1_engels",
    "VOP_Cijfer_CE_proxy_wiskunde",
    "VOP_Cijfer_CE1_natuurkunde",
    "VOP_Studiekeuzeprofiel_LTA_afkorting",
    "VOP_Toelaatgevende_vooropleiding_soort"
  )

## B Huidtherapie: voeg de variabele RNK_Rangnummer toe
if(opleiding == "HDT") {
  lSelect <- c(lSelect, "RNK_Rangnummer")
}

## Maak een subset
dfOpleiding_inschrijvingen <- dfOpleiding_inschrijvingen_base |>
  
  ## Selecteer de relevante variabelen
  select_at(lSelect) |>
  
  ## Hernoem variabelen voor beter leesbare namen
  rename(
    ID                    = INS_Student_UUID_opleiding_vorm,
    Geslacht              = DEM_Geslacht,
    Leeftijd              = DEM_Leeftijd_1_oktober,
    Reistijd              = GIS_Tijd_fiets_OV,
    Dubbele_studie        = INS_Dubbele_studie,
    Collegejaar           = INS_Collegejaar,
    Aanmelding            = INS_Dagen_tussen_aanmelding_en_1_september,
    Aansluiting           = INS_Aansluiting_LTA,
    Navitas               = INS_Navitas_tf,
    APCG                  = CBS_APCG_tf,
    SES_Arbeid            = SES_Deelscore_arbeid,
    SES_Welvaart          = SES_Deelscore_welvaart,
    SES_Totaal            = SES_Totaalscore,          
    Retentie              = SUC_Retentie,
    Cijfer_SE_VO          = VOP_Gemiddeld_cijfer_cijferlijst,
    Cijfer_CE_VO          = VOP_Gemiddeld_eindcijfer_VO_van_de_hoogste_vooropleiding_voor_het_HO,
    Cijfer_CE_Nederlands  = VOP_Cijfer_CE1_nederlands,
    Cijfer_CE_Engels      = VOP_Cijfer_CE1_engels,
    Cijfer_CE_Wiskunde    = VOP_Cijfer_CE_proxy_wiskunde,
    Cijfer_CE_Natuurkunde = VOP_Cijfer_CE1_natuurkunde,
    Studiekeuzeprofiel    = VOP_Studiekeuzeprofiel_LTA_afkorting,
    Vooropleiding         = VOP_Toelaatgevende_vooropleiding_soort
  ) |> 
  
  ## Pas CBS_APCG_tf aan naar factor
  mutate(APCG = case_when(APCG == TRUE ~ "Ja",
                          APCG == FALSE ~ "Nee",
                          .default = "Onbekend")) |>

  ## Geef aan waar missende cijfers in het VO zijn
  Mutate_Cijfers_VO() |>
  
  ## Verwijder variabelen, waarbij er maar 1 waarde is
  select(where(~ n_distinct(.) > 1)) |>
  
  ## Sorteer op Collegejaar en ID
  arrange(Collegejaar, ID)

## B Huidtherapie: hernoem de variabele RNK_Rangnummer
if(opleiding == "HDT") {
  dfOpleiding_inschrijvingen <- dfOpleiding_inschrijvingen |> 
    rename(Rangnummer = RNK_Rangnummer)
} 

dfOpleiding_inschrijvingen <- dfOpleiding_inschrijvingen |> 
 ltabase::sort_distinct()

## Verwijder de basis dataset
rm(dfOpleiding_inschrijvingen_base)

```

We maken een summary en voegen gewichten toe (willekeurig gegenereerd). We maken een survey design en tonen de samenvattende tabel.


```{r, echo=FALSE, results='asis'}
#| label: summary_data

## Maak een samenvatting van de data
dfOpleiding_inschrijvingen <- dfOpleiding_inschrijvingen |>
  
  ## Pas de labels van Retentie aan van True naar Ja, en van False naar Nee
  mutate(Retentie = fct_recode(Retentie, "Nee" = "FALSE", "Ja" = "TRUE")) |>
  
  ## Pas de volgorde van de labels van Retentie aan
  mutate(Retentie = fct_relevel(Retentie, "Ja", "Nee")) |>
  
  ## Pas Geslacht aan naar factor
  mutate(Geslacht = as.factor(Geslacht)) |>
  
  ## Maak een kolom met willekeurige gewichten tussen 10 en 20 
  mutate(Gewicht = round(runif(n(), 10, 20))) |> 
  
  ## Maak van het gewicht een frequentiegewicht
  mutate(Gewicht = hardhat::frequency_weights(Gewicht))

```

Maak nu een survey design

```{r, echo=FALSE, results='asis'}
#| label: svydesign

## Maak een survey design met de gewichten
dfOpleiding_inschrijvingen_srvy <- survey::svydesign(ids = ~ 1,
                                                     data = dfOpleiding_inschrijvingen,
                                                     weights = ~ Gewicht)

```

Toon de samenvattende tabel.

```{r, echo=FALSE, results='asis'}
#| label: summary_data_tbl

## Toon deze als een samenvattende tabel

tblOpleiding_inschrijvingen_srvy <- dfOpleiding_inschrijvingen_srvy |>
  tbl_svysummary(
    by = Retentie,
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = all_continuous() ~ 1,
    missing = "no",
    percent = "row",
    include = c(-Gewicht, -ID, -Collegejaar) ## Sluit Gewicht, ID en Collegejaar uit van de samenvatting
  ) |>
  
  ## Richt de vormgeving van de table in
  modify_header(all_stat_cols() ~ "**{level}**, N={Change_Number_Marks(n)} ({style_percent(p)}%)") |>
  modify_spanning_header(c("stat_1", "stat_2") ~ "**Retentie**") |>
  modify_header(label = "**Variabele**") |>
  bold_labels() |>
  modify_caption("**Studentkenmerken versus Retentie**") |>
  add_p() |>
  add_significance_stars( hide_p = FALSE, pattern = "{p.value}{stars}" ) |>
  add_overall(last = TRUE, col_label = "**Totaal**, N = {Change_Number_Marks(N)}")
  
  ## Toon de tabel
  
  tblOpleiding_inschrijvingen_srvy
```

Bewaar de samenvattende tabel als afbeelding.
  
```{r, echo=FALSE, results='asis'}
#| label: save_summary_data_as_png

## Bewaar als afbeelding
gt_tbl <- as_gt(tblOpleiding_inschrijvingen_srvy) 
gt_tbl |> 
  gtsave("10. Output/gs/tblOpleiding_inschrijvingen_srvy.png", expand = 10)
  
```
Voer ter illustratie een vergelijking tussen 2 factoren uit (met Geslacht).

```{r, echo=FALSE, results='asis'}
#| label: summary_data_tbl_2f

## Maak een samenvattende tabel voor 2 factoren
tblOpleiding_inschrijvingen_srvy_2f <- dfOpleiding_inschrijvingen_srvy |> 
  
  tbl_strata(
      strata = Geslacht,
      .header = "**{strata}**, N = {n}",
      ~.x |>
    tbl_svysummary(
      by = Retentie,
      include = c(-Geslacht, -Gewicht, -ID, -Collegejaar),
      statistic = list(
        all_continuous() ~ "{mean} ({sd})",
        all_categorical() ~ "{n} ({p}%)"
      ),
      digits = all_continuous() ~ 1, 
      missing = "no",
      percent = "row"
    ) |> 
    
    ## Richt de vormgeving van de table in
    modify_header(all_stat_cols() ~ "**{level}**, N={Change_Number_Marks(n)} ({style_percent(p)}%)") |>
    modify_header(label = "**Variabele**") |>
    bold_labels() |>
    modify_caption("**Studentkenmerken versus Geslacht en Retentie**") |>
    add_p() |> 
    add_significance_stars(
        hide_p = FALSE,
        pattern = "{p.value}{stars}"
      ) |>
    add_overall(last = TRUE, col_label = "**Totaal**, N = {Change_Number_Marks(N)}")
  )

## Toon de tabel
tblOpleiding_inschrijvingen_srvy_2f
```
Bewaar de samenvattende tabel als afbeelding.

```{r, echo=FALSE, results='asis'}
#| label: save_summary_data_as_png_f2
 
## Bewaar als afbeelding

gt_tbl <- as_gt(tblOpleiding_inschrijvingen_srvy_2f)
gt_tbl |> 
  gtsave("10. Output/gs/tblOpleiding_inschrijvingen_srvy_2f.png", expand = 10)

```

## Missende waarden

### Analyseer missende waarden

Analyseer de data en maak een samenvatting van de datakwaliteit.

```{r}
#| label: summarize_data

## Laad dlookr
suppressMessages(library(dlookr))

## Toon een samenvatting van de data, gesorteerd op missende waarden
diagnose(dfOpleiding_inschrijvingen) |> 
  mutate(missing_percent = round(missing_percent, 2),
         unique_rate = round(missing_percent, 2)) |>
  arrange(desc(missing_percent)) |>
  knitr::kable(caption = "Kwaliteit van de data voor bewerkingen (gesorteerd op missende waarden)",
               col.names = c("Variabelen",
                           "Type",
                           "# Missende waarden",
                           "% Missende waarden",
                           "# Unieke waarden",
                           "Ratio unieke waarden"))

## Verwijder dlookr
detach("package:dlookr", unload = TRUE)

```

### Vul missende waarden op

```{r}
#| label: mutate_data

## Bewerk de data
dfOpleiding_inschrijvingen <- dfOpleiding_inschrijvingen |> 
  
  ## Imputeer alle numerieke variabelen met de mean
  mutate(across(where(is.numeric), ~ ifelse(
    is.na(.x),
    mean(.x, na.rm = T),
    .x
  )) ) |>
  
  ## Zet character variabelen om naar factor
  mutate(across(where(is.character), as.factor)) |> 
  
  ## Zet logische variabelen om naar 0 of 1
  mutate(across(where(is.logical), as.integer)) |>
  
  ## Vul in factoren missende waarden op met "Onbekend"
  mutate(across(where(is.factor), ~ suppressWarnings(
    fct_explicit_na(.x, na_level = "Onbekend")
  ))) |> 
  
  ## Herschik de kolommen, zodat Retentie vooraan staat
  select(Retentie, everything()) 

## Bekijk de data
## glimpse(dfOpleiding_inschrijvingen) 

## Laad dlookr
suppressMessages(library(dlookr))

## Maak een diagnose van de data
diagnose(dfOpleiding_inschrijvingen) |> 
  mutate(missing_percent = round(missing_percent, 2),
         unique_rate = round(unique_rate, 2)) |>
  knitr::kable(caption = "Kwaliteit van de data na bewerkingen",
               col.names = c("Variabelen",
                           "Type",
                           "# Missende waarden",
                           "% Missende waarden",
                           "# Unieke waarden",
                           "Ratio unieke waarden"))

detach("package:dlookr", unload = TRUE)

```

## Correlaties

Het is verstandig om voorafgaand aan het bouwen van een model te kijken naar de onderlinge correlaties tussen numerieke variabelen. Dit geeft inzicht in de data en kan helpen bij het maken van keuzes voor het model of de duiding van de uitkomsten.

```{r}
#| label: corplot_data_base

dfOpleiding_inschrijvingen_clean <- dfOpleiding_inschrijvingen |> 
  select(where(is.numeric)) |> 
  na.omit() # Verwijder rijen met NA-waarden (0 rijen)

# Bereken de correlatiematrix
cor_matrix <- cor(dfOpleiding_inschrijvingen_clean)

# Controleer op NA/NaN/Inf waarden in de correlatiematrix
if(any(is.na(cor_matrix))) {
  stop("De correlatiematrix bevat NA/NaN/Inf waarden.")
}

## Maak een plot van de onderlinge correlaties in numerieke variabelen
corrplot::corrplot(
  cor_matrix, 
  order = 'hclust', 
  addrect = 4, 
  method = "number",  
  tl.cex = 0.8,       
  tl.col = "black",
  diag = FALSE
)
```

De gewogen variant.

```{r}
#| label: corplot_data_weighted

## Laad de wCorr library voor gewogen correlaties
library(wCorr)

# Maak een matrix van de numerieke variabelen zonder gewicht
dfOpleiding_inschrijvingen_variables <- dfOpleiding_inschrijvingen |> 
  select(where(is.numeric)) |> 
  select(-Gewicht) 
dfOpleiding_inschrijvingen_weights <- dfOpleiding_inschrijvingen$Gewicht

# Initialiseer een lege matrix voor de correlaties
var_names  <- colnames(dfOpleiding_inschrijvingen_variables)
cor_matrix <- matrix(ncol = length(var_names), 
                     nrow = length(var_names))
colnames(cor_matrix) <- var_names
rownames(cor_matrix) <- var_names

# Bereken de gewogen correlaties en vul de matrix
for (i in 1:length(var_names)) {
  for (j in 1:length(var_names)) {
    if (i == j) {
      cor_matrix[i, j] <- 1
    } else {
      cor_matrix[i, j] <- weightedCorr(dfOpleiding_inschrijvingen_variables[[i]], 
                                       dfOpleiding_inschrijvingen_variables[[j]], 
                                       method = "pearson", 
                                       weights = dfOpleiding_inschrijvingen_weights)
    }
  }
}

# Toon de matrix
cor_matrix |> 
  corrplot::corrplot(
    order = 'hclust', 
    addrect = 4,
    method = "number",  
    tl.cex = 0.8,       
    tl.col = "black",
    diag = FALSE)


```

## Bouw de datasets

### Split de data: trainingset, validatieset en testset

```{r}
#| label: split_data

set.seed(0821)

## Voeg het gewicht toe aan de data
dfOpleiding_inschrijvingen <- dfOpleiding_inschrijvingen |>
  mutate(Gewicht = hardhat::frequency_weights(Gewicht))

## Splits de data in 3 delen: 60%, 20% en 20%
splits      <- initial_validation_split(dfOpleiding_inschrijvingen,
                                        strata = Retentie,
                                        prop = c(0.6, 0.2))

## Maak drie sets: een trainingset, een testset en een validatieset
dfRetentie_train      <- training(splits)
dfRetentie_test       <- testing(splits)
dfRetentie_validation <- validation_set(splits)

## Maak een resample set op basis van 10 folds (default)
dfRetentie_resamples  <- vfold_cv(dfRetentie_train, strata = Retentie)
```

### Bekijk de proporties van de training- en testset

```{r, echo=FALSE}
#| label: split_data_tbl

## Training set proporties
dfRetentie_train_prop <- dfRetentie_train |> 
  count(Retentie) |> 
  mutate(Naam = "Trainingset",
         prop = n/sum(n)) 

## Test set proporties
dfRetentie_test_prop <- dfRetentie_test  |> 
  count(Retentie) |> 
  mutate(Naam = "Testset",
         prop = n/sum(n)) 

## Combineer de training- en validatieset om te tonen in een tabel
bind_rows(dfRetentie_train_prop,
          dfRetentie_test_prop) |> 
  mutate(prop = scales::percent(prop, accuracy = 0.1)) |>
  select(Naam, Retentie, n, prop) |> 
  knitr::kable(caption = "Verhouding training- en testset",
               col.names = c("Naam", "Retentie", "Aantal", "Proportie"))

```

## Model I: Logistische regressie (gewogen)

### Bouw het model: logistische regressie

```{r}
#| label: lr_mod
#| code-fold: false

## Bouw het model: logistische regressie
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet")
```

### Maak de recipe

```{r}
#| label: lr_recipe
#| code-fold: false

## Bouw de recipe: logistische regressie
lr_recipe <- 
  recipe(Retentie ~ ., data = dfRetentie_train) |>  
  update_role(ID, new_role = "ID") |>           ## Zet de student ID als ID variabele
  step_rm(Collegejaar) |>                       ## Verwijder collegejaar uit het model
  step_dummy(all_nominal_predictors()) |>       ## Maak dummy variabelen van categorische variabelen
  step_zv(all_predictors()) |>                  ## Verwijder zero values
  step_normalize(all_numeric_predictors())      ## Centreer en schaal numerieke variabelen

## Toon de recipe
tidy(lr_recipe) |> 
  knitr::kable(col.names = c("Nummer", 
                             "Operatie", 
                             "Type",
                             "Getraind",
                             "Sla over",
                             "ID"))
```
De variabelen die nu nog resteren zijn:

```{r, echo=FALSE}
#| label: lr_recipe_tbl

## Toon de variabelen die nog resteren
model_vars <- lr_recipe |> 
  prep() |> 
  juice() |> 
  names()

## Voeg lege waarden toe om de lengte deelbaar door 3 te maken
while (length(model_vars) %% 3 != 0) {
  model_vars <- c(model_vars, "")
}

model_vars_matrix <- matrix(model_vars, ncol = 3, byrow = FALSE)

knitr::kable(model_vars_matrix, caption = "Resterende variabelen na bewerkingen")

```

### Maak de workflow

Voor de uitvoering bouwen we een nieuwe workflow. Daaraan voegen we het model en de bewerkingen in de recipe toe.

```{r}
#| label: lr_workflow
#| code-fold: false

## Maak de workflow: logistische regressie
lr_workflow <- 
  workflow() |>              ## Maak een workflow
  add_model(lr_mod) |>       ## Voeg het model toe
  add_recipe(lr_recipe) |>   ## Voeg de recipe toe
  add_case_weights(Gewicht)  ## Voeg de gewichten toe
  
## Toon de workflow
lr_workflow
```


### Tune en train het model

Het model moet getuned worden. Dit houdt in dat we de beste parameters voor het model moeten vinden. We maken een grid met verschillende penalty waarden. Daarmee kunnen we vervolgens het beste model selecteren met de hoogste ROC/AUC. We plotten de resultaten van de tuning, zodat we hieruit het beste model kunnen kiezen.

```{r}
#| label: lr_reg_grid_1

cls_metrics <- metric_set(sensitivity, specificity)

## Maak een grid: logistische regressie
lr_reg_grid <- tibble(penalty = 10 ^ seq(-4, -1, length.out = 30))

set.seed(0821)

lr_res <- 
  lr_workflow |>
  tune_grid(resamples = dfRetentie_validation, 
            grid = lr_reg_grid, 
            metrics = cls_metrics)

autoplot(lr_res)

```
```{r}

lr_unwt_workflow <- 
  lr_workflow %>% 
  remove_case_weights()

set.seed(0821)
lr_unwt_res <- 
  lr_unwt_workflow |>  
  tune_grid(resamples = dfRetentie_validation, 
            grid = lr_reg_grid, 
            metrics = cls_metrics)

## Maak een facet plot van deze twee modellen
# Extraheer de resultaten uit lr_workflow_res en voeg een kolom toe om aan te geven welk model het is
lr_unwt_res_metrics <- collect_metrics(lr_unwt_res) |> 
  mutate(model = "Unweighted")
lr_wt_res_metrics <- collect_metrics(lr_res) |> 
  mutate(model = "Weighted")

# Combineer beide resultaten
combined_metrics <- bind_rows(lr_unwt_res_metrics, 
                              lr_wt_res_metrics)

# Facet plot maken
ggplot(combined_metrics, aes(x = penalty, y = mean, color = model, group = .metric)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ model, scales = "free_x") +
  labs(title = "Vergelijking van Modelprestaties",
       x = "Penalty",
       y = "Gemiddelde Prestatie") +
  scale_color_manual(values = c("Unweighted" = "darkblue", "Weighted" = "lightblue")) +
  theme_minimal() +
  theme(legend.position = "top")


```

```{r}
#| label: lr_reg_grid_2
#| code-fold: false

## Maak een grid: logistische regressie
lr_reg_grid <- tibble(penalty = 10 ^ seq(-4, -1, length.out = 30))

## Train en tune het model: logistische regressie
lr_res <- 
  lr_workflow |> 
  tune_grid(dfRetentie_validation,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

```

```{r}
#| label: lr_plot

## Plot de resultaten + een rode verticale lijn voor de max AUC
lr_plot <- 
  lr_res |> 
  collect_metrics() |> 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  
  ## Maak de schaal van de x-as logaritmisch
  scale_x_log10(labels = scales::label_number()) +
    theme(
      axis.title.x = element_text(margin = margin(t = 20))
    ) +
  
  # Bepaal de titel, ondertitel en caption
  labs(
    caption = sCaption,
    x = "Area under the ROC Curve",
    y = "Penalty"
  )
  
  ## Voeg LTA elementen toe
  lr_plot <- Add_LTA_Theme_Elements(lr_plot, title_subtitle = FALSE)
  
# Zoek de penalty waarde met de max AUC
max_auc_penalty <- lr_res |> 
  collect_metrics() |> 
  filter(mean == max(mean)) |> 
  pull(penalty)

# Voeg de rode verticale lijn toe aan lr_plot
lr_plot_plus <- lr_plot + 
  geom_vline(xintercept = max_auc_penalty, color = "red")

# Vind een mean voor de max AUC die hoger is
max_auc_mean <- lr_res |> 
  collect_metrics() |> 
  filter(mean == max(mean)) |> 
  pull(penalty)

## Print de definitieve plot
lr_plot_plus

```

### Kies het beste model

We evalueren modellen met een zo hoog mogelijke Area under the ROC Curve (AUC/ROC) en een zo laag mogelijke penalty. Zo kunnen we uit de resultaten het beste model kiezen. Tot slot maken we een ROC curve om de prestaties van het model te visualiseren.

```{r}
#| label: lr_top_models
#| code-fold: false

## Toon het beste model
top_models <-
  lr_res |> 
  show_best(metric = "roc_auc", n = 10) |> 
  mutate(mean = round(mean, 6)) |>
  arrange(penalty) 

top_models|> 
  knitr::kable(col.names = c("Penalty", 
                             "Metriek", 
                             "Estimator",
                             "Gemiddelde",
                             "Aantal",
                             "SE",
                             "Configuratie"))

```

```{r}
#| label: lr_best
#| code-fold: false

## Selecteer het beste model: logistische regressie
lr_best <- 
  lr_res |> 
  collect_metrics() |> 
  filter(mean == max(mean)) |>
  slice(1) 

lr_best|> 
  mutate(mean = round(mean, 6)) |>
  knitr::kable(col.names = c("Penalty", 
                             "Metriek", 
                             "Estimator",
                             "Gemiddelde",
                             "Aantal",
                             "SE",
                             "Configuratie"))

```

```{r}
#| label: lr_auc
#| code-fold: false

## Verzamel de predicties en evalueer het model (AUC/ROC): logistische regressie
lr_auc <- 
  lr_res |> 
  collect_predictions(parameters = lr_best) |> 
  roc_curve(Retentie, .pred_Ja) |> 
  mutate(model = "Logistisch Regressie")

## Plot de ROC curve
Get_ROC_Plot(lr_auc, position = 1)

## Bepaal de AUC van het beste model
lr_auc_highest   <-
  lr_res |>
  collect_predictions(parameters = lr_best) |> 
  roc_auc(Retentie, .pred_Ja)

## Voeg de naam van het model en de AUC toe dfModel_results
dfModel_results <- 
  dfModel_results |>
  add_row(model = "Logistic Regression", auc = lr_auc_highest$.estimate)

```

<!-- MODEL II: Random Forest -->

## Model II: Random Forest (gewogen)

### Bepaal het aantal PC-cores


```{r}
#| label: cores

## Bepaal het aantal cores
cores <- parallel::detectCores()

```

### Maak het model

```{r}
#| label: rf_mod
#| code-fold: false

## Bouw het model: random forest

rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) |> 
  set_engine("ranger", num.threads = cores) |> 
  set_mode("classification")
```

### Maak de recipe

```{r}
#| label: rf_recipe
#| code-fold: false

## Maak de recipe: random forest
rf_recipe <- 
  recipe(Retentie ~ ., data = dfRetentie_train) |> 
  step_rm(Collegejaar)                          ## Verwijder Collegejaar uit het model
  
## Toon de recipe
tidy(rf_recipe) |> 
  knitr::kable(col.names = c("Nummer", 
                             "Operatie", 
                             "Type",
                             "Getraind",
                             "Sla over",
                             "ID"))
```

### Maak de workflow

We voegen het model en de recipe toe aan de workflow voor dit model.

```{r}
#| label: rf_workflow
#| code-fold: false

## Maak de workflow: random forest
rf_workflow <- 
  workflow() |>              ## Maak een workflow
  add_model(rf_mod) |>       ## Voeg het model toe
  add_recipe(lr_recipe) |>   ## Voeg de recipe toe
  add_case_weights(Gewicht)  ## Voeg de gewichten toe

## Toon de workflow
rf_workflow
```

### Tune en train het model

```{r}
#| label: rf_tune
#| code-fold: false

## Toon de parameters die getuned kunnen worden
rf_mod

## Extraheer de parameters die getuned worden
extract_parameter_set_dials(rf_mod)

## Bepaal de seed
set.seed(2904)

## Bouw het grid: random forest
rf_res <- 
  rf_workflow |> 
  tune_grid(dfRetentie_validation,
            grid = 25,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```

### Kies het beste model

We evalueren de beste modellen en maken een ROC curve om de performance van het model te visualiseren. Vervolgens vergelijken we de prestaties van de modellen en kiezen we het beste model.

```{r}
#| label: rf_results
#| code-fold: false

## Toon de beste modellen
rf_res |> 
  show_best(metric = "roc_auc", n = 15) |> 
  mutate(mean = round(mean, 6)) |>
  knitr::kable(col.names = c("Mtry", 
                             "Min. aantal", 
                             "Metriek",
                             "Estimator",
                             "Gemiddelde",
                             "Aantal",
                             "SE",
                             "Configuratie"))

## Plot de resultaten
autoplot <- autoplot(rf_res) +
  theme_minimal() +
  labs(
    y = "roc/auc",
    caption = sCaption
  )
  
  ## Voeg LTA elementen toe
  autoplot <- Add_LTA_Theme_Elements(autoplot, title_subtitle = FALSE)
  
  print(autoplot)

```

```{r}
#| label: rf_best
#| code-fold: false

## Selecteer het beste model
rf_best <- 
  rf_res |> 
  select_best(metric = "roc_auc")

rf_best|> 
  knitr::kable(col.names = c("Mtry", 
                             "Min. aantal", 
                             "Configuratie"))

```

```{r}
#| label: rf_auc
#| code-fold: true

## Verzamel de predicties
rf_res |> 
  collect_predictions() |> 
  head(10) |>
  mutate(.pred_Nee = scales::percent(.pred_Nee, accuracy = 0.1),
         .pred_Ja  = scales::percent(.pred_Ja, accuracy = 0.1)) |>
  knitr::kable(col.names = c("% Voorsp. Nee", 
                             "% Voorsp. Ja", 
                             "ID",
                             "Rij",
                             "Mtry", 
                             "Min. aantal", 
                             "Retentie",
                             "Gewichten",
                             "Configuratie"))

## Bepaal de AUC/ROC curve
rf_auc <- 
  rf_res |> 
  collect_predictions(parameters = rf_best) |> 
  roc_curve(Retentie, .pred_Ja) |> 
  mutate(model = "Random Forest")

## Plot de ROC curve
Get_ROC_Plot(rf_auc, position = 2)

## Bepaal de AUC van het beste model
rf_auc_highest   <-
  rf_res |>
  collect_predictions(parameters = rf_best) |> 
  roc_auc(Retentie, .pred_Ja)

## Voeg de naam van het model en de AUC toe dfModel_results
dfModel_results <- 
  dfModel_results |>
  add_row(model = "Random Forest", auc = rf_auc_highest$.estimate)

```

<!-- Final Fit -->

## De uiteindelijke fit

### Combineer de AUC/ROC curves en kies het beste model

Eerst combineren we de AUC/ROC curves van de modellen om ze te vergelijken. We kiezen het beste model op basis van de hoogste AUC/ROC.

```{r}
#| label: bind_rows_auc_roc

## Combineer de AUC/ROC curves om de modellen te vergelijken
Get_ROC_Plot(list(lr_auc, rf_auc))

```

```{r}
#| label: best_model_auc_roc

## Bepaal welke van de modellen het beste is op basis van de hoogste AUC/ROC
dfModel_results <- dfModel_results |>
  mutate(number = row_number()) |> 
  mutate(best = ifelse(auc == max(auc), TRUE, FALSE)) |> 
  arrange(number)

## Bepaal het beste model
sBest_model     <- dfModel_results$model[dfModel_results$best == TRUE]
sBest_model_auc <- round(dfModel_results$auc[dfModel_results$best == TRUE], 4)
```

```{r, echo=FALSE, results='asis'}
#| label: best_model_auc_roc_text

## Bouw de tekst voor de beste modellen op
sText_best_model <- ""

walk(1:nrow(dfModel_results), function(i) {
  sText_best_model <-
    glue(
      sText_best_model,
      "Het {dfModel_results[i,]$model} model heeft een AUC van {round(dfModel_results[i,]$auc, 4)}. "
    )
})

## Herschik de uiteindelijke tekst voor een heldere samenvatting
sText_best_model <-
  glue(
    "Het beste model is het **{sBest_model}** model met een **AUC/ROC van {sBest_model_auc}**. {sText_best_model} We ronden de analyse verder af met het {sBest_model} model."
  )

```

`r sText_best_model`

### Maak het finale model

```{r, echo=FALSE, results='asis'}
#| label: text_final_model

## Bouw de tekst voor het laatste model op
if(sBest_model == "Logistisch Regressie") {
  
  ## Maak het laatste model
  sText_final_model <- "We maken het finale model op basis van de beste parameters die we hebben gevonden. Voor het Logistisch Regressie model is dit het model met de beste penalty en mixture."

} else if (sBest_model == "Random Forest") {
  
  ## Maak het laatste model
  sText_final_model <- "We maken het finale model op basis van de beste parameters die we hebben gevonden. Door in de engine bij `importance` de `impurity` op te geven, wordt het beste random forest model gekozen om de data definitief mee te classificeren."

}
```

We maken het finale model op basis van de beste parameters die we hebben gevonden. Door in de engine bij `importance` de `impurity` op te geven, wordt het beste random forest model gekozen om de data definitief mee te classificeren.

```{r}
#| label: last_mod
#| code-fold: false

## Test het ontwikkelde model op de testset
## Bepaal de optimale parameters

## Bouw de laatste modellen
last_lr_mod <-
    logistic_reg(penalty = lr_best$penalty,
                 mixture = 1) |>
    set_engine("glmnet") |>
    set_mode("classification")

last_rf_mod <-
    rand_forest(mtry = rf_best$mtry,
                min_n = rf_best$min_n,
                trees = 1000) |>
    set_engine("ranger", num.threads = cores, importance = "impurity") |>
    set_mode("classification")

```

### Maak de workflow

We voegen het model toe aan de workflow en updaten de workflow met het finale model.

```{r}
#| label: last_workflow
#| code-fold: false

## Update de workflows
 last_lr_workflow <- 
    lr_workflow |> 
    update_model(last_lr_mod)

 last_rf_workflow <- 
    rf_workflow |> 
    update_model(last_rf_mod)

```

### Fit het finale model

We voeren de finale fit uit. De functie `last_fit` past het model toe op de validatieset.

```{r}
#| label: last_fit
#| code-fold: false

## Voer de laatste fit uit
set.seed(2904)

## Maak voor beide modellen een laatste fit, zodat we deze kunnen opslaan voor later gebruik
last_fit_lr <- 
    last_lr_workflow |> 
    last_fit(splits)

last_fit_rf <- 
    last_rf_workflow |> 
    last_fit(splits)

lLast_fits <- list(last_fit_lr, last_fit_rf) |> 
  set_names(c("Logistic Regression", "Random Forest"))

## Bepaal welk model het beste is
if(sBest_model == "Logistic Regression") {
  last_fit <- last_fit_lr
} else if(sBest_model == "Random Forest") {
  last_fit <- last_fit_rf
}

## Bewaar de resultaten, de modelresultaten en de bijbehorende data
sFittedmodels_outputpath <- Get_Model_Outputpath(mode = "last-fits")
saveRDS(lLast_fits, file = sFittedmodels_outputpath)

sModelresults_outputpath <- Get_Model_Outputpath(mode = "modelresults")
saveRDS(dfModel_results, file = sModelresults_outputpath)

sData_outputpath <- Get_Model_Outputpath(mode = "data")
saveRDS(dfOpleiding_inschrijvingen, file = sData_outputpath)

```

### Evalueer het finale model: metrieken en vif

We evalueren het finale model op basis van 4 metrieken: 1) accuraatheid, 2) ROC/AUC en 3) de [Brier score](https://en.wikipedia.org/wiki/Brier_score) (de Mean Squared Error) en 4) de Variable Importance Factor (VIF). Uit de VIF is op te maken welke variabelen het meest bijdragen aan de voorspelling van de uitkomstvariabele.

```{r}
#| label: last_fit_metrics_vif
#| code-fold: false

## Verzamel de metrieken
last_fit |> 
  collect_metrics() |> 
  mutate(.estimate = round(.estimate, 4)) |>
  knitr::kable(col.names = c("Metriek", 
                             "Estimator",
                             "Estimate",
                             "Configuratie"))

```

```{r}
#| label: last_fit_metrics_vif_plot
#| code-fold: true

# Extraheer de feature importance
dfVif <- last_fit |>
  extract_fit_parsnip() |>
  vip::vi() |> 
  arrange(desc(Importance)) |>
  head(20)
  
# Maak de plot met fill op de variabele 'Importance'
importance_plot <- dfVif |> 
  ggplot(aes(x = reorder(Variable, Importance), 
             y = Importance, 
             fill = Importance)) +
  geom_col(show.legend = FALSE) +
  
  ## Maak de titel en caption
  labs(title = "Meest voorspellende factoren",
       subtitle = "Op basis van de Variable Importance Factor (VIF)",
       x = NULL,
       y = "VIF-score",
       caption = sCaption) +
  
  theme_minimal() +
  Set_LTA_Theme() +
  
  theme(
    axis.title.x = element_text(margin = margin(t = 20))
  ) +
  
  coord_flip()
  
  ## Voeg LTA elementen toe
  importance_plot <- Add_LTA_Theme_Elements(importance_plot, title_subtitle = TRUE)

# Toon de plot
print(importance_plot)

```

### Plot de ROC curve

Tot slot maken we een ROC curve om de prestaties van het definitieve model te visualiseren. De Sensitivity (True Positive Rate) en Specificity (True Negative Rate) worden hierin uitgezet. De Area under the ROC Curve (AUC/ROC) geeft de prestaties van het model weer. Het model scoort beter naarmate de AUC/ROC dichter bij de 1 ligt, de linker bovenhoek. De linker bovenhoek houdt in dat alle prognoses exact overeenstemmen met de werkelijkheid. Een AUC/ROC van 0,5 betekent dat het model niet beter presteert dan een willekeurige voorspelling.

```{r}
#| label: last_fit_roc
#| code-fold: false

## Toon de roc curve
auc_lf <- last_fit |> 
  collect_predictions() |> 
  roc_curve(Retentie, .pred_Ja) |> 
  mutate(model = "Last fit")

Get_ROC_Plot(auc_lf, position = 3)

```

<!-- Verantwoording -->

```{r, echo=FALSE, results='asis'}
sQuarto_version <- quarto::quarto_version()
```

 

**Verantwoording**

Deze analyse maakt deel uit van het onderzoek naar kansengelijkheid van het lectoraat Learning Technology & Analytics van De Haagse Hogeschool: [No Fairness without Awareness](https://www.dehaagsehogeschool.nl/onderzoek/kenniscentra/no-fairness-without-awareness) \| Het rapport is door het lectoraat ontwikkeld in [Quarto](https://quarto.org/) `r sQuarto_version`. \| Template versie: `r rmarkdown::metadata$ltatemplate`


<!-- Copyright -->

```{r, echo=FALSE, results='asis'}
nCurrent_year   <- as.numeric(format(Sys.Date(), "%Y"))
```

 

**Copyright**

Dr. Theo Bakker, Lectoraat Learning Technology & Analytics, De Haagse Hogeschool © 2023-`r nCurrent_year`. Alle rechten voorbehouden.

<!-- Opschonen -->

```{r, echo = FALSE}
#| label: cleanup

## Datasets
rm(
  dfOpleiding_inschrijvingen,
  dfRetentie_test,
  dfRetentie_train,
  dfRetentie_validation,
  splits
  )

## Logistische regressie
  rm(
    lr_auc,
    lr_auc_highest,
    lr_best,
    lr_mod,
    lr_plot,
    lr_recipe,
    lr_res,
    lr_workflow
  )
  # if(sBest_model == "lr") {
  #   rm(last_lr_mod,
  #      last_lr_workflow)
  # }


## Random Forest
  rm(
    rf_auc,
    rf_auc_highest,
    rf_best,
    rf_mod,
    rf_recipe,
    rf_res,
    rf_workflow,
    last_rf_mod,
    last_rf_workflow
  )
  # if(sBest_model == "rf") {
  #   rm(last_rf_mod,
  #      last_rf_workflow)
  # }


## Final Fit

  rm(
    last_fit
  )


## Conclusies

  rm(
    top_models
    )


## Collect garbage
invisible(gc())
  
```
