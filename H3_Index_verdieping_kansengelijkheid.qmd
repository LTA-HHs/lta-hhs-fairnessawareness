---
subtitle: "`r params$faculteit` | `r params$opleidingsnaam` (`r params$opleiding`) - `r params$opleidingsvorm` - versie `r params$versie`"

# Author and date
author: "Theo Bakker, lector Learning Technology & Analytics, De HHs"
date: last-modified

# LTA Template
ltatemplate: 0.9.1.9000

# Format and output
output-file: "lta-hhs-tidymodels-h3-verdieping-kansengelijkheid.html"

# Parameters
params:
  versie: "1.0"
  succes: "Retentie na 1 jaar"
  model: "Retentie na 1 jaar"
  propedeusediploma: "Nvt"
  use_synthetic_data: true
  recreateplots: false

  faculteit: "ITD"
  opleidingsnaam: "B Communication and Multimedia Design"
  opleiding: "CMD"
  opleidingsvorm: "voltijd"
  opleidingsvorm_afkorting: "VT"
  selectie: false

# Content
includes:
  inleiding:      true
  data:           true
  model_lr:       true
  model_rf:       true
  model_svm:      false
  final_fit:      true
  conclusies:     true
  verantwoording: true
  nextsteps:      true
  copyright:      true
---

<!-- Title -->

# Analyse van kansengelijkheid {#sec-kansengelijkheid}

```{r setup, include = FALSE}
#| label: setup
#| echo: false

## Include the _Setup.R file
source("_Setup.R")

```

<!-- Introduction -->

::: {.content-hidden unless-meta="includes.inleiding"}
## Inleiding

Na de factoranalyse van de data gaan we nu in op de onderwerpen bias, fairness en kansengelijkheid. Het doel is beter te begrijpen of er studenten zijn met minder kans op succes en of dit disproportioneel is. Dit kan duiden op kansenongelijkheid.

De analyse van kansengelijkheid heeft de volgende stappen:

1.  We lezen de bewerkte dataset weer in en de modellen die we in de basis-analyse hebben gemaakt.
2.  We maken weer een *explainer* om de modellen beter te begrijpen en te kunnen uitleggen.
3.  Vervolgens berekenen we of er *bias* bestaat voor verschillende groepen studenten naar geslacht, vooropleiding en vorm van aansluiting. We analyseren daarvoor de verdeling van kansen en mate van fairness in het voorspelmodel dat we hebben ontwikkeld.
4.  Tot slot trekken we er conclusies uit over de mate van bias binnen de opleiding voor `r tolower(params$model)`.
:::

<!-- Data -->

## Voorbereidingen

### Laad de data

We laden de bewerkte data en het beste prognosemodel in voor:

**Opleiding**: `r params$faculteit` \| `r Get_Opleidingsnaam_Synth(params$opleidingsnaam)` (`r params$opleiding`), `r params$opleidingsvorm`, eerstejaars - **`r sSucces_model`**

```{r}
#| label: load-data

## Define the paths
sData_outputpath         <- Get_Model_Outputpath(mode = "data")
sFittedmodels_outputpath <- Get_Model_Outputpath(mode = "last-fits")
sModelresults_outputpath <- Get_Model_Outputpath(mode = "modelresults")

## Load data for training: dates, last fits and model results
dfOpleiding_inschrijvingen <- rio::import(sData_outputpath, trust = TRUE) |> 
  mutate(Geslacht      = factor(Geslacht,      levels = lLevels_geslacht),
         Vooropleiding = factor(Vooropleiding, levels = lLevels_vop),
         Aansluiting   = factor(Aansluiting,   levels = lLevels_aansluiting))
lLast_fits                 <- rio::import(sFittedmodels_outputpath, trust = TRUE)
dfModel_results            <- rio::import(sModelresults_outputpath, trust = TRUE)

# Adjust the Retention variable to numeric (0/1), 
# so it can be made into an explainer
dfOpleiding_inschrijvingen$Retentie <- as.numeric(dfOpleiding_inschrijvingen$Retentie) - 1

## Create a list of dfPersonas
lDfPersona <- list()

## Walk over the variables
lDfPersona <- map(c("Geslacht", "Vooropleiding", "Aansluiting"),
                  ~ Get_dfPersona(.x)) |>
  set_names(c("Geslacht", "Vooropleiding", "Aansluiting"))

## Load the personas
dfPersona_all <- Get_dfPersona()

```

### Maak een explainer

We maken weer gebruik van de explainer van `DALEX`.

```{r, include = FALSE}
#| label: fitted-model

sBest_model <- dfModel_results$model[dfModel_results$number == 1]
last_fit    <- lLast_fits[[sBest_model]]

fitted_model <- last_fit |>
  extract_fit_parsnip()

## Check that the coefficients of the model are numerical
coefs <- tidy(fitted_model)$estimate

# Check that the coefficients are numerical
if (!is.numeric(coefs)) {
  stop("De geëxtraheerde coëfficiënten zijn niet numeriek.")
}

```

```{r}
#| label: lf-explainer

## Extract the fitted model and workflow
fitted_model <- last_fit |>
  extract_fit_parsnip()

workflow <- last_fit |>
  extract_workflow()

# Create an explainer
explain_lf <- DALEXtra::explain_tidymodels(
  model = workflow,
  data = dfOpleiding_inschrijvingen |> select(-Retentie),
  y = dfOpleiding_inschrijvingen |> pull(Retentie),
  colorize = TRUE,
  verbose = FALSE,
  label = "Linear Regression"
)

```

<!-- Equity of opportunity -->

## Analyse van kansengelijkheid

Tot slot onderzoeken we kansengelijkheid door te kijken naar bias in de data. Dit wordt ook wel een *fairness analyse* genoemd. Het leidende werk voor fairness analyses is [*Fairness and Machine Learning: Limitations and Opportunities*](https://fairmlbook.org/pdf/fairmlbook.pdf) [@Barocas.2023]. De methode die we in dit deel van de analyse hanteren is op dit gedachtengoed gebaseerd.

We onderzoeken of er bias bestaat voor verschillende groepen studenten als mogelijk teken van kansenongelijkheid. Ook hiervoor maken we gebruik van de `DALEX` explainer en onderzoeken de invloed van de variabelen op de kans op retentie voor verschillende groepen studenten naar geslacht, vooropleiding en aansluiting.

De volgende **definities** zijn van belang:

-   **Bevoorrechte groep**: Een groep die als standaard wordt beschouwd en mogelijk bevoordeeld wordt (bijv. meerderheidsgroepen, mannen, etc.).
-   **Beschermde groep**: Een groep waarvan wordt verwacht dat deze mogelijk benadeeld wordt (bijv. minderheidsgroepen, vrouwen, etc.).

In een onderwijssituatie kunnen deze groepen verschillen van maatschappelijke situaties. Zo hebben vrouwen in het onderwijs vaak een bevoorrechte positie omdat zij over het algemeen meer studiesucces hebben, terwijl in andere domeinen, bijvoorbeeld het vinden van werk, vrouwen vaak een beschermde groep zijn.

### Ratio's om kansengelijkheid te beoordelen

Voor elke groep onderzoeken we **5 ratio's**, ook wel maatstaven of metrieken genoemd. Deze ratio's zijn afgeleid van verhoudingen in de confusion matrix; ze geven inzicht in de mate van bias en kansengelijkheid vanuit verschillende perspectieven van een prognosemodel. 

```{r}
#| label: fig-confusion-matrix-explanation
#| fig-cap: "Confusion matrix in relatie tot BSA"

knitr::include_graphics(here::here("R/images", "confusion-matrix-fairness-lta-hhs.png"))

```

:::::::: panel-tabset
### 1. Accuracy Equality

`r kableExtra::text_spec("**1. Accuracy Equality Ratio**", color = lColors_hhs[["hhs-color-blue"]])`

*In welke mate voorspelt het model zowel de positieve als negatieve uitkomsten goed?*

Deze maatstaf wordt gebruikt om te beoordelen of een model even accuraat is voor verschillende subgroepen binnen de dataset. Het vergelijkt de nauwkeurigheid van het model voor een beschermde groep (een minderheidsgroep) met de nauwkeurigheid voor een bevoorrechte groep (de meerderheidsgroep). Deze ratio wordt berekend als de verhouding tussen de nauwkeurigheid voor de beschermde groep en de nauwkeurigheid voor de bevoorrechte groep.

**Formule**

$$ \text{ACC} = \frac{TP + TN}{TP + FP + TN + FN} $$

**Definities**

-   **Nauwkeurigheid (Accuracy)**: Het percentage correcte voorspellingen van het model. Dit wordt berekend als het aantal juiste voorspellingen gedeeld door het totale aantal voorspellingen.

**Interpretatie**

-   **Ratio = 1**: Het model is even accuraat voor beide groepen.
-   **Ratio \< 1**: Het model is minder accuraat voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.
-   **Ratio \> 1**: Het model is meer accuraat voor de beschermde groep dan voor de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
Stel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de nauwkeurigheid van het model voor havisten 80% is en voor mbo-ers 70%. De Accuracy Equality Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder accuraat is voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).
:::

### 2. Equal Opportunity

`r kableExtra::text_spec("**2. Equal Opportunity Ratio**", color = lColors_hhs[["hhs-color-blue"]])`

*In welke mate zijn de terecht positieve voorspellingen gelijk?*

Deze maatstaf beoordeelt de gelijkheid van kansen die een model biedt aan verschillende subgroepen in termen van de 'True Positive Rate' (TPR). Het vergelijkt de kans dat een model correct een positieve uitkomst voorspelt voor een beschermde groep versus een bevoorrechte groep.

De True Positive Rate (TPR) is een andere term voor de **sensitiviteit** (ook wel recall) genoemd. De Equal Opportunity Ratio wordt berekend als het aantal true positives gedeeld door het totaal aantal werkelijke positives.

**Formule**

$$ \text{TPR} = \frac{TP}{TP + FN} $$

**Definities**

-   **TP**: True Positives (correcte voorspellingen van positieve uitkomsten)
-   **FN**: False Negatives (werkelijke positieve uitkomsten die foutief als negatief zijn voorspeld)

**Interpretatie**

-   **Ratio = 1**: Het model biedt gelijke kansen aan beide groepen in termen van het correct voorspellen van positieve uitkomsten.
-   **Ratio \< 1**: Het model biedt minder kansen aan de beschermde groep in vergelijking met de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.
-   **Ratio \> 1**: Het model biedt meer kansen aan de beschermde groep in vergelijking met de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
Stel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de True Positive Rate voor havisten 70% is en voor mbo-ers 60%. De Equal Opportunity Ratio is dan 0,857 (60% / 70%). Dit betekent dat het model minder kans biedt aan de beschermde groep (mbo-ers) om correct positieve uitkomsten te voorspellen dan aan de bevoorrechte groep (havisten).
:::

### 3. Predictive Equality

`r kableExtra::text_spec("**3. Predictive Equality Ratio**", color = lColors_hhs[["hhs-color-blue"]])`

*In welke mate zijn de vals positieve voorspellingen gelijk?*

Deze maatstaf beoordeelt de gelijkheid van het aantal False Positives (vals-positieven) tussen verschillende subgroepen. Het vergelijkt de False Positive Rate (FPR) voor een beschermde groep met de FPR voor een bevoorrechte groep.

De FPR is de verhouding van het aantal vals-positieve voorspellingen (False Positives, FP) ten opzichte van het totaal aantal werkelijke negatieve gevallen (True Negatives, TN en False Positives, FP). De Predictive Equality Ratio wordt berekend als de verhouding tussen de FPR voor de beschermde groep en de FPR voor de bevoorrechte groep.

**Formule**

$$ \text{FPR} = \frac{FP}{FP + TN} $$

**Definities**

-   **FP**: False Positives (foutieve voorspellingen van positieve uitkomsten)
-   **TN**: True Negatives (correcte voorspellingen van negatieve uitkomsten)

**Interpretatie**

-   **Ratio = 1**: Het model heeft een gelijke kans om False Positives te maken voor beide groepen.
-   **Ratio \< 1**: Het model heeft minder kans om False Positives te maken voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias ten nadele van de bevoorrechte groep.
-   **Ratio \> 1**: Het model heeft meer kans om False Positives te maken voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias ten nadele van de beschermde groep.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
Stel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de False Positive Rate voor havisten 20% is en voor mbo-ers 30%. De Predictive Equality Ratio is dan 1,5 (30% / 20%). Dit betekent dat het model meer kans heeft om vals-positieve voorspellingen te maken voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).
:::

### 4. Predictive Parity

`r kableExtra::text_spec("**4. Predictive Parity Ratio**", color = lColors_hhs[["hhs-color-blue"]])`

*In welke mate zijn de terecht positieve voorspellingen gelijk?*

Deze maatstaf beoordeelt de gelijkheid van de nauwkeurigheid van de voorspelling tussen verschillende subgroepen door de positieve voorspellende waarde (Positive Predictive Value, PPV) van het model voor een beschermde groep te vergelijken met die voor een bevoorrechte groep. De PVV wordt ook wel de **precisie** genoemd en wordt berekend als het aantal true positives (TP) gedeeld door het totaal aantal voorspelde positives (TP en FP). Het is een maat voor de nauwkeurigheid van de positieve voorspellingen van het model.

**Formule**

$$ \text{PPV} = \frac{TP}{TP + FP} $$

**Definities**

-   **TP**: True Positives (correcte voorspellingen van positieve uitkomsten)
-   **FP**: False Positives (foutieve voorspellingen van positieve uitkomsten)

**Interpretatie**

-   **Ratio = 1**: Het model heeft een gelijke nauwkeurigheid in voorspellingen voor beide groepen.
-   **Ratio \< 1**: Het model is minder nauwkeurig in het voorspellen van positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.
-   **Ratio \> 1**: Het model is nauwkeuriger in het voorspellen van positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat ook op een vorm van bias kan wijzen, maar in het voordeel van de beschermde groep.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
Stel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de Positive Predictive Value voor havisten 80% is en voor mbo-ers 70%. De Predictive Parity Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder nauwkeurig is in het voorspellen van positieve uitkomsten voor de beschermde groep (mbo-ers) dan voor de bevoorrechte groep (havisten).
:::

### 5. Statistical Parity

`r kableExtra::text_spec("**5. Statistical Parity Ratio**", color = lColors_hhs[["hhs-color-blue"]])`

*In welke mate zijn de positieve voorspellingen gelijk?*

Deze maatstaf beoordeelt de gelijkheid van de positieve voorspellingen (ongeacht of ze correct zijn of niet) tussen verschillende subgroepen. Het vergelijkt de kans dat een model een positieve uitkomst voorspelt voor een beschermde groep met de kans dat het een positieve uitkomst voorspelt voor een bevoorrechte groep. De Statistical Parity Ratio wordt berekend als de verhouding tussen de kans op een positieve voorspelling voor de beschermde groep en de kans op een positieve voorspelling voor de bevoorrechte groep.

**Formule**

$$ \text{SPR} = \frac{TP + FP}{TP + FP + TN + FN} $$

**Definities**

-   **Positieve Voorspelling**: Een voorspelling waarin het model een positieve uitkomst voorspelt (bijv. aangenomen worden, krediet goedkeuring, etc.).

**Interpretatie**

-   **Ratio = 1**: Het model voorspelt even vaak positieve uitkomsten voor beide groepen.
-   **Ratio \< 1**: Het model voorspelt minder vaak positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat wijst op mogelijke bias tegen de beschermde groep.
-   **Ratio \> 1**: Het model voorspelt vaker positieve uitkomsten voor de beschermde groep dan voor de bevoorrechte groep, wat kan wijzen op bias ten nadele van de bevoorrechte groep.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
Stel dat we retentie voor havisten (bevoorrecht) en mbo-ers (beschermd) voorspellen en de kans op een positieve voorspelling voor havisten 80% is en voor mbo-ers 70%. De Statistical Parity Ratio is dan 0,875 (70% / 80%). Dit betekent dat het model minder vaak positieve uitkomsten voorspelt voor de beschermde groep (havisten) dan voor de bevoorrechte groep (mbo-ers).
:::
::::::::

Nu we deze begrippen hebben gedefinieerd, kunnen we de bias en kansengelijkheid van het model voor verschillende groepen studenten analyseren. Hiervoor gebruiken we het `fairmodels` package van `DALEX`.

<!-- Numbers and percentages by group -->

### Aantallen en percentages per groep

Voor de variabelen `Geslacht`, `Vooropleiding` en `Aansluiting` is de verdeling binnen deze opleiding als volgt:

```{r}
#| label: tbl-amount-and-percentages-per-group
#| tbl-cap: "Aantallen en percentages naar geslacht, vooropleiding en aansluiting in relatie tot retentie"
#| results: asis
#| echo: false

## Create a table with numbers and percentages for the 3 variables `Geslacht`, `Vooropleiding` and `Aansluiting`

tbl_summary <- dfOpleiding_inschrijvingen |> 
  select(Retentie, Geslacht, Vooropleiding, Aansluiting) |> 
  mutate(Retentie = ifelse(Retentie == 1, "Ja", "Nee")) |>
  tbl_summary(by = Retentie) |> 
  add_p(pvalue_fun = ~ style_pvalue(.x, digits = 2),
          test.args = list(
            all_tests("fisher.test") ~ list(simulate.p.value = TRUE),
            all_tests("wilcox.test") ~ list(exact = FALSE)
          )) |> 
    add_significance_stars(
      hide_p = FALSE,
      pattern = "{p.value}{stars}"
    ) |>
  add_overall(col_label = "**Totaal**  \nN = {style_number(N)}") |>
  add_n() |>
  modify_header(label ~ "**Variabele**") |> 
  modify_spanning_header(c("stat_1", "stat_2") ~ "**Retentie na 1 jaar**") |>
  bold_labels() |> 
  as_flex_table() |> 
  flextable::border(border.top = fp_border(color = "grey")) |> 
  set_table_properties(width = 0.8, layout = "autofit")


# Print summary table
tbl_summary

```

<!-- Distribution of opportunities by group -->

### Verdeling van kansen

Voordat we in meer detail kansengelijkheid gaan analyseren, onderzoeken we eerst de *verdeling van de kansen* op retentie voor verschillende groepen studenten voor de variabelen `Geslacht`, `Vooropleiding` en `Aansluiting`. De verdeling van deze kansen is uniek per opleiding.

**Toelichting**

-   De verdeling van de kansen is te zien door de *boxplot* en de *violin plot*.
-   De boxplot geeft de vier quartielen aan van de data: de box staat voor de middelste 50% van de data, met een streep die de mediaan aangeeft (de middelste waarde van de data). De lijnen (*whiskers*) geven de 1e 25% en laatste 25% van de data.
-   De boxplot wordt gecombineerd met de violin plot, waarbij de breedte van de violin de dichtheid van de data aangeeft. Het kan zijn dat het lijkt alsof er geen violin is; in dat geval is de verdeling van het aantal studenten zeer breed en de violin vorm daardoor heel smal.
-   Samen geven deze twee visualisaties een goed beeld van de verdeling van de voorspelde kansen van het model.
-   De blauwe gestippelde lijn geeft de 50% kans aan; alle waarden die boven deze lijn valt heeft een kans van 50% of meer op retentie. Hiervan voorspelt het model dat zij niet uitvallen. Deze grenslijn kan door de verdeling van de groepen heen lopen.

```{r}
#| label: bias-analysis-density
#| results: asis

## Make a fairness analysis
for(group in c("Geslacht", "Vooropleiding", "Aansluiting")) {

  ## Group
  Knit_Header(group, 4)
  
  # Determine the most common subgroup = Privileged
  sPrivileged <- Get_Privileged(dfOpleiding_inschrijvingen, group)

  ## Create a fairness object
  fobject <- Get_objFairness(explain_lf, group, sPrivileged)
  
  ## Create a table from the fairness analysis
  dfFairness_totaal <- Get_dfFairness_Total(fobject)
  
  ## Create a plot of the fairness analysis
  density_plot <- suppressWarnings(
    Get_Density_Plot(fobject, group = group) 
  ) 

  ## Save the plot
  sPlotname <- glue("density_plot_{tolower(group)}")
  sPlotPath <- Get_Plot_Outputpath(sPlotname, mode = "plot")

  suppressWarnings(
        Finalize_Plot(
          plot_name = density_plot,
          save_filepath = sPlotPath,
          height_pixels = 250 + (50 * length(unique(dfFairness_totaal$Categorie)))
        ))

  ## Show the existing plot
  sPlot <- glue("![Verdeling en dichtheid van kans op retentie naar  {tolower(group)}]({sPlotPath}){{#fig-fairness-check-{tolower(group)}}}")
  Knit_Print_Rule(sPlot)

}

```

### Fairness checks

Nu we de verdeling van de kansen kennen, maken we tot slot een fairness analyse voor de variabelen `Geslacht`, `Vooropleiding` en `Aansluiting`. Voor elke groep berekenen we de maatstaven die we eerder hebben behandeld.

We maken een plot van de fairness analyse, waarbij we per variabele één categorie nemen als de bevoorrechte groep; hiervoor hanteren we per variabele de meest frequente groep. De aanname is dat een opleiding op deze groep het beste is toegerust. Daarnaast speelt mee dat Dalex bij een te laag aantal studenten in een bevoorrechte groep geen fairness analyse kan berekenen.

Als binnen een variabele een groep een ratio heeft die naar links of naar rechts afwijkt, kan dit duiden op een verschil in kansengelijkheid. Let erop dat de bevoorrechte groep zelf hier niet in is opgenomen (!). Mochten alle overige groepen naar links of rechts afwijken, dan is er sprake van een bias naar de bevoorrechte groep.

Het wijkt af als de balken verder buiten het groene vlak komen en in het rode vlak; dit is gebaseerd op een marge, *epsilon*, van 0,8. Deze marge is gebaseerd op het 4/5 principe: er is sprake van een te groot verschil als de maat voor een beschermde groep 4/5 of meer afwijkt van de bevoorrechte groep. Een epsilon van 0,8 leidt tot marges van -0,2 (epsilon/1) en +0,25 (1/espilon). Als er twee ratio's of meer buiten deze marges vallen, is er volgens dit criterium sprake van bias. Als een maatstaf naar links afwijkt is er sprake van bias naar de beschermde groep (ten nadele), als deze naar rechts afwijkt is er sprake van bias naar de bevoorrechte groep (ten voordele).

::: {.callout-warning appearance="default" icon="true"}
### Nota Bene

Als de uitkomstmaat van een model negatief is (zoals uitval), dan moet de interpretatie precies andersom gemaakt worden. Dit geldt voor alle maatstaven van bias en fairness in dit hoofdstuk.
:::

Om de robuustheid en betrouwbaarheid in de detectie van bias te waarborgen, moeten er minstens twee metrieke waarden buiten de epsilon-marges vallen voordat er sprake is van bias [@Barocas.2023]. Hiervoor is een aantal redenen:

**1. Meerdere indicatoren**: Het gebruik van meerdere maatstaven zorgt ervoor dat we de detectie van bias niet baseren op slechts een, mogelijk ruisgevoelige, indicator. Als slechts één metriek buiten de marges valt, kan dit toeval zijn of te wijten zijn aan andere niet-systematische fouten in de data. We spreken dan nog niet over bias. Meerdere metrieke afwijkingen geven een sterkere indicatie van een systematisch probleem.

**2. Differentie van bias types**: Bias kan zich op verschillende manieren manifesteren, bijvoorbeeld in termen van ongelijksoortige impact, ongelijke kansen in voorspellingen of ongelijke behandeling. Door meerdere maatstaven te evalueren, onderzoeken we een breder spectrum van potentiële bias en zien we geen aspecten over het hoofd.

**3. Normatieve overwegingen**: Vaak is er een normatieve basis voor het definiëren van wat eerlijk is. Het vergelijken van meerdere maatstaven kan helpen om genuanceerder en vollediger beeld te krijgen van hoe een model presteert ten opzichte van verschillende fairness criteria.

De keuze voor twee maatstaven als minimum baseren we op een combinatie van statistische overwegingen en praktische normen binnen het machine learning vakgebied om een goed evenwicht te vinden tussen sensitiviteit (het detecteren van daadwerkelijke bias) en specificiteit (het vermijden van vals positieven) [@Barocas.2023].

```{r}
#| label: bias-analysis
#| results: asis

## Make a fairness analysis
for(group in c("Geslacht", "Vooropleiding", "Aansluiting")) {

  ## Group
  Knit_Header(group, 4)
  
  # Determine the most common subgroup = Privileged
  sPrivileged <- Get_Privileged(dfOpleiding_inschrijvingen, group)

  ## Create a fairness object
  fobject <- Get_objFairness(explain_lf, group, sPrivileged)

  ## Create a table from the fairness analysis
  dfFairness_totaal <- Get_dfFairness_Total(fobject)
  
  ## Check for bias
  Print_Fairness_Object_LTA(fobject)

  ## Create a plot of the fairness analysis
  fairness_plot <- suppressWarnings(
    Get_Fairness_Plot(fobject, group = group, privileged = sPrivileged) +
      theme(panel.border = element_rect(
        colour = "darkgrey",
        fill = NA,
        size = 0.4
      ))
  )

  ## Save the plot
  sPlotname <- glue("fairness_plot_{tolower(group)}")
  sPlotPath <- Get_Plot_Outputpath(sPlotname, mode = "plot")

  suppressWarnings(
        Finalize_Plot(
          plot_name = fairness_plot,
          save_filepath = sPlotPath,
          height_pixels = 250 + (50 * length(unique(dfFairness_totaal$Categorie)))
        ))

  ## Show the existing plot
  sPlot <- glue("![Fairness check naar {tolower(group)}]({sPlotPath}){{#fig-fairness-check-{tolower(group)}}}")
  Knit_Print_Rule(sPlot)
  
  ## Keep the fairness check data
  sFairness_outputpath  <- Get_Model_Outputpath(mode = "fairness", group = group)
  dfFairness_check_data <- Get_dfFairness_Check_Data(fobject[["fairness_check_data"]], group = group)
  saveRDS(dfFairness_check_data, file = sFairness_outputpath)
  
}

```

<!-- Conclusions -->

## Conclusies

Na de uitvoering van de fairness analyse vatten we de conclusies samen in een tabel en tekst.

**Toelichting:**

-   Bij rood is er sprake van een negatieve bias.
-   Bij groen is er sprake van een positieve bias.
-   Bij oranje is er sprake van een bias, maar zijn de aantallen studenten te laag om conclusies over een negatieve of positieve bias aan te verbinden. We hanteren een minimum van 15 studenten per categorie binnen een variabele.
-   De bevoorrechte groep is grijs. Hiervan dient een eventuele bias nader bepaald te worden (NTB = Nader te bepalen). Dit is het geval als alle overige groepen binnen een variabelen een bias hebben.

```{r}
#| label: tbl-fairness-conclusions
#| tbl-cap: "Fairness conclusies per groep"
#| results: asis
#| echo: false

lDfFairness <- list()

## Walk over the variables
for(i in c("Geslacht", "Vooropleiding", "Aansluiting")) {
  sFairness_outputpath  <- Get_Model_Outputpath(mode = "fairness", group = i)
  lDfFairness[[i]]      <- readRDS(sFairness_outputpath) |> 
    mutate(FRN_Bias = case_when(FRN_Score < 0.8 ~ "Negatieve Bias",
                                FRN_Score > 1.25 ~ "Positieve Bias", 
                                .default = "Geen Bias")) 
}

## Create a table from the fairness analysis
dfFairness_wide  <- Get_dfFairness_Wide(lDfFairness)

# Create a flextable
ftFairness_table <- Get_ftFairness(flextable(dfFairness_wide))

# Print the flextable
ftFairness_table
```

```{r}
#| label: txt-fairness-conclusions

# Now create a text per variable from the table
lConclusies <- list()
for(i in c("Geslacht", "Vooropleiding", "Aansluiting")) {
  lConclusies[[i]] <- Get_Fairness_Conclusies(dfFairness_wide, i)
}

# print(lConclusies[["Geslacht"]])
# print(lConclusies[["Vooropleiding"]])
# print(lConclusies[["Aansluiting"]])

```

<!-- Conclusions in text -->

1.  **Geslacht**: `r lConclusies[["Geslacht"]]`
2.  **Vooropleiding**: `r lConclusies[["Vooropleiding"]]`
3.  **Aansluiting**: `r lConclusies[["Aansluiting"]]`

<!-- Accountability -->

::: {.content-hidden unless-meta="includes.verantwoording"}
{{< include R/qmd/Include_Verantwoording.qmd >}}
:::

<!-- Copyright -->

{{< include R/qmd/Include_Copyright.qmd >}}


<!-- Cleaning up -->

```{r, echo = FALSE}
#| label: cleanup

## Datasets


## Collect garbage
invisible(gc())
  
```
