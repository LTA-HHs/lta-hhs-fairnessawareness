---
subtitle: "`r params$faculteit` | `r params$opleidingsnaam` (`r params$opleiding`) - `r params$opleidingsvorm` - versie `r params$versie`"

## Auteur en datum
author: "Theo Bakker, lector Learning Technology & Analytics, De HHs"
date: last-modified

## LTA Template
ltatemplate: 0.9.1.9000

## Format en output
output-file: "lta-hhs-tidymodels-retentie-verdieping-factoren.html"

## Parameters        
params:
  versie: "1.0"
  succes: "Retentie na 1 jaar"
  propedeusediploma: "Nvt" ## Nvt/Met P/Zonder P
  
  ## Use synthetic data
  use_synthetic_data: true
  
  ## Recreate plots
  recreateplots: true
  
  # BRV:ORM DU
  # faculteit: "BRV"
  # opleidingsnaam: "B Bestuurskunde Overheidsmanagement"
  # opleiding: "BO"
  # opleidingsvorm: "duaal"
  # opleidingsvorm_afkorting: "DU"
  # selectie: false
  
  # BRV:HBO-R VT
  # faculteit: "BRV"
  # opleidingsnaam: "B HBO-Rechten"
  # opleiding: "HBO-R"
  # opleidingsvorm: "deeltijd"
  # opleidingsvorm_afkorting: "DT"
  # selectie: false
  
  # ITD:CMD
  faculteit: "ITD"
  opleidingsnaam: "B Communication and Multimedia Design"
  opleiding: "CMD"
  opleidingsvorm: "voltijd"
  opleidingsvorm_afkorting: "VT"
  selectie: false
  
  ## Author
  author: "Theo Bakker, lector Learning Technology & Analytics"
  
## Content
includes:
  inleiding:      true
  data:           true
  model_lr:       true
  model_rf:       true
  model_svm:      false
  final_fit:      true
  conclusies:     true
  verantwoording: true
  nextsteps:      true
  copyright:      true
---

<!-- Title -->

# Analyse van factoren {#sec-factoranalyse}

```{r setup, include = FALSE}
#| label: setup
#| echo: false

## Sluit het _Setup.R bestand in
source("_Setup.R")

```

<!-- Inleiding -->

::: {.content-hidden unless-meta="includes.inleiding"}
## Inleiding

Na de basis-analyse van de data en het bouwen van de prognosemodellen, gaan we in deze verdiepende analyse dieper in op de **factoren** van de modellen. Het doel is beter te begrijpen hoe de factoren precies de retentie verklaren. Deze verdiepende factoranalyse heeft 6 stappen:

1.  We lezen de bewerkte dataset in en de modellen die we in de basis-analyse hebben gemaakt.
2.  We maken een *explainer* om de modellen beter te begrijpen en te kunnen uitleggen. Dit lichten we later in deze pagina toe.
3.  We gebruiken het beste model om de prognose te verklaren en te begrijpen. We kijken naar de bijdrage van de variabelen aan de voorspelling en passen het model toe op de meest voorkomende studenten.
4.  Vervolgens onderzoeken we de stabiliteit van de invloed van de verklarende variabelen met behulp van *Shapley* waarden.
5.  Daarna onderzoeken we hoe de retentie er *anders* uit zou kunnen zien als de studenten andere kenmerken zouden hebben met een *Ceteris Paribus analyse*.
6.  Tot slot onderzoeken we per variabele de variantie van de voorspellingen met een *Partial Dependence analyse*.\
:::

<!-- Data -->

## Voorbereidingen

### Laad de data

We laden de bewerkte data en prognosemodellen in voor:

**Opleiding**: `r params$faculteit` \| `r Get_Opleidingsnaam_Synth(params$opleidingsnaam)` (`r params$opleiding`), `r params$opleidingsvorm`, eerstejaars - **`r sSucces_model`**

```{r}
#| label: load_data

## Bepaal de paden
sData_outputpath           <- Get_Model_Outputpath(mode = "data")
sFittedmodels_outputpath   <- Get_Model_Outputpath(mode = "last-fits")
sModelresults_outputpath   <- Get_Model_Outputpath(mode = "modelresults")

## Laad de data voor de opleiding: data, last fits en model results
dfOpleiding_inschrijvingen <- rio::import(sData_outputpath, trust = TRUE)
lLast_fits                 <- rio::import(sFittedmodels_outputpath, trust = TRUE)
dfModel_results            <- rio::import(sModelresults_outputpath, trust = TRUE)

# Pas de Retentie variabele aan naar numeric (0/1), 
# zodat er een explainer van gemaakt kan worden
dfOpleiding_inschrijvingen$Retentie <- as.numeric(dfOpleiding_inschrijvingen$Retentie) - 1

## Maak een lijst van dfPersonas
lDfPersona <- list()

## Loop over de variabelen
lDfPersona <- map(c("Geslacht", "Vooropleiding", "Aansluiting"),
                  ~ Get_dfPersona(.x)) |>
  set_names(c("Geslacht", "Vooropleiding", "Aansluiting"))

dfPersona_per_group <- bind_rows(lDfPersona) 

## Bewaar dit bestand als excel
sOutputPath <- file.path("92_Tmp", "dfPersona_per_group.xlsx")
writexl::write_xlsx(dfPersona_per_group, sOutputPath)

## Laad de persona's
dfPersona_all <- Get_dfPersona()

```

## Verdiepende analyse van het model

We weten vanuit de basis-analyse welke variabelen van invloed zijn, maar niet hoe en in welke richting ze retentie verklaren: dragen ze sterk bij of juist niet, verhogen of verlagen ze retentie? Om het model beter te begrijpen en te kunnen uitleggen, maken met behulp van het [`DALEX` package](https://dalex.drwhy.ai) een *explainer*.

DALEX is onder andere ontwikkeld om uit te kunnen leggen welke verklarende variabelen van belang zijn en wat deze voor een effect hebben in een model. Een explainer is een model-onafhankelijke *wrapper*, die inzicht geeft in de voorspellingen van het model en de bijdrage van de variabelen aan de prognose. Een explainer maakt het verder mogelijk om modellen onderling te vergelijken en benchmarken.

### Maak een explainer

We gaan nu een stap verder met behulp van het `DALEX` package. Op basis van het tidymodels model extraheren we de informatie voor de explainer van Dalex.

```{r, include=FALSE}
#| label: fitted_model

sBest_model <- dfModel_results$model[dfModel_results$number == 1]
last_fit    <- lLast_fits[[sBest_model]]

fitted_model <- last_fit |>
  extract_fit_parsnip()

## Controleer of de coefficienten van het model numeriek zijn
coefs <- tidy(fitted_model)$estimate

# Controleer of de coëfficiënten numeriek zijn
if (!is.numeric(coefs)) {
  stop("De geëxtraheerde coëfficiënten zijn niet numeriek.")
}

```

```{r}
#| label: lf_explainer

## Extraheer het fitted model en de workflow
fitted_model <- last_fit |>
  extract_fit_parsnip()

workflow <- last_fit |>
  extract_workflow()

# Maak een explainer
explain_lf <- DALEX::explain(
  model = workflow,
  data = dfOpleiding_inschrijvingen,
  y = dfOpleiding_inschrijvingen$Retentie,
  label = "Linear Regression")

```

### Toets de Root Mean Square Error na permutaties

De eerste analyse is de Root Mean Square Error (RMSE) na permutaties.

-   De **RMSE** is een maatstaf voor de gemiddelde afwijking van de voorspellingen van een model ten opzichte van de werkelijke waarden. Het wordt berekend als de wortel van de gemiddelde kwadratische fout.
-   **RMSE na permutaties** wil zeggen dat de RMSE is berekend na het herhaaldelijk willekeurig herschikken (permuteren) van de waarden van een variabele in de dataset en daarmee de voorspellingen. Deze techniek passen we toe om de robuustheid en betrouwbaarheid van het model te evalueren.

**Waarom is RMSE na permutaties nodig?**

-   **Modelvalidatie**: Door de variabelen te permuteren en de RMSE te berekenen, kunnen we de prestatie van het model vergelijken met een willekeurige schatting. Variabelen die significant beter presteren dan de gemiddelde RMSE na permutaties hebben meer voorspellende kracht.
-   **Overfit detectie**: Als de RMSE van het originele model niet veel beter is dan het RMSE na permutaties, kan dit een indicatie zijn dat het model overfit op de trainingsdata en niet goed generaliseert naar nieuwe data.

De meeste voorspellende factoren en hun RMSE zijn:

```{r}
#| label: lf_model_parts

sPlotPath <- file.path(Get_Plot_Outputpath(plotname = "lf_model_parts_rmse"))

## Als de plot niet bestaat of als recreateplots - T, maak dan een nieuwe plot
if(!file.exists(sPlotPath) | params$recreateplots == TRUE) {

  ## Bereken de model parts op basis van de RMSE
  mp_rmse <- model_parts(explain_lf, loss_function = loss_root_mean_square)
  
  ## Maak een plot van de RMSE
  mp_rmse_plot <- Get_RMSE_Plot(mp_rmse)
  
  ## Bewaar de plot
  suppressWarnings(
    Finalize_Plot(
      plot_name = mp_rmse_plot,
      save_filepath = sPlotPath,
      height_pixels = 50 + (15 * length(unique(mp_rmse$variable)))
    ))

  # ## Toon de bestaande plot
  knitr::include_graphics(sPlotPath)
      
} else {
  
  ## Toon de bestaande plot
  knitr::include_graphics(sPlotPath)
  
}
```

Het valt op dat de meest voorspellende variabelen ook een hoge RMSE hebben. Dit betekent dat deze variabelen een grote invloed hebben op de voorspelling van het model, maar per toepassing op een individuele student uit het verleden ook sterk kunnen variëren.

### Inspecteer variabelen met de meeste invloed

Een volgende analyse is een toepassing van het model op de meest voorkomende student. We kijken eerst naar de meest voorkomende student in het algemeen. Vervolgens analyseren we de meest voorkomende student in meerdere groepen: naar vooropleiding, geslacht, leeftijd en aansluiting, etc. Om de meest voorkomende student te bepalen, gebruiken we de meeste frequente waarden van de verklarende variabelen in de dataset per groep.

NB. Het kan goed zijn dat we combinaties krijgen van waarden van variabelen die niet kunnen voorkomen, bijv. een student van het mbo met een E&M profiel. Dit is wel correct: het is een fictieve student die de meest voorkomende kenmerken van de totale populatie van studenten van deze opleiding vertegenwoordigt.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
Stel dat we een onderscheid maken tussen mbo en havo studenten, dan bepalen we de mediaan van numerieke variabelen en de meest frequente waarde van categorische variabelen. Van de leeftijd kan misschien 20 het vaakst voorkomen, etc.
:::

We kijken hiermee naar de voorspelling van het model per groep en de bijdrage van de verklarende variabelen aan die specifieke voorspelling. Dit geeft een verder inzicht in de werking van het model. Een categorie met 20 studenten of minder laten we buiten beschouwing.

```{r}
#| label: lf_break_down_all
#| echo: false
#| results: asis

## Maak een breakdown van de meeste voorkomende student over alle data
breakdown_lf_all <- predict_parts(explainer = explain_lf,
                                  new_observation = dfPersona_all[1, ],
                                  type = "break_down")

## Bereken de intercept
nIntercept <- breakdown_lf_all |> 
  filter(variable == "intercept") |>
  pull(cumulative) * 100 |> 
  round(1) 

sIntercept <- Change_Number_Marks(nIntercept, digits = 1)

```

#### Toelichting op de opbouw van de kans op retentie

De opbouw van het model bestaat uit een *intercept*, gevolgd door verklarende variabelen die een verschil maken ten opzichte van die intercept. De intercept is de **basiskans op retentie** voor alle studenten. Deze kans is voor de `r params$opleidingsnaam` (`r params$opleiding`) `r params$opleidingsvorm` **`r sIntercept`%**. De cumulatieve bijdrage van de variabelen aan de voorspelling kan positief of negatief zijn. Een positieve bijdrage betekent dat de variabele de kans op retentie verhoogt, een negatieve bijdrage betekent dat het de kans op retentie verlaagt.

Het kan zijn dat nieuwe variabelen geen invloed meer hebben op de kans. Dit betekent niet per se dat ze niet belangrijk zijn. Het kan zijn dat de invloed die ze hebben op de kans al is 'afgevangen' door variabelen die eerder in het model zijn opgenomen.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
De variabele `Cijfer_CE_VO_missing = Ja` betekent dat een student geen VO cijfers heeft voor het centraal schriftelijk examen. Dit geldt voor vrijwel alle MBO studenten. Doordat de variabele `Cijfer_CE_VO_missing` de kans op retentie net wat sterker beïnvloedt, komt `Vooropleiding = MBO` niet meer voor als invloedrijke variabele, maar is dit wel de achterliggende reden dat het cijfer ontbreekt.
:::

Uiteindelijk tellen alle verklarende variabelen op tot een definitieve voorspelling die per persoon verschilt, afhankelijk van hun persoonlijke verschillen per variabele.

#### De meest voorkomende student (totaal)

We kijken eerst naar de meest voorkomende student in de opleiding. We analyseren de kans op retentie voor deze *fictieve* student en de bijdrage van de variabelen aan die kans. Daarbij tonen we de verdeling van de voorspellingen voor deze student voor alle variabelen en per variabele. Dit laat zien welke variabelen belangrijk zijn, naar welke kant de verdeling neigt en welke spreiding de kansverdeling heeft.

**Toelichting**

-   **All data** - De eerste variabele `all data` is eigenlijk geen variabele, maar geeft aan wat alle data samen aan kans op retentie voorspellen. Variabelen die daarna bovenaan staan, wegen het zwaarst in de voorspelling van de kans.
-   **Richting** - Als de verdeling van de kansen naar de linkerkant van de x-as gaat, draagt deze variabele meer bij aan een toename op de kans op retentie; als deze naar de rechterkant beweegt, draagt deze variabele juist bij aan een afname op de kans op retentie
-   **Spreiding** - Als de spreiding breed is, geeft dit aan dat er binnen deze variabele veel variatie is in de kans op retentie en er voorzichtig mee omgegaan moet worden. Als de spreiding heel smal is, betekent dit dat de variabele weinig of geen invloed heeft op de kans op retentie Deze variabelen bevinden zich op de intercept.
-   **Vorm** - De vorm achter de variabele (een viool) geeft de verdeling van de kans op retentie weer. Hoe breder de viool-vorm, hoe meer studenten op die locatie een kans op retentie hebben.

```{r}
#| label: lf_break_down_distribution_all
#| echo: false
#| results: asis

## Bepaal de plot
sPlotPath <- file.path(Get_Plot_Outputpath(plotname = "lf_break_down_distribution_all"))

## Als de plot niet bestaat of als recreateplots - T, maak dan een nieuwe plot
if(!file.exists(sPlotPath) | params$recreateplots == TRUE) {

  ## Bepaal de algemene persona en de breakdown (met distributie)
  breakdown_lf_all <- predict_parts(explainer = explain_lf,
                                    new_observation = dfPersona_all[1, ],
                                    type = "break_down",  
                                    keep_distributions = TRUE)
  
  ## Bepaal de dataframe voor de breakdown
  dfBreakdown_lf_all <- Get_dfBreakdown_Lf(breakdown_lf_all)
  
  ## Bepaal de titels
  lTitles <- Get_Breakdown_Titles(breakdown_lf_all, dfPersona_all, 1, 
                                  "Alle studenten", "Alle studenten",
                                  mode = "all")
  
  ## Bouw de plot
  breakdown_plot <- Get_Breakdown_Plot_All(breakdown_lf_all, 
                                           lTitles)
    
  ## Bewaar de plot
  suppressWarnings(
    Finalize_Plot(
          plot_name = breakdown_plot,
          save_filepath = sPlotPath,
          height_pixels = 50 + (20 * length(breakdown_lf_all$variable))
        )
    )

  
  ## Toon de bestaande plot
  knitr::include_graphics(sPlotPath)

} else {

  ## Toon de bestaande plot
  knitr::include_graphics(sPlotPath)

}

```

#### De meest voorkomende student (per groep)

Nu de algemene opbouw van de kans op retentie bekend is voor de meest voorkomende student, gaan we verder met een analyse van de meest voorkomende studenten *per groep*.

De volgorde van de variabelen is zo gesorteerd dat per groep de meest voorspellende variabelen bovenaan staat. De volgorde verschilt per groep en geeft inzicht in wat er per groep speelt. De variabelen zijn vaak proxies voor onderliggende verschillen.

```{r}
#| label: lf_break_down
#| echo: false
#| results: asis

## Loop over de persona's
for(group in names(lDfPersona)) {
  
  ## Laad de dataset voor de huidige persona
  dfPersona <- lDfPersona[[group]]
  
  ## Print de naam van lDfPersona als header
  Knit_Header(glue("Naar {tolower(group)}"), 5)
  
  ## Bepaal of er in de dataset een groep is met minder dan 21 studenten;
  ## Zo ja, laat die buiten beschouwing en meld dit
  if (any(dfPersona$Subtotaal < 21)) {
    
    ## Bepaal de categorieën met minder dan 21 studenten
    lCategorie_te_laag <- dfPersona |>
      filter(Subtotaal < 21) |>
      pull(Categorie) 
    
    ## Bepaal de tekst voor de melding
    if(length(lCategorie_te_laag) > 1) {
      .categorieen  <- paste0(head(lCategorie_te_laag, 
                                   length(lCategorie_te_laag) - 1), " en ", 
                              tail(lCategorie_te_laag, 1))
      .subtotalen   <- "De subtotalen voor de categorieën"
      .persoonsvorm <- "zijn"
    } else {
      .categorieen  <- lCategorie_te_laag
      .subtotalen   <- "Het subtotaal voor de categorie"
      .persoonsvorm <- "is"
    }
    
    ## Print de melding
    Knit_Print_Rule(glue("{(.subtotalen)} {(.categorieen)} {(.persoonsvorm)} te laag voor een betrouwbare analyse."))
  }
  
  ## Open een panel-tabset
  Knit_Print_Rule(glue("::: {.panel-tabset}", 
                       .open = "{{", 
                       .close = "}}"))
  
  ## Bepaal de sorteervolgorde van de variabelen
  if(group == "Geslacht") {
    lArrange <- c("M", "V")
  } else if (group == "Vooropleiding") {
    lArrange <- lLevels_vop
  } else if (group == "Aansluiting"){
    lArrange <- lLevels_aansluiting
  }
  
  # Sorteer de persona op basis van de levels van de categorie
  dfPersona <- dfPersona |> 
    arrange(match(Categorie, lArrange))
  
  # Loop over de persona's
  for(j in 1:nrow(dfPersona)) {
    
    ## Bepaal de huidige student
    student_current   <- dfPersona[j, ]
    student_groep     <- student_current$Groep
    student_categorie <- dfPersona[j, ]$Categorie # levels(student_current[[student_groep]])[j]
    
    ## Bepaal de plotnaam
    sPlotPath <- Get_Breakdown_Plotpath(student_groep, student_categorie)
    
    ## Als het subtotaal < 21, ga dan door naar het volgende item
    if (as.numeric(dfPersona[j, 'Subtotaal']) < 21) {
      next
    }
    
    ## Als recreateplots == T, maak dan een nieuwe plot
    if(params$recreateplots) {
      
      ## Bepaal de breakdown voor de huidige student
      breakdown_lf <- predict_parts(explainer = explain_lf,
                                    new_observation = student_current,
                                    type = "break_down")
      
      dfBreakdown_lf <- Get_dfBreakdown_Lf(breakdown_lf)
      
      ## Toon de header
      Knit_Header(student_categorie, 5)
      
      ## Functie om de titels te bepalen
      lTitles <- Get_Breakdown_Titles(breakdown_lf, dfPersona, j, 
                                      student_groep, student_categorie)
      
      # Watervalplot met ggplot
      plot <- Get_Breakdown_Plot(dfBreakdown_lf, lTitles)
      
      ## Bewaar de plot
      suppressWarnings(
        Finalize_Plot(
          plot_name = plot,
          save_filepath = sPlotPath,
          height_pixels = 50 + (20 * length(breakdown_lf$variable))
        ))
      
      ## Toon de bestaande plot
      sPlot <- glue("![]({sPlotPath})")
      Knit_Print_Rule(sPlot)
      
    } else {
      
      ## Toon de header
      Knit_Header(student_categorie, 5)
      
      ## Toon de bestaande plot
      sPlot <- glue("![]({sPlotPath})")
      Knit_Print_Rule(sPlot)
      
    }
    
  }
  
  ## Sluit de panel-tabset
  Knit_Print_Rule(":::")
  
}

```

### Shapley

Na deze factorentanalyse kijken we naar de stabiliteit van de invloed van de verklarende variabelen. We gebruiken hiervoor *Shapley* waarden. Anders dan bij de vorige modellen, houdt Shapley rekening met een andere volgorde van de variabelen.

De volgorde van de variabelen is cumulatief (additief) en maakt dus uit voor de bijdrage aan het model: als er een andere variabele al in het model is toegevoegd, heeft dat invloed op de daaropvolgende variabele. Een Shapley analyse permuteert de volgorde van de variabelen om daarmee de verschillen te berekenen in de bijdrage aan de voorspelling. Zo krijgen we nog beter zicht op het belang en de invloed van de individuele variabelen in het voorspelmodel. Variabelen zonder bijdrage hebben we verwijderd.

```{r}
#| label: lf_shapley

## Bewaar de plot
sPlotPath <- file.path(Get_Plot_Outputpath(plotname = "lf_shapley"))

## Als de plot niet bestaat of als recreateplots - T, maak dan een nieuwe plot
if(!file.exists(sPlotPath) | params$recreateplots == TRUE) {

  ## Bepaal de Shapley waarden
  lf_shapley <- 
    predict_parts(
      explainer = explain_lf,
      new_observation = dfPersona_all[1, ],
      type = "shap",
      B = 20
    )

  ## Zet deze om naar een dataframe
  dfShapley <- Get_dfShapley(lf_shapley)

  ## Bouw de plot
  shapley_plot <- Get_Shapley_Plot(dfShapley)
  
  ## Bewaar de plot
  suppressWarnings(
    Finalize_Plot(
      plot_name = shapley_plot,
      save_filepath = sPlotPath,
      height_pixels = 50 + (20 * length(unique(dfShapley$variable_name)))
    ))
  
  ## Print de bestaande plot
  knitr::include_graphics(sPlotPath)

} else {

  ## Print de bestaande plot
  knitr::include_graphics(sPlotPath)

}

```

**Toelichting:**

-   De variabelen met blauwe balken *verhogen* de kans op retentie, de variabelen met rode balken *verlagen* de kans op retentie
-   De boxplot in iedere balk geeft de spreiding van de bijdrage van de variabelen aan de voorspelling weer. Hoe breder de boxplot, des te meer variatie in de bijdrage van de variabele aan de voorspelling.
-   De positie van de variabele geeft het belang van de variabele aan in de voorspelling. Hoe hoger de variabele, des te belangrijker de variabele is in de voorspelling.

<!-- Scenarios -->

### What-if: een Ceteris Paribus analyse

Vervolgens analyseren we een aantal scenario's (wat als...). We nemen opnieuw de meest voorkomende studenten, maar beelden nu af hoe de kans op retentie eruit zou zien als telkens een van de variabelen net wat anders was geweest.

::: {.callout-warning appearance="default" icon="true"}
### Let op!

Dit is de invloed van de variabelen bij de unieke combinatie van deze meest voorkomende student per categorie. Zie voor de invloed van een variabelen ongeacht deze unieke combinatie de analyse van Partial Dependence Profielen in de volgende paragraaf.
:::

Hiervoor houden we steeds alle variabelen gelijk, op één na (*ceteris paribus* is Latijn voor 'al het overige gelijk'). Van die ene variabelen passen we de waarden aan en zien dan het effect op de voorspelde kans op retentie. Dit geeft beter inzicht in het effect van de individuele variabelen in het model. We voeren deze analyse uit voor numerieke variabelen.

::: {.callout-note appearance="simple" icon="false" title="Ter illustratie"}
Stel dat de student in dit model net een wat hoger eindexamencijfer zou hebben gehad op de middelbare school, wat zou dan de kans op retentie zijn geweest? Het is waarschijnlijk dat de kans op retentie dan hoger zou zijn geweest. Bij hbo-opleidingen die goed aansluiten hebben met een opleiding aan een universiteit, zou de kans op retentie juist lager zijn geweest omdat studenten dan na een hbo-diploma vaak doorstromen naar een universiteit.
:::

Opnieuw kijken we naar geslacht, vooropleiding en aansluiting. N.B. Het kan zijn dat een van de categorieën niet zichtbaar is, dit komt doordat deze dan over elkaar heen vallen.

```{r}
#| label: lf_cp_all
#| echo: false
#| results: asis

library(ingredients)

## Bepaal de meest voorkomende studenten
student_all <- dfPersona_all[1, ] |> as.data.frame()

dfPersona_tmp <- bind_rows(lDfPersona)
student_m    <- dfPersona_tmp[1, ]
student_v    <- dfPersona_tmp[2, ]
student_mbo  <- dfPersona_tmp[3, ]
student_havo <- dfPersona_tmp[4, ]
student_vwo  <- dfPersona_tmp[5, ]

## Maak variabelen splits voor elke continue
variable_splits = list(
  Leeftijd = seq(
    min(dfOpleiding_inschrijvingen$Leeftijd),
    max(dfOpleiding_inschrijvingen$Leeftijd),
    1
  ),
  Cijfer_CE_VO = seq(0, 10, 0.5),
  Cijfer_CE_Wiskunde = seq(0, 10, 0.5),
  SES_Totaal = seq(
    min(dfOpleiding_inschrijvingen$SES_Totaal),
    max(dfOpleiding_inschrijvingen$SES_Totaal),
    0.1
  ),
  Aanmelding = seq(
    min(dfOpleiding_inschrijvingen$Aanmelding),
    max(dfOpleiding_inschrijvingen$Aanmelding),
    1
  )
)

for (group in c("Geslacht", "Vooropleiding", "Aansluiting")) {
  
  ## Als recreateplots == T, maak dan een nieuwe plot
  if(params$recreateplots) {
  
    ## Bewaar de plot
    sPlotPath <- file.path(Get_Plot_Outputpath(plotname = paste0("lf_cp_", tolower(group))))
    
    Knit_Header(group, 4)
  
    ## Maak een breakdown van de meeste voorkomende student over alle data
    if(group == "Geslacht") {
      .new_observation <- dfPersona_tmp |>
        filter(Groep == "Geslacht") |> 
        arrange(match(Geslacht, c("M","V")))
    } else if(group == "Vooropleiding") {
      .new_observation <- dfPersona_tmp |>
        filter(Groep == "Vooropleiding",
               Vooropleiding %in% c("MBO", "HAVO", "VWO")) |>
        arrange(match(Vooropleiding, c("MBO", "HAVO", "VWO")))
    } else if(group == "Aansluiting") {
      .new_observation <- dfPersona_tmp |>
        filter(Groep == "Aansluiting") |>
        arrange(match(
          Aansluiting,
          c("Direct",
            "Tussenjaar",
            "Switch",
            "Na CD",
            "Overig",
            "Onbekend")
        ))
    }
    
    ## Maak een ceteris paribus analyse
    cp_lf_all <- predict_profile(
      explainer = explain_lf,
      new_observation = .new_observation,
      variable_splits = variable_splits
    )

    ## Maak een Ceteris Paribus plot
    cp_plot <- Get_Ceteris_Paribus_Plot(cp_lf_all, group)

    suppressWarnings(
          Finalize_Plot(
            plot_name = cp_plot,
            save_filepath = sPlotPath
          ))

    ## Print de bestaande plot
    sPlot <- glue("![]({sPlotPath})")
    Knit_Print_Rule(sPlot)
    
    } else {
      
      ## Print de bestaande plot
      sPlotPath <- file.path(Get_Plot_Outputpath(plotname = paste0("lf_cp_", tolower(group))))
      sPlot <- glue("![]({sPlotPath})")
      Knit_Print_Rule(sPlot)
  
  } 
}

```

<!-- Partial Dependence -->

### Partial Dependence analyse

Tot slot analyseren we *Partial Dependence*. Hierbij onderzoeken we de invloed van individuele variabelen op de kans op retentie, ongeacht de combinatie van de meest voorkomende studenten. Per (numerieke) variabele analyseren we de variantie binnen de kansen op retentie. We gebruiken hiervoor het gemiddelde van alle Ceteris Paribus profielen. Vandaar dat we ook wel spreken over Partial Dependence profielen (PDP's). We gebruiken voor deze analyse weer het `DALEX` package.

We analyseren eerst de variabelen voor alle studenten. We tonen niet alleen de gemiddelde lijn, maar ook de lijnen van de individuele CP-profielen. Vervolgens analyseren op dezelfde manier de variabelen per groep: geslacht, vooropleiding en aansluiting.

**Toelichting**

-   De *gemiddelde lijn* geeft de gemiddelde kans op retentie weer voor alle studenten in de dataset voor alle waarden per variabele.
-   De *individuele lijnen* geven de kans op retentie weer voor de individuele studenten in de dataset voor alle waarden per variabele. De bandbreedte van de individuele lijnen geeft de spreiding van de kans op retentie weer binnen de variabele. Het toont dat de kans op retentie per student kan verschillen, zelfs als de variabele gelijk is; de richting van het verband is wel gelijk.
-   Standaard worden 100 willekeurige profielen gekozen om deze afbeeldingen op te bouwen; door deze selectie kan het zijn dat sommige categorieën met weinig observaties in de populatie niet afgebeeld worden.
-   Doordat lijnen kunnen overlappen kan het zijn dat sommige lijnen niet zichtbaar zijn. De legenda geeft aan welke mogelijke categorieën voorkomen in de analyse.

```{r}
#| label: lf_pdp_all
#| echo: false
#| results: asis

set.seed(1134)

## Maak een PDP voor alle variabelen. Gebruik de variable_splits die we eerder hebben gemaakt
for (group in c("Alle studenten", "Geslacht", "Vooropleiding", "Aansluiting")) {
  
  ## Als recreateplots == T, maak dan een nieuwe plot
  if(params$recreateplots) {
  
    ## Bewaar de plot
    sPlotPath <- file.path(Get_Plot_Outputpath(plotname = paste0("lf_pdp_",
                                                                 tolower(group))))
    ## Maak een header
    Knit_Header(group, 4)

    if(group == "Alle studenten") {
      
      ## Maak het model profiel
      pdp_lf <- model_profile(explainer = explain_lf,
                              variable_splits = variable_splits)

      ## Maak een Partial Dependence plot
      pdp_plot <- Get_Partial_Dependence_Plot(pdp_lf, "all")
      
      
    } else {
      
      ## Maak het model profiel
      pdp_lf <- model_profile(explainer = explain_lf,
                              variable_splits = variable_splits,
                              groups = group)
      
      ## Maak een Partial Dependence plot per groep
      pdp_plot <- Get_Partial_Dependence_Plot(pdp_lf, group)
      
    }
    
    ## Bewaar de plot
    suppressWarnings(
          Finalize_Plot(
            plot_name = pdp_plot,
            save_filepath = sPlotPath
          ))

    ## Print de bestaande plot
    sPlot <- glue("![]({sPlotPath})")
    Knit_Print_Rule(sPlot)
    
    } else {
      
      ## Maak een header
      Knit_Header(group, 4)
      
      ## Print de bestaande plot
      sPlotPath <- file.path(Get_Plot_Outputpath(plotname = paste0("lf_pdp_",
                                                                   tolower(group))))
      sPlot <- glue("![]({sPlotPath})")
      Knit_Print_Rule(sPlot)
      
    }
  }

```

<!-- Next steps -->

::: {.content-hidden unless-meta="includes.nextsteps"}
## Vervolgstappen: kansengelijkheid

De volgende stap (stap 3) is te onderzoeken of er binnen deze opleiding binnen deze modellen **kansengelijkheid** bestaat.

Dit doen we door voor verschillende groepen studenten de metrieken van de modellen te evalueren, zoals accuraatheid. Als de metrieken van de voorspellingen van het model voor verschillende groepen studenten sterk uiteenlopen kan er sprake zijn van een bias, wat kan duiden op kansenongelijkheid. Dit is het onderwerp van de volgende en laatste analyse.
:::

<!-- Verantwoording -->

::: {.content-hidden unless-meta="includes.verantwoording"}
{{< include 01_Includes/Include_Verantwoording.qmd >}}
:::

<!-- Copyright -->

{{< include 01_Includes/Include_Copyright.qmd >}}


<!-- Opschonen -->

```{r, echo = FALSE}
#| label: cleanup

## Datasets


## Collect garbage
invisible(gc())
  
```
